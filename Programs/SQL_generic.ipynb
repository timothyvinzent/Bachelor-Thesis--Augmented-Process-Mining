{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import dspy\n",
    "import dotenv, os\n",
    "from pydantic import BaseModel, Field\n",
    "import openai\n",
    "import pm4py\n",
    "import ast\n",
    "from numpy import random\n",
    "from dspy.evaluate import Evaluate\n",
    "from collections import defaultdict\n",
    "import tqdm as notebook_tqdm\n",
    "import copy\n",
    "import re\n",
    "from dspy.teleprompt import BootstrapFewShot\n",
    "from dspy.teleprompt import BootstrapFewShotWithRandomSearch\n",
    "import phoenix as px\n",
    "from openinference.instrumentation.dspy import DSPyInstrumentor\n",
    "from opentelemetry import trace as trace_api\n",
    "from opentelemetry.exporter.otlp.proto.http.trace_exporter import OTLPSpanExporter\n",
    "from opentelemetry.sdk import trace as trace_sdk\n",
    "from opentelemetry.sdk.resources import Resource\n",
    "from opentelemetry.sdk.trace.export import SimpleSpanProcessor\n",
    "from chroma_retriever import Chroma\n",
    "from chromadb.utils import embedding_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_transformer_ef = embedding_functions.SentenceTransformerEmbeddingFunction(model_name=\"all-mpnet-base-v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_FILE_NAME = \"/Users/sulzair/Documents/Bachelor Thesis/Proof-of-Concept/Road_Traffic_Fine_Management_Process.xes\" #replce with your file path\n",
    "SQLITE_DB_NAME = \"SQL_big.db\" #\"my_database.db\" #leve as is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üåç To view the Phoenix app in your browser, visit http://localhost:6006/\n",
      "üìñ For more information on how to use Phoenix, check out https://docs.arize.com/phoenix\n"
     ]
    }
   ],
   "source": [
    "phoenix_session = px.launch_app()\n",
    "endpoint = \"http://127.0.0.1:6006/v1/traces\"\n",
    "resource = Resource(attributes={})\n",
    "tracer_provider = trace_sdk.TracerProvider(resource=resource)\n",
    "span_otlp_exporter = OTLPSpanExporter(endpoint=endpoint)\n",
    "tracer_provider.add_span_processor(SimpleSpanProcessor(span_exporter=span_otlp_exporter))\n",
    "\n",
    "trace_api.set_tracer_provider(tracer_provider=tracer_provider)\n",
    "DSPyInstrumentor().instrument()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure llm\n",
    "dotenv.load_dotenv()\n",
    "lm = dspy.LM('openai/gpt-4o', temperature=0.3, max_tokens=4096, stop=None, cache=False)\n",
    "dspy.settings.configure(lm = lm, trace = [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ab56d57eeb0445d9b2462c3c92b0e84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "parsing log, completed traces ::   0%|          | 0/150370 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/58/khmpyrfx1rx1x9hg_t8d7d600000gn/T/ipykernel_3943/278237547.py:40: UserWarning: the 'timedelta' type is not supported, and will be written as integer values (ns frequency) to the database.\n",
      "  df_s.to_sql(\"event_log\", conn, if_exists=\"replace\", index=False)\n"
     ]
    }
   ],
   "source": [
    "df = pm4py.read_xes(INPUT_FILE_NAME)\n",
    "df.columns = df.columns.str.replace(':', '_', regex=False)\n",
    "# replace nan values with 0 in columns \"amount\", \"expense\", \"paymentAmount\", \"totalPaymentAmount\"\n",
    "df['amount'] = df['amount'].fillna(0)\n",
    "df['expense'] = df['expense'].fillna(0)\n",
    "df['paymentAmount'] = df['paymentAmount'].fillna(0)\n",
    "df['totalPaymentAmount'] = df['totalPaymentAmount'].fillna(0)\n",
    "#fturn euros into cents\n",
    "df['amount'] = df['amount'] * 100\n",
    "df['amount'] = df['amount'].astype(int)\n",
    "df['expense'] = df['expense'] * 100\n",
    "df['expense'] = df['expense'].astype(int)\n",
    "df['paymentAmount'] = df['paymentAmount'] * 100\n",
    "df['paymentAmount'] = df['paymentAmount'].astype(int)\n",
    "df['totalPaymentAmount'] = df['totalPaymentAmount'] * 100\n",
    "df['totalPaymentAmount'] = df['totalPaymentAmount'].astype(int)\n",
    "\n",
    "df_s = df.sort_values(by=[\"case_concept_name\", \"time_timestamp\"])\n",
    "df_s = df_s.reset_index(drop=True)\n",
    "\n",
    "gold = pd.read_csv(\"/Users/sulzair/Documents/Bachelor Thesis/dspy_v2/benchmark/PM_EVALQUESTIONS_DF4.csv\")\n",
    "gold['time_timestamp'] = pd.to_datetime(gold['time_timestamp'])\n",
    "gold['time_timestamp_beginn'] = pd.to_datetime(gold['time_timestamp_beginn'])\n",
    "gold['time_timestamp_end'] = pd.to_datetime(gold['time_timestamp_end'])\n",
    "gold['duration'] = pd.to_timedelta(gold['duration'], unit='s')\n",
    "#gold[\"duration\"] = gold[\"duration\"].dt.total_seconds()\n",
    "gold_sorted = gold.sort_values(by=['case_concept_name', 'time_timestamp'])\n",
    "gold_sorted = gold_sorted.reset_index(drop=True)\n",
    "\n",
    "# add any columns from gold which are not present in df_s\n",
    "for col in gold_sorted.columns:\n",
    "    if col not in df_s.columns:\n",
    "        df_s[col] = gold_sorted[col]\n",
    "\n",
    "conn = sqlite3.connect(SQLITE_DB_NAME)\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"DROP TABLE IF EXISTS temp_table;\")\n",
    "print(cur.fetchall())\n",
    "conn.commit()\n",
    "df_s.to_sql(\"event_log\", conn, if_exists=\"replace\", index=False)\n",
    "cur = conn.cursor()\n",
    "indexes = [\n",
    "    \"CREATE INDEX IF NOT EXISTS idx_case_concept_name ON event_log(case_concept_name);\",\n",
    "    \"CREATE INDEX IF NOT EXISTS idx_concept_name ON event_log(concept_name);\",\n",
    "    \"CREATE INDEX IF NOT EXISTS idx_timestamp ON event_log(time_timestamp);\"\n",
    "]\n",
    "for index_query in indexes:\n",
    "    cur.execute(index_query)\n",
    "conn.commit()\n",
    "cur.execute(\"ALTER TABLE event_log ADD COLUMN idx INTEGER;\")\n",
    "conn.commit()\n",
    "cur.execute(\"\"\"UPDATE event_log SET idx = (\n",
    "    SELECT rowid FROM (\n",
    "        SELECT ROW_NUMBER() OVER (ORDER BY case_concept_name, time_timestamp) as seq_num, rowid\n",
    "        FROM event_log\n",
    "    ) temp WHERE temp.rowid = event_log.rowid\n",
    ");\"\"\")\n",
    "conn.commit()\n",
    "cur.execute(\"CREATE INDEX idx_event_log_idx ON event_log(idx);\")\n",
    "conn.commit()\n",
    "cur.execute(\"VACUUM;\")\n",
    "cur.execute(\"ANALYZE;\")\n",
    "conn.commit()\n",
    "cur.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(59.89625590210813,)]\n"
     ]
    }
   ],
   "source": [
    "cur = conn.cursor()\n",
    "\n",
    "query = \"\"\"SELECT \n",
    "    (CAST(COUNT(DISTINCT case_concept_name) FILTER (WHERE underpaid = 1) AS FLOAT) / COUNT(DISTINCT case_concept_name)) * 100 AS percentage_underpaid_cases \n",
    "FROM \n",
    "    event_log;\"\"\"\n",
    "cur.execute(query)\n",
    "lowest_amount = cur.fetchall()\n",
    "print(lowest_amount)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.5 Initiate Chroma Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"- 'amount' (int): The amount due to be paid for the fine (including the penalty amount in case it is added). There are no nan values in this column.\", \"- 'org_resource' (int): A numeric code indicating the employee who handled the case.\", \"- 'dismissal' (string): A flag indicating whether and by whom the fine is dismissed. It is initialized to NIL. We know the meaning of:  \\n        'G': dismissed by the judge\\n        '#': dismissed by the prefecture\\n        NIL: not dismissed, i.e., to be paid.\\n        There are several other values used for which we do not know the semantics.\", \"- 'concept_name' (string): the activity/ event type name\\n    Activity Description, column: 'concept_name':\\n        > 'Create Fine': The initial creation of the fine in the information system. It initializes event log attributes amount, dismissal, points and totalPaymentAmount.\\n        > 'Send Fine': A notification about the fine is sent by post to the offender.\\n        > 'Insert Fine Notification': The notification is received by the offender.\\n        > 'Add penalty': An additional penalty is applied.\\n        > 'Payment': A payment made by the offender is registered.\\n        > 'Send for Credit Collection': Unpaid fines are sent for credit collection. A separate process is started by a collection agency to collect the money of the unpaid fines.\\n        > 'Insert Date Appeal to Prefecture': The offender appeals against the fine to the prefecture. A prefecture in Italy is an administrative body representing the national government in each province.\\n        > 'Send Appeal to Prefecture': The appeal is sent to the prefecture by the local police.\\n        > 'Receive Result Appeal from Prefecture': The local police receives the result of the appeal. If the prefecture dismisses the fine, the appeal is deemed accepted, and the obligation to pay the fine is cancelled. In this case, there is no need for the police to receive the result from the prefecture (Receive Result Appeal from Prefecture) and notify the offender (Notify Result Appeal to Offender).\\n        > 'Notify Result Appeal to Offender': The local police informs the offender of the appeal result. \\n        > 'Appeal to Judge': The offender appeals against the fine to a judge.\\n    IMPORTANT: The last event in a case can be arbitrary. There is no guarantee that the last event is 'Send Fine' or 'Payment'. The last event can be any event in the log.\", \"- 'vehicleClass' (string): A flag indicating the kind of vehicle driven or owned by the offender. The semantics of the values is unknown.\", \"- 'totalPaymentAmount' (int): The cumulative amount paid by the offender. It is always initialized to 0. There are no nan values in this column.\", \"- 'lifecycle_transition' (string): the transition of the activity (complete, start, etc.)\", \"- 'article' (string): The number of the article of the Italian roadtraffic law that is violated by the offender (e.g., article 157 refers to stopping and parking vehicles).\", \"- 'points' (float): Penalty points deducted from the driving license. In Italy, each driver starts with 20 points on their license and may loose points for each offence, based on the gravity.\", \"- 'expense' (int): The additional amount due to be paid for postal expenses. There are no nan values in this column.\", \"- 'notificationType' (string): A flag indicating to whom the fine refers. 'P': car owner, 'C': car driver.\", \"- 'lastSent' (datetime): N/A\", \"- 'paymentAmount' (int): The amount paid by the offender in one transaction. There are no nan values in this column.\", \"- 'matricola' (string): N/A (Probably refers to the matriculation number of the car.)\", \"- 'dismissed_by_prefecture' (int): A boolean indicator (stored as an integer) showing whether the fine was dismissed by the prefecture ('#') across all events of a case. 1 for dismissed by the prefecture, 0 otherwise.\", \"- 'dismissed_by_judge' (int): A boolean indicator (stored as an integer) showing whether the fine was dismissed by a judge ('G') across all events of a case. 1 for dismissed by the judge, 0 otherwise.\", \"- 'maxtotalPaymentAmount' (int): The maximum total payment amount recorded for each case. If all entries are NaN or Null, the value is set to 0. This value is consistent across all rows pertaining to the same case.\", \"- 'duration' (int): The total duration in seconds between the first and last event for each case, consistent across all rows pertaining to the same case.\", \"- 'event_count' (int): The number of events recorded for each case, consistent across all rows pertaining to the same case.\", \"- 'expense_sum' (int): The total sum of 'expense' values for each case, consistent across all rows pertaining to the same case.\", \"- 'amount_min' (int): The minimum non zero and non null 'amount' value recorded for each case, consistent across all rows pertaining to the same case.\", \"- 'amount_last' (int): The maximum 'amount' value recorded for each case, consistent across all rows pertaining to the same case.\", \"- 'dismissed' (int): A boolean indicator (stored as an integer) showing whether the fine was dismissed by either the judge ('G') or the prefecture ('#') across all events of a case. 1 for dismissed, 0 otherwise.\", \"- 'credit_collected' (int): A boolean indicator (stored as an integer) showing whether any event in a case involves sending the fine for credit collection ('Send for Credit Collection'). 1 if any event in the case involves credit collection, 0 otherwise. This value is consistent across all rows pertaining to the same case.\", \"- 'obligation_topay_cancelled' (int): A boolean indicator (stored as an integer) showing whether the obligation to pay the fine is cancelled due to the time difference between 'Create Fine' and 'Send Fine' being more than 90 days. 1 for cancelled, 0 otherwise. This value is consistent across all rows pertaining to the same case.\", \"- 'penalty_added' (int): A boolean indicator (stored as an integer) showing whether any event in a case involves adding a penalty ('Add penalty'). 1 if any event in the case involves adding a penalty, 0 otherwise. This value is consistent across all rows pertaining to the same case.\", \"- 'dismissed_by_other' (int): A boolean indicator (stored as an integer) showing whether any dismissal record in a case does not match the predefined values (NaN, NULL, NIL, G, or #). 1 if there is at least one such record, 0 otherwise. This value is consistent across all rows pertaining to the same case.\", \"- 'appealed_to_judge' (int): A boolean indicator (stored as an integer) showing whether any event in a case involves an appeal to a judge ('Appeal to Judge'). 1 if any event in the case involves an appeal to a judge, 0 otherwise. This value is consistent across all rows pertaining to the same case.\", \"- 'appealed_to_prefecture' (int): A boolean indicator (stored as an integer) showing whether any event in a case involves an appeal to the prefecture ('Insert Date Appeal to Prefecture'). 1 if any event in the case involves an appeal to the prefecture, 0 otherwise. This value is consistent across all rows pertaining to the same case.\", \"- 'appeal_to_judgeorprefecture' (int): A boolean indicator (stored as an integer) showing whether any event in a case involves an appeal to a judge ('Appeal to Judge') or an appeal to the prefecture ('Insert Date Appeal to Prefecture'). 1 if any event in the case involves either, 0 otherwise. This value is consistent across all rows pertaining to the same case.\", \"- 'add_penalty_count' (int): The number of times the event 'Add penalty' occurs for each case, consistent across all rows pertaining to the same case.\", \"- 'send_fine_count' (int): The number of times the event 'Send Fine' occurs for each case, consistent across all rows pertaining to the same case.\", \"- 'payment_count' (int): The number of times the event 'Payment' occurs for each case, consistent across all rows pertaining to the same case.\", \"- 'insert_fine_notification_count' (int): The number of times the event 'Insert Fine Notification' occurs for each case, consistent across all rows pertaining to the same case.\", \"- 'send_for_credit_collection_count' (int): The number of times the event 'Send for Credit Collection' occurs for each case, consistent across all rows pertaining to the same case.\", \"- 'insert_date_appeal_to_prefecture_count' (int): The number of times the event 'Insert Date Appeal to Prefecture' occurs for each case, consistent across all rows pertaining to the same case.\", \"- 'send_appeal_to_prefecture_count' (int): The number of times the event 'Send Appeal to Prefecture' occurs for each case, consistent across all rows pertaining to the same case.\", \"- 'receive_result_appeal_from_prefecture_count' (int): The number of times the event 'Receive Result Appeal from Prefecture' occurs for each case, consistent across all rows pertaining to the same case.\", \"- 'notify_result_appeal_to_offender_count' (int): The number of times the event 'Notify Result Appeal to Offender' occurs for each case, consistent across all rows pertaining to the same case.\", \"- 'appeal_to_judge_count' (int): The number of times the event 'Appeal to Judge' occurs for each case, consistent across all rows pertaining to the same case.\", \"- 'outstanding_balance' (int): The final balance calculated for each case, derived from the last amount due ('amount_last') plus the sum of expenses ('expense_sum') minus the maximum total payment amount ('maxtotalPaymentAmount'). This value is consistent across all rows pertaining to the same case.\", \"- 'credit_collected_AND_dismissed' (int): A boolean indicator (stored as an integer) showing whether any event in a case involves both dismissal of the fine and credit collection. 1 if any event in the case involves both, 0 otherwise. This value is consistent across all rows pertaining to the same case.\", \"- 'paid_nothing' (int): A boolean indicator (stored as an integer) showing whether the maximum total payment amount for each case is zero or less. 1 if the maximum total payment amount is zero or less, 0 otherwise. This value is consistent across all rows pertaining to the same case.\", \"- 'appeal_judge_cancelled' (int): A boolean indicator (stored as an integer) showing whether a case was appealed to a judge and not dismissed by the judge. 1 for cases where the appeal to the judge was not dismissed, 0 otherwise. This value is consistent across all rows pertaining to the same case.\", \"- 'appeal_prefecture_cancelled' (int): A boolean indicator (stored as an integer) showing whether a case was appealed to the prefecture and not dismissed by the prefecture. 1 for cases where the appeal to the prefecture was not dismissed, 0 otherwise. This value is consistent across all rows pertaining to the same case.\", \"- 'fully_paid' (int): A boolean indicator (stored as an integer) showing whether the outstanding balance for each case is zero or less, indicating that the fine has been fully paid. 1 for fully paid, 0 otherwise. This value is consistent across all rows pertaining to the same case.\", \"- 'overpaid' (int): A boolean indicator (stored as an integer) showing whether the outstanding balance for each case is less than zero, indicating that the payment exceeded the amount due. 1 for overpaid, 0 otherwise. This value is consistent across all rows pertaining to the same case.\", \"- 'underpaid' (int): A boolean indicator (stored as an integer) showing whether the outstanding balance for each case is greater than zero, indicating that the fine has not been fully paid. 1 for underpaid, 0 otherwise. This value is consistent across all rows pertaining to the same case.\", \"- 'credit_collected_AND_fully_paid' (int): A boolean indicator (stored as an integer) showing whether any event in a case involves both credit collection ('Send for Credit Collection') and full payment of the fine. 1 if any event in the case involves both, 0 otherwise. This value is consistent across all rows pertaining to the same case.\", \"- 'dismissed_AND_fully_paid' (int): A boolean indicator (stored as an integer) showing whether any event in a case involves both the dismissal of the fine and the full payment of the fine. 1 if any event in the case involves both, 0 otherwise. This value is consistent across all rows pertaining to the same case.\", \"- 'overpaid_amount' (int): The amount by which the payment exceeded the amount due, calculated as the absolute value of the negative 'outstanding_balance' if 'overpaid' is true (1), otherwise set to 0. This value is consistent across all rows pertaining to the same case.\", \"- 'underpaid_amount' (int): The amount still owed if the fine has not been fully paid, equal to the 'outstanding_balance' when 'underpaid' is true (1), otherwise set to 0. This value is consistent across all rows pertaining to the same case.\", \"- 'part_paid' (int): A boolean indicator (stored as an integer) showing whether the fine is partially paid, i.e., not fully paid and not unpaid. It is set to 1 if both 'fully_paid' and 'paid_nothing' are 0, indicating partial payment, and 0 otherwise. This value is consistent across all rows pertaining to the same case.\", \"- 'unresolved' (int): A boolean indicator (stored as an integer) showing whether a case remains unresolved, i.e., not fully paid, not collected for credit, and not dismissed. 1 for unresolved, 0 otherwise. This value is consistent across all rows pertaining to the same case.\", \"- 'paid_without_obligation' (int): A boolean indicator (stored as an integer) showing whether the obligation to pay the fine was cancelled and the fine was fully paid for each case. 1 if both conditions are met, 0 otherwise. This value is consistent across all rows pertaining to the same case.\", \"- 'time_timestamp_beginn' (datetime): The timestamp of the first event for each case, consistent across all rows pertaining to the same case.\", \"- 'time_timestamp_end' (datetime): The timestamp of the last event for each case, consistent across all rows pertaining to the same case.\"]\n",
      "57\n",
      "['amount']\n",
      "['org_resource']\n",
      "['dismissal']\n",
      "['concept_name']\n",
      "['vehicleClass']\n",
      "['totalPaymentAmount']\n",
      "['lifecycle_transition']\n",
      "['article']\n",
      "['points']\n",
      "['expense']\n",
      "['notificationType']\n",
      "['lastSent']\n",
      "['paymentAmount']\n",
      "['matricola']\n",
      "['dismissed_by_prefecture']\n",
      "['dismissed_by_judge']\n",
      "['maxtotalPaymentAmount']\n",
      "['duration']\n",
      "['event_count']\n",
      "['expense_sum']\n",
      "['amount_min']\n",
      "['amount_last']\n",
      "['dismissed']\n",
      "['credit_collected']\n",
      "['obligation_topay_cancelled']\n",
      "['penalty_added']\n",
      "['dismissed_by_other']\n",
      "['appealed_to_judge']\n",
      "['appealed_to_prefecture']\n",
      "['appeal_to_judgeorprefecture']\n",
      "['add_penalty_count']\n",
      "['send_fine_count']\n",
      "['payment_count']\n",
      "['insert_fine_notification_count']\n",
      "['send_for_credit_collection_count']\n",
      "['insert_date_appeal_to_prefecture_count']\n",
      "['send_appeal_to_prefecture_count']\n",
      "['receive_result_appeal_from_prefecture_count']\n",
      "['notify_result_appeal_to_offender_count']\n",
      "['appeal_to_judge_count']\n",
      "['outstanding_balance']\n",
      "['credit_collected_AND_dismissed']\n",
      "['paid_nothing']\n",
      "['appeal_judge_cancelled']\n",
      "['appeal_prefecture_cancelled']\n",
      "['fully_paid']\n",
      "['overpaid']\n",
      "['underpaid']\n",
      "['credit_collected_AND_fully_paid']\n",
      "['dismissed_AND_fully_paid']\n",
      "['overpaid_amount']\n",
      "['underpaid_amount']\n",
      "['part_paid']\n",
      "['unresolved']\n",
      "['paid_without_obligation']\n",
      "['time_timestamp_beginn']\n",
      "['time_timestamp_end']\n"
     ]
    }
   ],
   "source": [
    "rm = Chroma(sentence_transformer_ef) # for python, use standard cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE DATABASE CONTAINS THE TABLE: event_log CONTAINING THE FOLLOWING COLUMNS (only the ones denoted by a \"-\", )\n",
      "- 'case_concept_name' (string): the case identifier, use this to group by cases (retrieve information about cases as a whole)\n",
      "- 'time_timestamp' (datetime): the timestamp of the activity.\n",
      "- 'event_count' (int): The number of events recorded for each case, consistent across all rows pertaining to the same case.\n",
      "- 'notify_result_appeal_to_offender_count' (int): The number of times the event 'Notify Result Appeal to Offender' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'insert_fine_notification_count' (int): The number of times the event 'Insert Fine Notification' occurs for each case, consistent across all rows pertaining to the same case.\n"
     ]
    }
   ],
   "source": [
    "question= \"\"\"How many cases are present in the event log?\"\"\"\n",
    "\n",
    "test_retrieval = rm.retrieve(question, num= 3)# to low for one of the questions, concept_name does not appear in the top 6\n",
    "print(test_retrieval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Initialize Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2 PM_SQL_sp_reasoning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "##MULTI THREAD VERSION AND Better deepcopy\n",
    "\n",
    "class CodeOutput(BaseModel):\n",
    "    sql : str\n",
    "\n",
    "class ReasoningOutput(BaseModel):\n",
    "    approach : str\n",
    "\n",
    "class SQL_format(dspy.Signature):\n",
    "    \"\"\"Generate a single SQLite query that returns the specific information requested in the question \n",
    "    and include relevant details such as duration or amount. When asked about information pertaining \n",
    "    to cases (not events), group by case to avoid counting the same case multiple times. Aggregate when necessary,\n",
    "    using subqueries and outer queries to limit the output size and results in a table that answers the question directly.\n",
    "    Be aware to make a distinction between questions that ask about cases and question that ask about events, since some of the available columns are aggregated over cases and might lead to wrong results when used in the wrong context.\"\"\"\n",
    "\n",
    "    question = dspy.InputField()\n",
    "    column_description = dspy.InputField(desc=\"Information about the database and its tables\")\n",
    "    approach = dspy.InputField(desc= \"Suggested approach to generate the query\")\n",
    "    sqlite_query: CodeOutput = dspy.OutputField()\n",
    "\n",
    "\n",
    "class Reasoning(dspy.Signature):\n",
    "    \"\"\"Objective: Develop a strategy and logic to create a single SQLite query that will answer a given question.\n",
    "    Database Information: Use the details about the database and its columns to guide your approach. \n",
    "    Be specific about whether the question pertains to \"cases\" or \"events,\" since every row is an event, and multiple events can be part of a single case.\n",
    "    Column Details: Some columns contain the same information for each event (row) per case (referred to as \"case predicate\"). Other columns are independent of cases and refer to events directly.\n",
    "    You can determine this, based on whether the column description mentions that all values are the same for a case or if the column is aggregated over a case.\n",
    "    Grouping: When asked about questions independent of cases and you are using a column that is a case predicate, group by case to avoid counting an aggregated value multiple times.\n",
    "    Do not forget about this for percentage calculations as well (using something like (DISTINCT case_concept_name) FILTER (WHERE col = 1) instead of not grouping by case first for case predicates).\n",
    "    Query Construction: Do not write the actual query. Instead, provide a detailed explanation of how to construct the query.\n",
    "    Aggregation: Aggregate data when necessary. Use subqueries and outer queries to limit the output size. Ensure the final result is a table that directly answers the question.\n",
    "    Some questions might have multiple valid anwers(i.e finding case with highest value x, might have mutliple cases with the same highest value), be aware of this and consider LIMIT 10 instead of LIMIT 1 in such cases.\n",
    "    \"\"\"\n",
    "\n",
    "    # some questions might have multiple valid anwers(i.e finding case with highest value x, might have mutliple cases with the same highest value)\n",
    "    question = dspy.InputField()\n",
    "    column_description = dspy.InputField(desc=\"Information about the database and its tables\")\n",
    "    reasoning: ReasoningOutput = dspy.OutputField()\n",
    "\n",
    "\n",
    "\n",
    "class Answering(dspy.Signature):\n",
    "    \"\"\"Carefully analyze the question and information in the table to form a helpful response. Use all the columns from the table (information) when writing your answer (don't leave away any additional information).\"\"\"\n",
    "    question = dspy.InputField()\n",
    "    table = dspy.InputField(desc=\"Pipe deliniated string representing a table.\")\n",
    "    sql = dspy.InputField(desc=\"SQL query that was executed to generate the table.\")\n",
    "    answer = dspy.OutputField(desc=\"Only write the answer, not question or table)\")  \n",
    "\n",
    "class PM_SQL_multi_sp(dspy.Module):\n",
    "\n",
    "    def __init__(self, pool, rm=rm, max_length = 1500):\n",
    "        super().__init__()\n",
    "\n",
    "        self.pool = pool\n",
    "        self.max_length = max_length\n",
    "        self.generated_query = dspy.Predict(SQL_format)\n",
    "        self.reasoning = dspy.Predict(Reasoning)\n",
    "        self.ans = dspy.Predict(Answering)\n",
    "        self.queries = defaultdict(list)\n",
    "        self.errors = defaultdict(list)\n",
    "        self.table = defaultdict(list)\n",
    "        self.rm = rm\n",
    "        \n",
    "    def forward(self, question):\n",
    "        error_hist = \"\"\n",
    "        self.column_description = self.rm.retrieve(question, num= 9)# to low for one of the questions, concept_name does not appear in the top 6\n",
    "        temp_query_hist = []\n",
    "        try:\n",
    "            reasoning = self.reasoning(question = question, column_description = self.column_description)\n",
    "        except Exception as e:\n",
    "            self.errors[question].append(str(e))\n",
    "            reasoning = \"Error generating reasoning: \" + str(e)\n",
    "            return self.ans(question = question, table = reasoning, sql= \"Error generating reasoning\")\n",
    "        dspy.Suggest(\n",
    "            len(reasoning.reasoning.approach) <= 1400, # change to 1400\n",
    "            \"Your reasoning should be fewer than 1400 characters long\",\n",
    "        )\n",
    "\n",
    "\n",
    "        try:\n",
    "            result = self.generated_query(question = question, column_description = self.column_description, approach = reasoning.reasoning.approach)\n",
    "        except Exception as e:\n",
    "            self.errors[question].append(str(e))\n",
    "            result = \"Error executing query: \" + str(e)\n",
    "            return self.ans(question = question, table = result, sql= \"Error executing query\")\n",
    "        \n",
    "        query = result.sqlite_query.sql\n",
    "        temp_query_hist.append(query)\n",
    "        self.queries[question].append(query)\n",
    "        conn = self.pool.get_connection() # insted of self.conn.cursor()\n",
    "        cur = conn.cursor()\n",
    "        result = \"\"\n",
    "        #print(f\"From SQL: Query that will be executed: {query}\")\n",
    "        cause_error = True\n",
    "        dspy.Suggest(\n",
    "            bool(query in temp_query_hist),\n",
    "            \"Query should be distinct from previous queries that resulted in syntax errors: \"+ \"; \".join(f\"{i+1}) {q}\" for i, q in enumerate(temp_query_hist)),\n",
    "        )\n",
    "        error_code_fail = \"\"\n",
    "        try:\n",
    "            cur.execute(query)\n",
    "            \n",
    "        except Exception as e:\n",
    "            cause_error = False\n",
    "            error_code_fail = str(e)\n",
    "            cur.close()\n",
    "            self.pool.release_connection(conn)\n",
    "            self.errors[question].append(str(e))\n",
    "            #print(\"Query generator doing error handling\")\n",
    "            \n",
    "        dspy.Suggest(\n",
    "            cause_error,\n",
    "            \"Error executing SQLite query \" + error_code_fail,\n",
    "        )\n",
    "        if len(temp_query_hist) > 3:\n",
    "            try:\n",
    "                pred = self.ans(question = question, table = \"Error executing query: \" + str(e), sql = query)\n",
    "                return pred\n",
    "            except Exception as e:\n",
    "                self.errors[question].append(str(e))\n",
    "                #print(f\"From SQL: number of errors: {len(self.errors[question])}\")\n",
    "                return self.ans(question = question, table = \"There was an error during the answering of the question due to the following error: \" + str(e), sql = query)\n",
    "\n",
    "        column_names = [description[0] for description in cur.description]\n",
    "        header = \"|\".join(column_names)\n",
    "        # Initialize result with the header and account for its length.\n",
    "        result = header\n",
    "        current_length = len(result)\n",
    "        for row in cur.fetchall():\n",
    "            row_data = \" | \".join([str(cell) for cell in row])\n",
    "            if current_length + len(row_data) + 1 > self.max_length:\n",
    "                break  # Keep within the max_length limit.\n",
    "            result += \" \\n\" + row_data\n",
    "            current_length += len(row_data) + 1\n",
    "        self.table[question].append(result)\n",
    "        cur.close()\n",
    "        self.pool.release_connection(conn)\n",
    "        \n",
    "        try: \n",
    "            pred = self.ans(question = question, table = result, sql = query)\n",
    "        except Exception as e:\n",
    "            self.errors[question].append(str(e))\n",
    "            try:\n",
    "                pred = self.ans(question = question, table = result, sql = query)\n",
    "            except Exception as e:\n",
    "                self.errors[question].append(str(e))\n",
    "                #print(f\"From SQL: number of errors: {len(self.errors[question])}\")\n",
    "                return self.ans(question = question, table = \"There was an error during the answering of the question due to the following error: \" + str(e), sql = query)\n",
    "        \n",
    "        #print(f\"From SQL: number of errors: {len(self.errors[question])}\")\n",
    "        #print(f\"From SQL: result: {pred.answer}, type: {type(pred.answer)}\")\n",
    "        return pred\n",
    "    def __deepcopy__(self, memo):\n",
    "\n",
    "        # Create a new instance of the class\n",
    "        cls = self.__class__\n",
    "        result = cls.__new__(cls)\n",
    "\n",
    "        # Copy all attributes except for 'conn'\n",
    "        memo[id(self)] = result\n",
    "        for k, v in self.__dict__.items():\n",
    "            if k == 'pool':\n",
    "                setattr(result, k, None)  # or reinitialize the connection if needed\n",
    "            elif k == 'rm':\n",
    "                setattr(result, k, None)\n",
    "            else:\n",
    "                try:\n",
    "                    setattr(result, k, copy.deepcopy(v, memo))\n",
    "                except Exception as e:\n",
    "                    print(\"k\", k)\n",
    "                    print(\"type of k\", type(k))\n",
    "                    print(\"v\", v)\n",
    "                    print(\"type of v\", type(v))\n",
    "        \n",
    "        # Optionally, reinitialize the connection if needed\n",
    "        \n",
    "        result.pool = self.pool\n",
    "        result.rm = self.rm\n",
    "        \n",
    "        return result\n",
    "    \n",
    "\n",
    "    def get_history(self):\n",
    "        return self.queries, self.errors, self.table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "adjusted version without pydantic class (for the mipro optimizer) & increase the resoning length from 1400 characters to something like 5k characters. The reason for this was to alleviate the issue of just recounding the column descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "##MULTI THREAD VERSION AND Better deepcopy\n",
    "\n",
    "class CodeOutput(BaseModel):\n",
    "    sql : str\n",
    "\n",
    "class ReasoningOutput(BaseModel):\n",
    "    approach : str\n",
    "\n",
    "class SQL_format(dspy.Signature):\n",
    "    \"\"\"Generate a single SQLite query that returns the specific information requested in the question \n",
    "    and include relevant details such as duration or amount. When asked about information pertaining \n",
    "    to cases (not events), group by case to avoid counting the same case multiple times. Aggregate when necessary,\n",
    "    using subqueries and outer queries to limit the output size and results in a table that answers the question directly.\n",
    "    Be aware to make a distinction between questions that ask about cases and question that ask about events, since some of the available columns are aggregated over cases and might lead to wrong results when used in the wrong context.\"\"\"\n",
    "\n",
    "    question = dspy.InputField()\n",
    "    column_description = dspy.InputField(desc=\"Information about the database and its tables\")\n",
    "    approach = dspy.InputField(desc= \"Suggested approach to generate the query\")\n",
    "    sqlite_query = dspy.OutputField()\n",
    "\n",
    "\n",
    "class Reasoning(dspy.Signature):\n",
    "    \"\"\"Objective: Develop a strategy and logic to create a single SQLite query that will answer a given question.\n",
    "    Database Information: Use the details about the database and its columns to guide your approach. \n",
    "    Be specific about whether the question pertains to \"cases\" or \"events,\" since every row is an event, and multiple events can be part of a single case.\n",
    "    Column Details: Some columns contain the same information for each event (row) per case (referred to as \"case predicate\"). Other columns are independent of cases and refer to events directly.\n",
    "    You can determine this, based on whether the column description mentions that all values are the same for a case or if the column is aggregated over a case.\n",
    "    Grouping: When asked about questions independent of cases and you are using a column that is a case predicate, group by case to avoid counting an aggregated value multiple times.\n",
    "    Do not forget about this for percentage calculations as well (using something like (DISTINCT case_concept_name) FILTER (WHERE col = 1) instead of not grouping by case first for case predicates).\n",
    "    Query Construction: Do not write the actual query. Instead, provide a detailed explanation of how to construct the query.\n",
    "    Aggregation: Aggregate data when necessary. Use subqueries and outer queries to limit the output size. Ensure the final result is a table that directly answers the question.\n",
    "    Some questions might have multiple valid anwers(i.e finding case with highest value x, might have mutliple cases with the same highest value), be aware of this and consider LIMIT 10 instead of LIMIT 1 in such cases.\n",
    "    \"\"\"\n",
    "\n",
    "    # some questions might have multiple valid anwers(i.e finding case with highest value x, might have mutliple cases with the same highest value)\n",
    "    question = dspy.InputField()\n",
    "    column_description = dspy.InputField(desc=\"Information about the database and its tables\")\n",
    "    reasoning = dspy.OutputField()\n",
    "\n",
    "\n",
    "\n",
    "class Answering(dspy.Signature):\n",
    "    \"\"\"Carefully analyze the question and information in the table to form a helpful response. Use all the columns from the table (information) when writing your answer (don't leave away any additional information).\"\"\"\n",
    "    question = dspy.InputField()\n",
    "    table = dspy.InputField(desc=\"Pipe deliniated string representing a table.\")\n",
    "    sql = dspy.InputField(desc=\"SQL query that was executed to generate the table.\")\n",
    "    answer = dspy.OutputField(desc=\"Only write the answer, not question or table)\")  \n",
    "\n",
    "class PM_SQL_mipro(dspy.Module):\n",
    "\n",
    "    def __init__(self, pool, rm=rm, max_length = 1500):\n",
    "        super().__init__()\n",
    "\n",
    "        self.pool = pool\n",
    "        self.max_length = max_length\n",
    "        self.generated_query = dspy.Predict(SQL_format)\n",
    "        self.reasoning = dspy.Predict(Reasoning)\n",
    "        self.ans = dspy.Predict(Answering)\n",
    "        self.queries = defaultdict(list)\n",
    "        self.errors = defaultdict(list)\n",
    "        self.table = defaultdict(list)\n",
    "        self.rm = rm\n",
    "        \n",
    "    def forward(self, question):\n",
    "        error_hist = \"\"\n",
    "        self.column_description = self.rm.retrieve(question, num= 9)# to low for one of the questions, concept_name does not appear in the top 6\n",
    "        temp_query_hist = []\n",
    "        try:\n",
    "            reasoning = self.reasoning(question = question, column_description = self.column_description)\n",
    "        except Exception as e:\n",
    "            self.errors[question].append(str(e))\n",
    "            reasoning = \"Error generating reasoning: \" + str(e)\n",
    "            return self.ans(question = question, table = reasoning, sql= \"Error generating reasoning\")\n",
    "        dspy.Suggest(\n",
    "            len(reasoning.reasoning) <= 2400, # change to 1400\n",
    "            \"Your reasoning should be fewer than 1400 characters long\",\n",
    "        )\n",
    "\n",
    "\n",
    "        try:\n",
    "            result = self.generated_query(question = question, column_description = self.column_description, approach = reasoning.reasoning)\n",
    "        except Exception as e:\n",
    "            self.errors[question].append(str(e))\n",
    "            result = \"Error executing query: \" + str(e)\n",
    "            return self.ans(question = question, table = result, sql= \"Error executing query\")\n",
    "        \n",
    "        query = result.sqlite_query\n",
    "        temp_query_hist.append(query)\n",
    "        self.queries[question].append(query)\n",
    "        conn = self.pool.get_connection() # insted of self.conn.cursor()\n",
    "        cur = conn.cursor()\n",
    "        result = \"\"\n",
    "        #print(f\"From SQL: Query that will be executed: {query}\")\n",
    "        cause_error = True\n",
    "        dspy.Suggest(\n",
    "            bool(query in temp_query_hist),\n",
    "            \"Query should be distinct from previous queries that resulted in syntax errors: \"+ \"; \".join(f\"{i+1}) {q}\" for i, q in enumerate(temp_query_hist)),\n",
    "        )\n",
    "        error_code_fail = \"\"\n",
    "        try:\n",
    "            cur.execute(query)\n",
    "            \n",
    "        except Exception as e:\n",
    "            cause_error = False\n",
    "            error_code_fail = str(e)\n",
    "            cur.close()\n",
    "            self.pool.release_connection(conn)\n",
    "            self.errors[question].append(str(e))\n",
    "            #print(\"Query generator doing error handling\")\n",
    "            \n",
    "        dspy.Suggest(\n",
    "            cause_error,\n",
    "            \"Error executing SQLite query \" + error_code_fail,\n",
    "        )\n",
    "        if len(temp_query_hist) > 3:\n",
    "            try:\n",
    "                pred = self.ans(question = question, table = \"Error executing query: \" + str(e), sql = query)\n",
    "                return pred\n",
    "            except Exception as e:\n",
    "                self.errors[question].append(str(e))\n",
    "                #print(f\"From SQL: number of errors: {len(self.errors[question])}\")\n",
    "                return self.ans(question = question, table = \"There was an error during the answering of the question due to the following error: \" + str(e), sql = query)\n",
    "\n",
    "        column_names = [description[0] for description in cur.description]\n",
    "        header = \"|\".join(column_names)\n",
    "        # Initialize result with the header and account for its length.\n",
    "        result = header\n",
    "        current_length = len(result)\n",
    "        for row in cur.fetchall():\n",
    "            row_data = \" | \".join([str(cell) for cell in row])\n",
    "            if current_length + len(row_data) + 1 > self.max_length:\n",
    "                break  # Keep within the max_length limit.\n",
    "            result += \" \\n\" + row_data\n",
    "            current_length += len(row_data) + 1\n",
    "        self.table[question].append(result)\n",
    "        cur.close()\n",
    "        self.pool.release_connection(conn)\n",
    "        \n",
    "        try: \n",
    "            pred = self.ans(question = question, table = result, sql = query)\n",
    "        except Exception as e:\n",
    "            self.errors[question].append(str(e))\n",
    "            try:\n",
    "                pred = self.ans(question = question, table = result, sql = query)\n",
    "            except Exception as e:\n",
    "                self.errors[question].append(str(e))\n",
    "                #print(f\"From SQL: number of errors: {len(self.errors[question])}\")\n",
    "                return self.ans(question = question, table = \"There was an error during the answering of the question due to the following error: \" + str(e), sql = query)\n",
    "        \n",
    "        #print(f\"From SQL: number of errors: {len(self.errors[question])}\")\n",
    "        #print(f\"From SQL: result: {pred.answer}, type: {type(pred.answer)}\")\n",
    "        return pred\n",
    "    def __deepcopy__(self, memo):\n",
    "\n",
    "        # Create a new instance of the class\n",
    "        cls = self.__class__\n",
    "        result = cls.__new__(cls)\n",
    "\n",
    "        # Copy all attributes except for 'conn'\n",
    "        memo[id(self)] = result\n",
    "        for k, v in self.__dict__.items():\n",
    "            if k == 'pool':\n",
    "                setattr(result, k, None)  # or reinitialize the connection if needed\n",
    "            elif k == 'rm':\n",
    "                setattr(result, k, None)\n",
    "            else:\n",
    "                try:\n",
    "                    setattr(result, k, copy.deepcopy(v, memo))\n",
    "                except Exception as e:\n",
    "                    print(\"k\", k)\n",
    "                    print(\"type of k\", type(k))\n",
    "                    print(\"v\", v)\n",
    "                    print(\"type of v\", type(v))\n",
    "        \n",
    "        # Optionally, reinitialize the connection if needed\n",
    "        \n",
    "        result.pool = self.pool\n",
    "        result.rm = self.rm\n",
    "        \n",
    "        return result\n",
    "    \n",
    "\n",
    "    def get_history(self):\n",
    "        return self.queries, self.errors, self.table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.3 PM_SQL_no_reasoning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "##MULTI THREAD VERSION AND Better deepcopy\n",
    "\n",
    "class CodeOutput(BaseModel):\n",
    "    sql : str\n",
    "\n",
    "class SQL_format(dspy.Signature):\n",
    "    \"\"\"Generate a single SQLite query that returns the specific information requested in the question \n",
    "    and include relevant details such as duration or amount. When asked about information pertaining \n",
    "    to cases (not events), group by case to avoid counting the same case multiple times. Aggregate when necessary,\n",
    "    using subqueries and outer queries to limit the output size and results in a table that answers the question directly.\n",
    "    Be aware to make a distinction between questions that ask about cases and question that ask about events, since some of the available columns are aggregated over cases and might lead to wrong results when used in the wrong context.\"\"\"\n",
    "\n",
    "    column_description = dspy.InputField(desc=\"Information about the database and its tables\")\n",
    "    question = dspy.InputField()\n",
    "    SQLite_query: CodeOutput = dspy.OutputField()\n",
    "\n",
    "\n",
    "\n",
    "class Answering(dspy.Signature):\n",
    "    \"\"\"Carefully analyze the question and information in the table to form a helpful response. Use all the columns from the table (information) when writing your answer (don't leave away any additional information).\"\"\"\n",
    "    question = dspy.InputField()\n",
    "    table = dspy.InputField(desc=\"Pipe deliniated string representing a table.\")\n",
    "    sql = dspy.InputField(desc=\"SQL query that was executed to generate the table.\")\n",
    "    answer = dspy.OutputField(desc=\"Only write the answer, not question or table)\")  \n",
    "\n",
    "class PM_SQL_multi_nr(dspy.Module):\n",
    "\n",
    "    def __init__(self, pool, rm=rm, max_length = 1500):\n",
    "        super().__init__()\n",
    "\n",
    "        self.pool = pool\n",
    "        self.max_length = max_length\n",
    "        self.generated_query = dspy.Predict(SQL_format)\n",
    "        self.ans = dspy.Predict(Answering)\n",
    "        self.queries = defaultdict(list)\n",
    "        self.errors = defaultdict(list)\n",
    "        self.table = defaultdict(list)\n",
    "        self.rm = rm\n",
    "        \n",
    "    def forward(self, question):\n",
    "        error_hist = \"\"\n",
    "        self.column_description = self.rm.retrieve(question, num= 9)\n",
    "        temp_query_hist = []\n",
    "        try:\n",
    "            result = self.generated_query(question = question, column_description = self.column_description)\n",
    "        except Exception as e:\n",
    "            self.errors[question].append(str(e))\n",
    "            result = \"Error executing query: \" + str(e)\n",
    "            return self.ans(question = question, table = result, sql= \"Error executing query\")\n",
    "        \n",
    "        query = result.SQLite_query.sql\n",
    "        temp_query_hist.append(query)\n",
    "        self.queries[question].append(query)\n",
    "        conn = self.pool.get_connection() # insted of self.conn.cursor()\n",
    "        cur = conn.cursor()\n",
    "        result = \"\"\n",
    "        #print(f\"From SQL: Query that will be executed: {query}\")\n",
    "        cause_error = True\n",
    "        dspy.Suggest(\n",
    "            bool(query in temp_query_hist),\n",
    "            \"Query should be distinct from previous queries that resulted in syntax errors: \"+ \"; \".join(f\"{i+1}) {q}\" for i, q in enumerate(temp_query_hist)),\n",
    "        )\n",
    "        error_code_fail = \"\"\n",
    "        try:\n",
    "            cur.execute(query)\n",
    "            \n",
    "        except Exception as e:\n",
    "            cause_error = False\n",
    "            error_code_fail = str(e)\n",
    "            cur.close()\n",
    "            self.pool.release_connection(conn)\n",
    "            self.errors[question].append(str(e))\n",
    "            print(\"Query generator doing error handling\")\n",
    "            \n",
    "        dspy.Suggest(\n",
    "            cause_error,\n",
    "            \"Error executing SQLite query \" + error_code_fail,\n",
    "        )\n",
    "        if len(temp_query_hist) > 3:\n",
    "            try:\n",
    "                pred = self.ans(question = question, table = \"Error executing query: \" + str(e), sql = query)\n",
    "                return pred\n",
    "            except Exception as e:\n",
    "                self.errors[question].append(str(e))\n",
    "                print(f\"From SQL: number of errors: {len(self.errors[question])}\")\n",
    "                return self.ans(question = question, table = \"There was an error during the answering of the question due to the following error: \" + str(e), sql = query)\n",
    "\n",
    "        column_names = [description[0] for description in cur.description]\n",
    "        header = \"|\".join(column_names)\n",
    "        # Initialize result with the header and account for its length.\n",
    "        result = header\n",
    "        current_length = len(result)\n",
    "        for row in cur.fetchall():\n",
    "            row_data = \" | \".join([str(cell) for cell in row])\n",
    "            if current_length + len(row_data) + 1 > self.max_length:\n",
    "                break  # Keep within the max_length limit.\n",
    "            result += \" \\n\" + row_data\n",
    "            current_length += len(row_data) + 1\n",
    "        self.table[question].append(result)\n",
    "        cur.close()\n",
    "        self.pool.release_connection(conn)\n",
    "        \n",
    "        try: \n",
    "            pred = self.ans(question = question, table = result, sql = query)\n",
    "        except Exception as e:\n",
    "            self.errors[question].append(str(e))\n",
    "            try:\n",
    "                pred = self.ans(question = question, table = result, sql = query)\n",
    "            except Exception as e:\n",
    "                self.errors[question].append(str(e))\n",
    "                print(f\"From SQL: number of errors: {len(self.errors[question])}\")\n",
    "                return self.ans(question = question, table = \"There was an error during the answering of the question due to the following error: \" + str(e), sql = query)\n",
    "        \n",
    "        #print(f\"From SQL: number of errors: {len(self.errors[question])}\")\n",
    "        #print(f\"From SQL: result: {pred.answer}, type: {type(pred.answer)}\")\n",
    "        return pred\n",
    "    def __deepcopy__(self, memo):\n",
    "\n",
    "        # Create a new instance of the class\n",
    "        cls = self.__class__\n",
    "        result = cls.__new__(cls)\n",
    "\n",
    "        # Copy all attributes except for 'conn'\n",
    "        memo[id(self)] = result\n",
    "        for k, v in self.__dict__.items():\n",
    "            if k == 'pool':\n",
    "                setattr(result, k, None)  # or reinitialize the connection if needed\n",
    "            elif k == 'rm':\n",
    "                setattr(result, k, None)\n",
    "            else:\n",
    "                try:\n",
    "                    setattr(result, k, copy.deepcopy(v, memo))\n",
    "                except Exception as e:\n",
    "                    print(\"k\", k)\n",
    "                    print(\"type of k\", type(k))\n",
    "                    print(\"v\", v)\n",
    "                    print(\"type of v\", type(v))\n",
    "        \n",
    "        # Optionally, reinitialize the connection if needed\n",
    "        \n",
    "        result.pool = self.pool\n",
    "        result.rm = self.rm\n",
    "        \n",
    "        return result\n",
    "    \n",
    "\n",
    "    def get_history(self):\n",
    "        return self.queries, self.errors, self.table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.4 PM_SQL_COI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "##MULTI THREAD VERSION AND Better deepcopy\n",
    "\n",
    "class CodeOutput(BaseModel):\n",
    "    sql : str\n",
    "\n",
    "class SQL_format(dspy.Signature):\n",
    "    \"\"\"Generate a single SQLite query that returns the specific information requested in the question \n",
    "    and include relevant details such as duration or amount. When asked about information pertaining \n",
    "    to cases (not events), group by case to avoid counting the same case multiple times. Aggregate when necessary,\n",
    "    using subqueries and outer queries to limit the output size and results in a table that answers the question directly.\n",
    "    Be aware to make a distinction between questions that ask about cases and question that ask about events, since some of the available columns are aggregated over cases and might lead to wrong results when used in the wrong context.\"\"\"\n",
    "\n",
    "    column_description = dspy.InputField(desc=\"Information about the database and its tables\")\n",
    "    question = dspy.InputField()\n",
    "    SQLite_query: CodeOutput = dspy.OutputField()\n",
    "\n",
    "\n",
    "\n",
    "class Answering(dspy.Signature):\n",
    "    \"\"\"Carefully analyze the question and information in the table to form a helpful response. Use all the columns from the table (information) when writing your answer (don't leave away any additional information).\"\"\"\n",
    "    question = dspy.InputField()\n",
    "    table = dspy.InputField(desc=\"Pipe deliniated string representing a table.\")\n",
    "    sql = dspy.InputField(desc=\"SQL query that was executed to generate the table.\")\n",
    "    answer = dspy.OutputField(desc=\"Only write the answer, not question or table)\")  \n",
    "\n",
    "class PM_SQL_multi_COI(dspy.Module):\n",
    "\n",
    "    def __init__(self, pool, rm=rm, max_length = 1500):\n",
    "        super().__init__()\n",
    "\n",
    "        self.pool = pool\n",
    "        self.max_length = max_length\n",
    "        self.generated_query = dspy.ChainOfThought(SQL_format)\n",
    "        self.ans = dspy.Predict(Answering)\n",
    "        self.queries = defaultdict(list)\n",
    "        self.errors = defaultdict(list)\n",
    "        self.table = defaultdict(list)\n",
    "        self.rm = rm\n",
    "        \n",
    "    def forward(self, question):\n",
    "        error_hist = \"\"\n",
    "        self.column_description = self.rm.retrieve(question, num= 9)\n",
    "        temp_query_hist = []\n",
    "        try:\n",
    "            result = self.generated_query(question = question, column_description = self.column_description)\n",
    "        except Exception as e:\n",
    "            self.errors[question].append(str(e))\n",
    "            result = \"Error executing query: \" + str(e)\n",
    "            return self.ans(question = question, table = result, sql= \"Error executing query\")\n",
    "        \n",
    "        query = result.SQLite_query.sql\n",
    "        temp_query_hist.append(query)\n",
    "        self.queries[question].append(query)\n",
    "        conn = self.pool.get_connection() # insted of self.conn.cursor()\n",
    "        cur = conn.cursor()\n",
    "        result = \"\"\n",
    "        #print(f\"From SQL: Query that will be executed: {query}\")\n",
    "        cause_error = True\n",
    "        dspy.Suggest(\n",
    "            bool(query in temp_query_hist),\n",
    "            \"Query should be distinct from previous queries that resulted in syntax errors: \"+ \"; \".join(f\"{i+1}) {q}\" for i, q in enumerate(temp_query_hist)),\n",
    "        )\n",
    "        error_code_fail = \"\"\n",
    "        try:\n",
    "            cur.execute(query)\n",
    "            \n",
    "        except Exception as e:\n",
    "            cause_error = False\n",
    "            error_code_fail = str(e)\n",
    "            cur.close()\n",
    "            self.pool.release_connection(conn)\n",
    "            self.errors[question].append(str(e))\n",
    "            print(\"Query generator doing error handling\")\n",
    "            \n",
    "        dspy.Suggest(\n",
    "            cause_error,\n",
    "            \"Error executing SQLite query \" + error_code_fail,\n",
    "        )\n",
    "        if len(temp_query_hist) > 3:\n",
    "            try:\n",
    "                pred = self.ans(question = question, table = \"Error executing query: \" + str(e), sql = query)\n",
    "                return pred\n",
    "            except Exception as e:\n",
    "                self.errors[question].append(str(e))\n",
    "                print(f\"From SQL: number of errors: {len(self.errors[question])}\")\n",
    "                return self.ans(question = question, table = \"There was an error during the answering of the question due to the following error: \" + str(e), sql = query)\n",
    "\n",
    "        column_names = [description[0] for description in cur.description]\n",
    "        header = \"|\".join(column_names)\n",
    "        # Initialize result with the header and account for its length.\n",
    "        result = header\n",
    "        current_length = len(result)\n",
    "        for row in cur.fetchall():\n",
    "            row_data = \" | \".join([str(cell) for cell in row])\n",
    "            if current_length + len(row_data) + 1 > self.max_length:\n",
    "                break  # Keep within the max_length limit.\n",
    "            result += \" \\n\" + row_data\n",
    "            current_length += len(row_data) + 1\n",
    "        self.table[question].append(result)\n",
    "        cur.close()\n",
    "        self.pool.release_connection(conn)\n",
    "        \n",
    "        try: \n",
    "            pred = self.ans(question = question, table = result, sql = query)\n",
    "        except Exception as e:\n",
    "            self.errors[question].append(str(e))\n",
    "            try:\n",
    "                pred = self.ans(question = question, table = result, sql = query)\n",
    "            except Exception as e:\n",
    "                self.errors[question].append(str(e))\n",
    "                print(f\"From SQL: number of errors: {len(self.errors[question])}\")\n",
    "                return self.ans(question = question, table = \"There was an error during the answering of the question due to the following error: \" + str(e), sql = query)\n",
    "        \n",
    "        #print(f\"From SQL: number of errors: {len(self.errors[question])}\")\n",
    "        #print(f\"From SQL: result: {pred.answer}, type: {type(pred.answer)}\")\n",
    "        return pred\n",
    "    def __deepcopy__(self, memo):\n",
    "\n",
    "        # Create a new instance of the class\n",
    "        cls = self.__class__\n",
    "        result = cls.__new__(cls)\n",
    "\n",
    "        # Copy all attributes except for 'conn'\n",
    "        memo[id(self)] = result\n",
    "        for k, v in self.__dict__.items():\n",
    "            if k == 'pool':\n",
    "                setattr(result, k, None)  # or reinitialize the connection if needed\n",
    "            elif k == 'rm':\n",
    "                setattr(result, k, None)\n",
    "            else:\n",
    "                try:\n",
    "                    setattr(result, k, copy.deepcopy(v, memo))\n",
    "                except Exception as e:\n",
    "                    print(\"k\", k)\n",
    "                    print(\"type of k\", type(k))\n",
    "                    print(\"v\", v)\n",
    "                    print(\"type of v\", type(v))\n",
    "        \n",
    "        # Optionally, reinitialize the connection if needed\n",
    "        \n",
    "        result.pool = self.pool\n",
    "        result.rm = self.rm\n",
    "        \n",
    "        return result\n",
    "    \n",
    "\n",
    "    def get_history(self):\n",
    "        return self.queries, self.errors, self.table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simplest Program (no reasoning, no prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "##MULTI THREAD VERSION AND Better deepcopy\n",
    "\n",
    "class PM_SQL_multi_simple(dspy.Module):\n",
    "\n",
    "    def __init__(self, pool, rm=rm, max_length = 1500):\n",
    "        super().__init__()\n",
    "\n",
    "        self.pool = pool\n",
    "        self.max_length = max_length\n",
    "        self.generated_query = dspy.Predict('column_description, question -> SQLite_query')\n",
    "        self.ans = dspy.Predict('question, table, sql -> answer')\n",
    "        self.queries = defaultdict(list)\n",
    "        self.errors = defaultdict(list)\n",
    "        self.table = defaultdict(list)\n",
    "        self.rm = rm\n",
    "        \n",
    "    def forward(self, question):\n",
    "        error_hist = \"\"\n",
    "        self.column_description = self.rm.retrieve(question, num= 9)\n",
    "        temp_query_hist = []\n",
    "        try:\n",
    "            result = self.generated_query(question = question, column_description = self.column_description)\n",
    "        except Exception as e:\n",
    "            self.errors[question].append(str(e))\n",
    "            result = \"Error executing query: \" + str(e)\n",
    "            return self.ans(question = question, table = result, sql= \"Error executing query\")\n",
    "        \n",
    "        query = result.SQLite_query\n",
    "        temp_query_hist.append(query)\n",
    "        self.queries[question].append(query)\n",
    "        conn = self.pool.get_connection() # insted of self.conn.cursor()\n",
    "        cur = conn.cursor()\n",
    "        result = \"\"\n",
    "        #print(f\"From SQL: Query that will be executed: {query}\")\n",
    "        cause_error = True\n",
    "        dspy.Suggest(\n",
    "            bool(query in temp_query_hist),\n",
    "            \"Query should be distinct from previous queries that resulted in syntax errors: \"+ \"; \".join(f\"{i+1}) {q}\" for i, q in enumerate(temp_query_hist)),\n",
    "        )\n",
    "        error_code_fail = \"\"\n",
    "        try:\n",
    "            cur.execute(query)\n",
    "            \n",
    "        except Exception as e:\n",
    "            cause_error = False\n",
    "            error_code_fail = str(e)\n",
    "            cur.close()\n",
    "            self.pool.release_connection(conn)\n",
    "            self.errors[question].append(str(e))\n",
    "            print(\"Query generator doing error handling\")\n",
    "            \n",
    "        dspy.Suggest(\n",
    "            cause_error,\n",
    "            \"Error executing SQLite query \" + error_code_fail,\n",
    "        )\n",
    "        if len(temp_query_hist) > 3:\n",
    "            try:\n",
    "                pred = self.ans(question = question, table = \"Error executing query: \" + str(e), sql = query)\n",
    "                return pred\n",
    "            except Exception as e:\n",
    "                self.errors[question].append(str(e))\n",
    "                print(f\"From SQL: number of errors: {len(self.errors[question])}\")\n",
    "                return self.ans(question = question, table = \"There was an error during the answering of the question due to the following error: \" + str(e), sql = query)\n",
    "\n",
    "        column_names = [description[0] for description in cur.description]\n",
    "        header = \"|\".join(column_names)\n",
    "        # Initialize result with the header and account for its length.\n",
    "        result = header\n",
    "        current_length = len(result)\n",
    "        for row in cur.fetchall():\n",
    "            row_data = \" | \".join([str(cell) for cell in row])\n",
    "            if current_length + len(row_data) + 1 > self.max_length:\n",
    "                break  # Keep within the max_length limit.\n",
    "            result += \" \\n\" + row_data\n",
    "            current_length += len(row_data) + 1\n",
    "        self.table[question].append(result)\n",
    "        cur.close()\n",
    "        self.pool.release_connection(conn)\n",
    "        \n",
    "        try: \n",
    "            pred = self.ans(question = question, table = result, sql = query)\n",
    "        except Exception as e:\n",
    "            self.errors[question].append(str(e))\n",
    "            try:\n",
    "                pred = self.ans(question = question, table = result, sql = query)\n",
    "            except Exception as e:\n",
    "                self.errors[question].append(str(e))\n",
    "                print(f\"From SQL: number of errors: {len(self.errors[question])}\")\n",
    "                return self.ans(question = question, table = \"There was an error during the answering of the question due to the following error: \" + str(e), sql = query)\n",
    "        \n",
    "        #print(f\"From SQL: number of errors: {len(self.errors[question])}\")\n",
    "        #print(f\"From SQL: result: {pred.answer}, type: {type(pred.answer)}\")\n",
    "        return pred\n",
    "    def __deepcopy__(self, memo):\n",
    "\n",
    "        # Create a new instance of the class\n",
    "        cls = self.__class__\n",
    "        result = cls.__new__(cls)\n",
    "\n",
    "        # Copy all attributes except for 'conn'\n",
    "        memo[id(self)] = result\n",
    "        for k, v in self.__dict__.items():\n",
    "            if k == 'pool':\n",
    "                setattr(result, k, None)  # or reinitialize the connection if needed\n",
    "            elif k == 'rm':\n",
    "                setattr(result, k, None)\n",
    "            else:\n",
    "                try:\n",
    "                    setattr(result, k, copy.deepcopy(v, memo))\n",
    "                except Exception as e:\n",
    "                    print(\"k\", k)\n",
    "                    print(\"type of k\", type(k))\n",
    "                    print(\"v\", v)\n",
    "                    print(\"type of v\", type(v))\n",
    "        \n",
    "        # Optionally, reinitialize the connection if needed\n",
    "        \n",
    "        result.pool = self.pool\n",
    "        result.rm = self.rm\n",
    "        \n",
    "        return result\n",
    "    \n",
    "\n",
    "    def get_history(self):\n",
    "        return self.queries, self.errors, self.table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.5 Quick test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQL thread pooling\n",
    "from queue import Queue\n",
    "import threading\n",
    "\n",
    "\n",
    "class SQLiteConnectionPool:\n",
    "    def __init__(self, database, max_size=10):\n",
    "        self.database = database\n",
    "        self.pool = Queue(maxsize=max_size)\n",
    "        for _ in range(max_size):\n",
    "            self.pool.put(self.create_new_connection())\n",
    "\n",
    "    def create_new_connection(self):\n",
    "        return sqlite3.connect(self.database, check_same_thread=False)\n",
    "\n",
    "    def get_connection(self):\n",
    "        return self.pool.get()\n",
    "\n",
    "    def release_connection(self, conn):\n",
    "        self.pool.put(conn)\n",
    "\n",
    "pool = SQLiteConnectionPool(SQLITE_DB_NAME, max_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C18395, C15814, C21853, C22583, C20473, C21090, C22584, C17345, C21546, C22283\n"
     ]
    }
   ],
   "source": [
    "sql_agent = PM_SQL_multi_sp(pool).activate_assertions()\n",
    "\n",
    "result = sql_agent(\"What are names of the 10 cases whith the highest outstanding_balance?\")\n",
    "\n",
    "print(result.answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating LM JUDGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class scoring(BaseModel):\n",
    "    score: str\n",
    "class Assess(dspy.Signature):\n",
    "    \"\"\"Assess how closely the Answer matches the prediction in relation to the question. Differences in formating are less important than the actual content. Plausible methods to arrive at the answer are not considered. Only consider the Answer and the Prediction + the Question, nothing else is relevant to you.\"\"\"\n",
    "    question = dspy.InputField()\n",
    "    solution = dspy.InputField()\n",
    "    prediction = dspy.InputField()\n",
    "    reasoning = dspy.OutputField(desc=\"Reasoning behind the score\")\n",
    "    score = dspy.OutputField(desc=\"0 means its absolutely wrong, 1 means that the prediction answers parts of the question but not all of it, 2 means its an exact match in terms of content\")\n",
    "\n",
    "\n",
    "class LM_EVAL(dspy.Module):\n",
    "\n",
    "    def __init__(self, gpt4T):\n",
    "        super().__init__()\n",
    "        self.gpt4T = gpt4T\n",
    "        self.reasoning = defaultdict(list)\n",
    "        self.scorer = dspy.Predict(Assess)\n",
    "        self.hist = []\n",
    "\n",
    "    def forward(self, example, prediction, trace= None):\n",
    "        question = example.question\n",
    "        example = example.example\n",
    "        pred = prediction.answer\n",
    "        with dspy.context(lm=self.gpt4T):        \n",
    "            pred = self.scorer(question=question, solution=example, prediction=pred)\n",
    "        self.reasoning[question].append(pred.reasoning)                \n",
    "        try:\n",
    "        \n",
    "            numbers = re.findall(r'\\d+', pred.score)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # Check if we found any numbers and take the last one\n",
    "        if numbers:\n",
    "            last_number = numbers[-1]\n",
    "            \n",
    "            # Convert the last found number to an integer and check if it's in the valid range\n",
    "            last_number_int = int(last_number)\n",
    "            if last_number_int in {0, 1, 2}:\n",
    "                pred.score = last_number_int #str(last_number_int) this is used for the compiling of the judge\n",
    "                #print(f\"From LM_EVAL: {pred.score}, type: {type(pred.score)}, after assigning value to it\")\n",
    "                if trace is None:\n",
    "                    self.hist.append(pred.score)\n",
    "                    return pred.score \n",
    "                    \n",
    "                else:\n",
    "                    print(\"trace is being used\")\n",
    "                    boolean = pred.score == 2\n",
    "                    pred.score = boolean\n",
    "                    self.hist.append(pred.score)\n",
    "                    return pred.score\n",
    "            else:\n",
    "                if trace is None:\n",
    "                \n",
    "                    return 0\n",
    "                else:\n",
    "                \n",
    "                    return False\n",
    "        else:\n",
    "            if trace is None:\n",
    "                self.hist.append(0)\n",
    "                return 0\n",
    "            else:\n",
    "                self.hist.append(False)\n",
    "                return False\n",
    "            #print(f\"From LM_EVAL: {pred.answer},type: {type(pred.answer)} did not take a single number as output\")\n",
    "            \n",
    "    \n",
    "\n",
    "    def get_reasoning(self):\n",
    "        return self.reasoning\n",
    "    def get_history(self):\n",
    "        return self.hist\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def save_report_v2(output,scores,filename, program, e_metric):\n",
    "    qs = []\n",
    "    exs = []\n",
    "    preds = []\n",
    "    for i in range(len(output)):\n",
    "        qs.append(output[i][0][\"question\"])\n",
    "        exs.append(output[i][0][\"example\"])\n",
    "        try:\n",
    "            preds.append(output[i][1][\"answer\"])\n",
    "        except:\n",
    "            preds.append(\"No Answer Possible\")\n",
    "\n",
    "    qa, es, tb= program.get_history()\n",
    "    re = e_metric.get_reasoning()\n",
    "\n",
    "    df_merged = pd.DataFrame({\"question\": qs, \"example\": exs, \"prediction\": preds, \"SCORE\": scores})\n",
    "    df_merged['reasoning'] = df_merged['question'].map(re)\n",
    "    df_merged['queries'] = df_merged['question'].map(qa)\n",
    "    df_merged['errors'] = df_merged['question'].map(es)\n",
    "    df_merged['table'] = df_merged['question'].map(tb)\n",
    "    df_merged.to_csv(f\"{filename}.csv\", index=False)\n",
    "    return df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "      <th>Direct col to use</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How many events are in the log?</td>\n",
       "      <td>561470</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How many cases are in the log?</td>\n",
       "      <td>150370</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>When is the start of the event log?</td>\n",
       "      <td>1/1/2000 / 2000-01-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>When is the end of the event log?</td>\n",
       "      <td>6/18/2013/ 2013-06-18</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How many Create Fine events occur?</td>\n",
       "      <td>150370</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Question                 Answer  \\\n",
       "0      How many events are in the log?                 561470   \n",
       "1       How many cases are in the log?                 150370   \n",
       "2  When is the start of the event log?  1/1/2000 / 2000-01-01   \n",
       "3    When is the end of the event log?  6/18/2013/ 2013-06-18   \n",
       "4   How many Create Fine events occur?                 150370   \n",
       "\n",
       "  Direct col to use  \n",
       "0               NaN  \n",
       "1               NaN  \n",
       "2               NaN  \n",
       "3               NaN  \n",
       "4               NaN  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reading the gold answers\n",
    "qa = pd.read_csv(\"/Users/sulzair/Documents/Bachelor Thesis/dspy_v2/benchmark/q_a_final.csv\")\n",
    "qa.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "181"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(qa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting gold answers df into instance of DSPY Example class\n",
    "dataset = []\n",
    "\n",
    "for question, answer, _ in qa.values:\n",
    "    dataset.append(dspy.Example(question = question, example = answer).with_inputs(\"question\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset[120:125]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "      <th>Direct col to use</th>\n",
       "      <th>Split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Generic Questions</td>\n",
       "      <td>How many events are in the log?</td>\n",
       "      <td>561470</td>\n",
       "      <td>NaN</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>How many cases are in the log?</td>\n",
       "      <td>150370</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>When is the start of the event log?</td>\n",
       "      <td>1/1/2000 / 2000-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>When is the end of the event log?</td>\n",
       "      <td>6/18/2013/ 2013-06-18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Activity Count (log)</td>\n",
       "      <td>How many Create Fine events occur?</td>\n",
       "      <td>150370</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Category                             Question  \\\n",
       "0     Generic Questions      How many events are in the log?   \n",
       "1                   NaN       How many cases are in the log?   \n",
       "2                   NaN  When is the start of the event log?   \n",
       "3                   NaN    When is the end of the event log?   \n",
       "4  Activity Count (log)   How many Create Fine events occur?   \n",
       "\n",
       "                  Answer Direct col to use  Split  \n",
       "0                 561470               NaN   test  \n",
       "1                 150370               NaN  train  \n",
       "2  1/1/2000 / 2000-01-01               NaN   test  \n",
       "3  6/18/2013/ 2013-06-18               NaN   test  \n",
       "4                 150370               NaN  train  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test_split = pd.read_csv('/Users/sulzair/Documents/Bachelor Thesis/dspy_v2/benchmark/sql_questions_to_splitt.csv')\n",
    "train_test_split.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Example({'question': 'How many cases are fully_paid AND obligation_topay_cancelled OR credit_collected AND obligation_topay_cancelled OR dismissed AND obligation_topay_cancelled ', 'example': '34183'}) (input_keys={'question'})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[160]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'How many cases are fully_paid AND obligation_topay_cancelled OR credit_collected AND obligation_topay_cancelled OR dismissed AND obligation_topay_cancelled '"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test_split.loc[160].Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset 78\n",
      "testset 103\n",
      "dataset 181\n"
     ]
    }
   ],
   "source": [
    "trainset = []\n",
    "testset = []\n",
    "\n",
    "for i in range(len(dataset)):\n",
    "    try:\n",
    "        obj = train_test_split.loc[train_test_split['Question'] == dataset[i].question][\"Split\"][i]\n",
    "    except:\n",
    "        print(\"error at\", i)\n",
    "\n",
    "    if obj == \"train\":\n",
    "        trainset.append(dataset[i])\n",
    "    elif obj == \"test\":\n",
    "        testset.append(dataset[i])\n",
    "\n",
    "print(\"trainset\", len(trainset))\n",
    "print(\"testset\", len(testset))\n",
    "print(\"dataset\", len(dataset))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Runs"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**'openai/gpt-4o-mini', temperature=0.3, max_tokens=4096,**\n",
    "\n",
    "**Results:**\n",
    "\n",
    "- pm_sql_multi_sp (uc): score: 149.5% ,time: 13m36s Name: pm_sql_multi_sp_uc_mini\n",
    "- pm_sql_multi_nr (uc): score: 149.5%,time: 3m 36s Name: pm_sql_multi_nr_uc_mini\n",
    "- pm_sql_multi_COI (uc): score: 151.5% ,time: 5m 31s Name: pm_sql_multi_COI_uc_mini\n",
    "- pm_sql_multi_simple (uc): score: 105.8%, time: 4m Name: pm_sql_multi_simple_uc_mini\n",
    "\n",
    "---\n",
    "\n",
    "**'openai/gpt-4o', temperature=0.3, max_tokens=4096,**\n",
    "\n",
    "**Results:**\n",
    "\n",
    "- pm_sql_multi_sp (uc): score:177.7% ,time: 11m 42s Name: pm_sql_multi_sp_uc_4o\n",
    "- pm_sql_multi_nr (uc): score: 168.0%,time: 4m Name: pm_sql_multi_nr_uc_4o\n",
    "- pm_sql_multi_COI (uc): score: 160.2%,time: 13m 40s Name: pm_sql_multi_COI_uc_4o\n",
    "- pm_sql_multi_simple (uc): score: 149.5%, time: 7m Name: pm_sql_multi_simple_uc_4o\n",
    "\n",
    "files (all for temp 0.3)\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "\n",
    "**'openai/gpt-4o', temperature=1, max_tokens=4096,**\n",
    "\n",
    "- pm_sql_multi_sp (uc): score:174.8% ,time: 13m 38s Name: pm_sql_multi_sp_uc_4o_temp1\n",
    "\n",
    "**Optimizated runs**\n",
    "\n",
    "**'openai/gpt-4o', temperature=0.3, max_tokens=4096,**\n",
    "\n",
    "- pm_sql_multi_sp (bootstrap_fewshot_1): score: 188.3% ,time: 8m 47s\n",
    "settings: 8 bootstrapped demos, 2 rounds Name pm_sql_multi_sp_4o_bootstrap_fewshot_1\n",
    "\n",
    "- pm_sql_multi_sp (bootstrap_fewshot_2 (removed col examples)): score: 183.5% ,time: 8m 30s\n",
    "settings: 8 bootstrapped demos, 2 rounds (removed the column descriptions to save tokens)\n",
    "Name pm_sql_multi_sp_4o_bootstrap_fewshot_2\n",
    "\n",
    "\n",
    "- pm_sql_multi_sp (random_search_1 + Mipro (no real prompts adjusted)): score: 181.6% ,time: \n",
    "Name pm_sql_multi_sp_random_search_mipro_4o\n",
    "\n",
    "**'openai/gpt-4o-mini', temperature=0.3, max_tokens=4096,**\n",
    "- pm_sql_multi_sp (bootstrap_fewshot_1): score: 174.8% ,time: 13m 47s\n",
    "settings: 8 bootstrapped demos, 2 rounds Name pm_sql_multi_sp_mini_bootstrap_fewshot_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PM_SQL_multi_sp (separate reasoning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gpt4T = dspy.LM(model='openai/gpt-4o', temperature=1, max_tokens=3000, stop=None, cache=False)\n",
    "\n",
    "judge_adjusted = LM_EVAL(gpt4T)\n",
    "judge_adjusted.load(\"/Users/sulzair/Documents/Bachelor Thesis/dspy_v2/Optimized_prompts/judge_optimized_final.json\")\n",
    "\n",
    "sql_uncompiled = PM_SQL_multi_sp(pool=pool).activate_assertions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate = Evaluate(devset=testset, metric=judge_adjusted, num_threads=5, display_progress=True, display_table=len(testset), return_outputs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeroshot_optimized_program._compiled = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 187.00 / 103 (181.6%): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 103/103 [08:32<00:00,  4.98s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/23 14:51:25 INFO dspy.evaluate.evaluate: Average Metric: 187 / 103 (181.6%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>example</th>\n",
       "      <th>answer</th>\n",
       "      <th>LM_EVAL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How many events are in the log?</td>\n",
       "      <td>561470</td>\n",
       "      <td>561470</td>\n",
       "      <td>‚úîÔ∏è [2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When is the start of the event log?</td>\n",
       "      <td>1/1/2000 / 2000-01-01</td>\n",
       "      <td>2000-01-01 00:00:00+00:00</td>\n",
       "      <td>‚úîÔ∏è [2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>When is the end of the event log?</td>\n",
       "      <td>6/18/2013/ 2013-06-18</td>\n",
       "      <td>2013-06-18 00:00:00+00:00</td>\n",
       "      <td>‚úîÔ∏è [2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How many cases have sent an appeal to the Prefecture?</td>\n",
       "      <td>4141</td>\n",
       "      <td>4141</td>\n",
       "      <td>‚úîÔ∏è [2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How many event types are there?</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>‚úîÔ∏è [2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Which case is underpaid == True AND part_paid == True AND payment_...</td>\n",
       "      <td>C23364</td>\n",
       "      <td>C23364</td>\n",
       "      <td>‚úîÔ∏è [2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>How many cases have undresolved == True AND obligation_topay_cance...</td>\n",
       "      <td>13395</td>\n",
       "      <td>13395</td>\n",
       "      <td>‚úîÔ∏è [2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>How many cases have unresolved == True AND obligation_topay_cancel...</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>How many cases are credit collected before 2002-12-24?</td>\n",
       "      <td>9383</td>\n",
       "      <td>20930</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>How many cases have credit_collected == True AND time_timestamp_en...</td>\n",
       "      <td>9383</td>\n",
       "      <td>9383</td>\n",
       "      <td>‚úîÔ∏è [2]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>103 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                  question  \\\n",
       "0                                          How many events are in the log?   \n",
       "1                                      When is the start of the event log?   \n",
       "2                                        When is the end of the event log?   \n",
       "3                    How many cases have sent an appeal to the Prefecture?   \n",
       "4                                          How many event types are there?   \n",
       "..                                                                     ...   \n",
       "98   Which case is underpaid == True AND part_paid == True AND payment_...   \n",
       "99   How many cases have undresolved == True AND obligation_topay_cance...   \n",
       "100  How many cases have unresolved == True AND obligation_topay_cancel...   \n",
       "101                 How many cases are credit collected before 2002-12-24?   \n",
       "102  How many cases have credit_collected == True AND time_timestamp_en...   \n",
       "\n",
       "                   example                     answer LM_EVAL  \n",
       "0                   561470                     561470  ‚úîÔ∏è [2]  \n",
       "1    1/1/2000 / 2000-01-01  2000-01-01 00:00:00+00:00  ‚úîÔ∏è [2]  \n",
       "2    6/18/2013/ 2013-06-18  2013-06-18 00:00:00+00:00  ‚úîÔ∏è [2]  \n",
       "3                     4141                       4141  ‚úîÔ∏è [2]  \n",
       "4                       11                         11  ‚úîÔ∏è [2]  \n",
       "..                     ...                        ...     ...  \n",
       "98                  C23364                     C23364  ‚úîÔ∏è [2]  \n",
       "99                   13395                      13395  ‚úîÔ∏è [2]  \n",
       "100                      2                          6          \n",
       "101                   9383                      20930          \n",
       "102                   9383                       9383  ‚úîÔ∏è [2]  \n",
       "\n",
       "[103 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "score, outputs, scores = evaluate(program = zeroshot_optimized_program, return_all_scores= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = save_report_v2(outputs,scores, \"/Users/sulzair/Documents/Bachelor Thesis/dspy_v2/Results_SQL/compiled/pm_sql_multi_sp_random_search_mipro_4o\", zeroshot_optimized_program, judge_adjusted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = save_report_v2(outputs,scores, \"/Users/sulzair/Documents/Bachelor Thesis/dspy_v2/Results/pm_sql_multi_sp_uc_4o_temp1\", sql_uncompiled, judge_adjusted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PM_SQL_multi_nr (no reasoning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt4T = dspy.LM(model='openai/gpt-4o', temperature=1, max_tokens=3000, stop=None, cache=True)\n",
    "\n",
    "judge_adjusted = LM_EVAL(gpt4T)\n",
    "judge_adjusted.load(\"/Users/sulzair/Documents/Bachelor Thesis/dspy_v2/Optimized_prompts/judge_optimized_final.json\")\n",
    "\n",
    "sql_uncompiled = PM_SQL_multi_nr(pool=pool).activate_assertions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate = Evaluate(devset=testset, metric=judge_adjusted, num_threads=5, display_progress=True, display_table=len(testset), return_outputs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 173.00 / 103 (168.0%): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 103/103 [04:13<00:00,  2.46s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/20 13:30:23 INFO dspy.evaluate.evaluate: Average Metric: 173 / 103 (168.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>example</th>\n",
       "      <th>answer</th>\n",
       "      <th>LM_EVAL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How many events are in the log?</td>\n",
       "      <td>561470</td>\n",
       "      <td>561470</td>\n",
       "      <td>‚úîÔ∏è [2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When is the start of the event log?</td>\n",
       "      <td>1/1/2000 / 2000-01-01</td>\n",
       "      <td>2000-01-01 00:00:00+00:00</td>\n",
       "      <td>‚úîÔ∏è [2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>When is the end of the event log?</td>\n",
       "      <td>6/18/2013/ 2013-06-18</td>\n",
       "      <td>2013-06-18 00:00:00+00:00</td>\n",
       "      <td>‚úîÔ∏è [2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How many cases have sent an appeal to the Prefecture?</td>\n",
       "      <td>4141</td>\n",
       "      <td>4141</td>\n",
       "      <td>‚úîÔ∏è [2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How many event types are there?</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>‚úîÔ∏è [2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Which case is underpaid == True AND part_paid == True AND payment_...</td>\n",
       "      <td>C23364</td>\n",
       "      <td>C23364</td>\n",
       "      <td>‚úîÔ∏è [2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>How many cases have undresolved == True AND obligation_topay_cance...</td>\n",
       "      <td>13395</td>\n",
       "      <td>13395</td>\n",
       "      <td>‚úîÔ∏è [2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>How many cases have unresolved == True AND obligation_topay_cancel...</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>How many cases are credit collected before 2002-12-24?</td>\n",
       "      <td>9383</td>\n",
       "      <td>20930</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>How many cases have credit_collected == True AND time_timestamp_en...</td>\n",
       "      <td>9383</td>\n",
       "      <td>9383</td>\n",
       "      <td>‚úîÔ∏è [2]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>103 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                  question  \\\n",
       "0                                          How many events are in the log?   \n",
       "1                                      When is the start of the event log?   \n",
       "2                                        When is the end of the event log?   \n",
       "3                    How many cases have sent an appeal to the Prefecture?   \n",
       "4                                          How many event types are there?   \n",
       "..                                                                     ...   \n",
       "98   Which case is underpaid == True AND part_paid == True AND payment_...   \n",
       "99   How many cases have undresolved == True AND obligation_topay_cance...   \n",
       "100  How many cases have unresolved == True AND obligation_topay_cancel...   \n",
       "101                 How many cases are credit collected before 2002-12-24?   \n",
       "102  How many cases have credit_collected == True AND time_timestamp_en...   \n",
       "\n",
       "                   example                     answer LM_EVAL  \n",
       "0                   561470                     561470  ‚úîÔ∏è [2]  \n",
       "1    1/1/2000 / 2000-01-01  2000-01-01 00:00:00+00:00  ‚úîÔ∏è [2]  \n",
       "2    6/18/2013/ 2013-06-18  2013-06-18 00:00:00+00:00  ‚úîÔ∏è [2]  \n",
       "3                     4141                       4141  ‚úîÔ∏è [2]  \n",
       "4                       11                         11  ‚úîÔ∏è [2]  \n",
       "..                     ...                        ...     ...  \n",
       "98                  C23364                     C23364  ‚úîÔ∏è [2]  \n",
       "99                   13395                      13395  ‚úîÔ∏è [2]  \n",
       "100                      2                          6          \n",
       "101                   9383                      20930          \n",
       "102                   9383                       9383  ‚úîÔ∏è [2]  \n",
       "\n",
       "[103 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "score, outputs, scores = evaluate(program = sql_uncompiled, return_all_scores= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = save_report_v2(outputs,scores, \"/Users/sulzair/Documents/Bachelor Thesis/dspy_v2/Results/pm_sql_multi_nr_uc_4o\", sql_uncompiled, judge_adjusted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PM_SQL_multi_COI (no reasoning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gpt4T = dspy.LM(model='openai/gpt-4o', temperature=1, max_tokens=3000, stop=None, cache=False)\n",
    "\n",
    "judge_adjusted = LM_EVAL(gpt4T)\n",
    "judge_adjusted.load(\"/Users/sulzair/Documents/Bachelor Thesis/dspy_v2/Optimized_prompts/judge_optimized_final.json\")\n",
    "\n",
    "sql_uncompiled = PM_SQL_multi_COI(pool=pool).activate_assertions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate = Evaluate(devset=testset, metric=judge_adjusted, num_threads=5, display_progress=True, display_table=len(testset), return_outputs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 165.00 / 103 (160.2%): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 103/103 [13:38<00:00,  7.95s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/20 13:45:20 INFO dspy.evaluate.evaluate: Average Metric: 165 / 103 (160.2%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>example</th>\n",
       "      <th>answer</th>\n",
       "      <th>LM_EVAL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How many events are in the log?</td>\n",
       "      <td>561470</td>\n",
       "      <td>561470</td>\n",
       "      <td>‚úîÔ∏è [2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When is the start of the event log?</td>\n",
       "      <td>1/1/2000 / 2000-01-01</td>\n",
       "      <td>2000-01-01 00:00:00+00:00</td>\n",
       "      <td>‚úîÔ∏è [2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>When is the end of the event log?</td>\n",
       "      <td>6/18/2013/ 2013-06-18</td>\n",
       "      <td>2013-06-18 00:00:00+00:00</td>\n",
       "      <td>‚úîÔ∏è [2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How many cases have sent an appeal to the Prefecture?</td>\n",
       "      <td>4141</td>\n",
       "      <td>4141</td>\n",
       "      <td>‚úîÔ∏è [2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How many event types are there?</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>‚úîÔ∏è [2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Which case is underpaid == True AND part_paid == True AND payment_...</td>\n",
       "      <td>C23364</td>\n",
       "      <td>C23364</td>\n",
       "      <td>‚úîÔ∏è [2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>How many cases have undresolved == True AND obligation_topay_cance...</td>\n",
       "      <td>13395</td>\n",
       "      <td>13395</td>\n",
       "      <td>‚úîÔ∏è [2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>How many cases have unresolved == True AND obligation_topay_cancel...</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>How many cases are credit collected before 2002-12-24?</td>\n",
       "      <td>9383</td>\n",
       "      <td>20930</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>How many cases have credit_collected == True AND time_timestamp_en...</td>\n",
       "      <td>9383</td>\n",
       "      <td>9383</td>\n",
       "      <td>‚úîÔ∏è [2]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>103 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                  question  \\\n",
       "0                                          How many events are in the log?   \n",
       "1                                      When is the start of the event log?   \n",
       "2                                        When is the end of the event log?   \n",
       "3                    How many cases have sent an appeal to the Prefecture?   \n",
       "4                                          How many event types are there?   \n",
       "..                                                                     ...   \n",
       "98   Which case is underpaid == True AND part_paid == True AND payment_...   \n",
       "99   How many cases have undresolved == True AND obligation_topay_cance...   \n",
       "100  How many cases have unresolved == True AND obligation_topay_cancel...   \n",
       "101                 How many cases are credit collected before 2002-12-24?   \n",
       "102  How many cases have credit_collected == True AND time_timestamp_en...   \n",
       "\n",
       "                   example                     answer LM_EVAL  \n",
       "0                   561470                     561470  ‚úîÔ∏è [2]  \n",
       "1    1/1/2000 / 2000-01-01  2000-01-01 00:00:00+00:00  ‚úîÔ∏è [2]  \n",
       "2    6/18/2013/ 2013-06-18  2013-06-18 00:00:00+00:00  ‚úîÔ∏è [2]  \n",
       "3                     4141                       4141  ‚úîÔ∏è [2]  \n",
       "4                       11                         11  ‚úîÔ∏è [2]  \n",
       "..                     ...                        ...     ...  \n",
       "98                  C23364                     C23364  ‚úîÔ∏è [2]  \n",
       "99                   13395                      13395  ‚úîÔ∏è [2]  \n",
       "100                      2                          6          \n",
       "101                   9383                      20930          \n",
       "102                   9383                       9383  ‚úîÔ∏è [2]  \n",
       "\n",
       "[103 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "score, outputs, scores = evaluate(program = sql_uncompiled, return_all_scores= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = save_report_v2(outputs,scores, \"/Users/sulzair/Documents/Bachelor Thesis/dspy_v2/Results/pm_sql_multi_COI_uc_4o\", sql_uncompiled, judge_adjusted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PM_SQL_simple (no reasoning, no prompts) - baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gpt4T = dspy.LM(model='openai/gpt-4o', temperature=1, max_tokens=3000, stop=None, cache=False)\n",
    "\n",
    "judge_adjusted = LM_EVAL(gpt4T)\n",
    "judge_adjusted.load(\"/Users/sulzair/Documents/Bachelor Thesis/dspy_v2/Optimized_prompts/judge_optimized_final.json\")\n",
    "\n",
    "sql_uncompiled = PM_SQL_multi_simple(pool=pool).activate_assertions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate = Evaluate(devset=testset, metric=judge_adjusted, num_threads=5, display_progress=True, display_table=len(testset), return_outputs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score, outputs, scores = evaluate(program = sql_uncompiled, return_all_scores= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = save_report_v2(outputs,scores, \"/Users/sulzair/Documents/Bachelor Thesis/dspy_v2/Results/pm_sql_multi_simple_uc_4o\", sql_uncompiled, judge_adjusted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we select the architecture of PM_SQL_multi_sp since it scored the highest. Now we do further optimization:\n",
    "\n",
    "BootstrapFewShot\n",
    "BootstrapFewShotWithRandomSearch\n",
    "MIPROV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstrap FewShot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78\n"
     ]
    }
   ],
   "source": [
    "print(len(trainset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_uncompiled = PM_SQL_multi_sp(pool=pool).activate_assertions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|‚ñè         | 1/78 [00:05<06:43,  5.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trace is being used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|‚ñé         | 2/78 [00:09<05:42,  4.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trace is being used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|‚ñç         | 3/78 [00:13<05:34,  4.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trace is being used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|‚ñå         | 4/78 [00:18<05:54,  4.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trace is being used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|‚ñã         | 5/78 [00:24<06:14,  5.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trace is being used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|‚ñä         | 6/78 [00:30<06:14,  5.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trace is being used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|‚ñâ         | 7/78 [00:34<05:46,  4.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trace is being used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|‚ñà         | 8/78 [00:39<05:43,  4.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trace is being used\n",
      "Bootstrapped 8 full traces after 8 examples for up to 3 rounds, amounting to 8 attempts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "bootstrap_fewshot = BootstrapFewShot(\n",
    "    metric = judge_adjusted,\n",
    "    max_bootstrapped_demos = 8,\n",
    "    max_labeled_demos = 0,\n",
    "    max_rounds = 3,\n",
    "    max_errors = 2)\n",
    "sql_compiled = bootstrap_fewshot.compile(student = sql_uncompiled, trainset = trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"/Users/sulzair/Documents/Bachelor Thesis/dspy_v2/Optimized_prompts/sql_bootstrap_bootstrap_fewshot_1.json\"\n",
    "sql_compiled.save(path=save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eval on testset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gpt 4-o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate = Evaluate(devset=testset, metric=judge_adjusted, num_threads=5, display_progress=True, display_table=len(testset), return_outputs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 194.00 / 103 (188.3%): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 103/103 [08:47<00:00,  5.12s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/22 13:17:10 INFO dspy.evaluate.evaluate: Average Metric: 194 / 103 (188.3%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>example</th>\n",
       "      <th>answer</th>\n",
       "      <th>LM_EVAL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How many events are in the log?</td>\n",
       "      <td>561470</td>\n",
       "      <td>561470</td>\n",
       "      <td>‚úîÔ∏è [2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When is the start of the event log?</td>\n",
       "      <td>1/1/2000 / 2000-01-01</td>\n",
       "      <td>2000-01-01 00:00:00+00:00</td>\n",
       "      <td>‚úîÔ∏è [2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>When is the end of the event log?</td>\n",
       "      <td>6/18/2013/ 2013-06-18</td>\n",
       "      <td>2013-06-18 00:00:00+00:00</td>\n",
       "      <td>‚úîÔ∏è [2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How many cases have sent an appeal to the Prefecture?</td>\n",
       "      <td>4141</td>\n",
       "      <td>4141</td>\n",
       "      <td>‚úîÔ∏è [2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How many event types are there?</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>‚úîÔ∏è [2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Which case is underpaid == True AND part_paid == True AND payment_...</td>\n",
       "      <td>C23364</td>\n",
       "      <td>C23364</td>\n",
       "      <td>‚úîÔ∏è [2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>How many cases have undresolved == True AND obligation_topay_cance...</td>\n",
       "      <td>13395</td>\n",
       "      <td>13395</td>\n",
       "      <td>‚úîÔ∏è [2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>How many cases have unresolved == True AND obligation_topay_cancel...</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>How many cases are credit collected before 2002-12-24?</td>\n",
       "      <td>9383</td>\n",
       "      <td>9383</td>\n",
       "      <td>‚úîÔ∏è [2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>How many cases have credit_collected == True AND time_timestamp_en...</td>\n",
       "      <td>9383</td>\n",
       "      <td>9383</td>\n",
       "      <td>‚úîÔ∏è [2]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>103 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                  question  \\\n",
       "0                                          How many events are in the log?   \n",
       "1                                      When is the start of the event log?   \n",
       "2                                        When is the end of the event log?   \n",
       "3                    How many cases have sent an appeal to the Prefecture?   \n",
       "4                                          How many event types are there?   \n",
       "..                                                                     ...   \n",
       "98   Which case is underpaid == True AND part_paid == True AND payment_...   \n",
       "99   How many cases have undresolved == True AND obligation_topay_cance...   \n",
       "100  How many cases have unresolved == True AND obligation_topay_cancel...   \n",
       "101                 How many cases are credit collected before 2002-12-24?   \n",
       "102  How many cases have credit_collected == True AND time_timestamp_en...   \n",
       "\n",
       "                   example                     answer LM_EVAL  \n",
       "0                   561470                     561470  ‚úîÔ∏è [2]  \n",
       "1    1/1/2000 / 2000-01-01  2000-01-01 00:00:00+00:00  ‚úîÔ∏è [2]  \n",
       "2    6/18/2013/ 2013-06-18  2013-06-18 00:00:00+00:00  ‚úîÔ∏è [2]  \n",
       "3                     4141                       4141  ‚úîÔ∏è [2]  \n",
       "4                       11                         11  ‚úîÔ∏è [2]  \n",
       "..                     ...                        ...     ...  \n",
       "98                  C23364                     C23364  ‚úîÔ∏è [2]  \n",
       "99                   13395                      13395  ‚úîÔ∏è [2]  \n",
       "100                      2                          6          \n",
       "101                   9383                       9383  ‚úîÔ∏è [2]  \n",
       "102                   9383                       9383  ‚úîÔ∏è [2]  \n",
       "\n",
       "[103 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "score, outputs, scores = evaluate(program = sql_compiled, return_all_scores= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = save_report_v2(outputs,scores, \"/Users/sulzair/Documents/Bachelor Thesis/dspy_v2/Results_SQL/pm_sql_multi_sp_4o_bootstrap_fewshot_1\", sql_compiled, judge_adjusted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "removing the column descriptions (bootstrap_fewshot_2.json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sql_fewshot_2 = PM_SQL_multi_sp(pool=pool).activate_assertions()\n",
    "sql_fewshot_2.load(\"/Users/sulzair/Documents/Bachelor Thesis/dspy_v2/Optimized_prompts/sql_bootstrap_fewshot_2.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate = Evaluate(devset=testset, metric=judge_adjusted, num_threads=5, display_progress=True, display_table=len(testset), return_outputs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 189.00 / 103 (183.5%): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 103/103 [08:33<00:00,  4.98s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/22 13:46:00 INFO dspy.evaluate.evaluate: Average Metric: 189 / 103 (183.5%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>example</th>\n",
       "      <th>answer</th>\n",
       "      <th>LM_EVAL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How many events are in the log?</td>\n",
       "      <td>561470</td>\n",
       "      <td>561470</td>\n",
       "      <td>‚úîÔ∏è [2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When is the start of the event log?</td>\n",
       "      <td>1/1/2000 / 2000-01-01</td>\n",
       "      <td>2000-01-01 00:00:00+00:00</td>\n",
       "      <td>‚úîÔ∏è [2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>When is the end of the event log?</td>\n",
       "      <td>6/18/2013/ 2013-06-18</td>\n",
       "      <td>2013-06-18 00:00:00+00:00</td>\n",
       "      <td>‚úîÔ∏è [2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How many cases have sent an appeal to the Prefecture?</td>\n",
       "      <td>4141</td>\n",
       "      <td>4188</td>\n",
       "      <td>‚úîÔ∏è [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How many event types are there?</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>‚úîÔ∏è [2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Which case is underpaid == True AND part_paid == True AND payment_...</td>\n",
       "      <td>C23364</td>\n",
       "      <td>C23364</td>\n",
       "      <td>‚úîÔ∏è [2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>How many cases have undresolved == True AND obligation_topay_cance...</td>\n",
       "      <td>13395</td>\n",
       "      <td>13395</td>\n",
       "      <td>‚úîÔ∏è [2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>How many cases have unresolved == True AND obligation_topay_cancel...</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>How many cases are credit collected before 2002-12-24?</td>\n",
       "      <td>9383</td>\n",
       "      <td>20930</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>How many cases have credit_collected == True AND time_timestamp_en...</td>\n",
       "      <td>9383</td>\n",
       "      <td>9383</td>\n",
       "      <td>‚úîÔ∏è [2]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>103 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                  question  \\\n",
       "0                                          How many events are in the log?   \n",
       "1                                      When is the start of the event log?   \n",
       "2                                        When is the end of the event log?   \n",
       "3                    How many cases have sent an appeal to the Prefecture?   \n",
       "4                                          How many event types are there?   \n",
       "..                                                                     ...   \n",
       "98   Which case is underpaid == True AND part_paid == True AND payment_...   \n",
       "99   How many cases have undresolved == True AND obligation_topay_cance...   \n",
       "100  How many cases have unresolved == True AND obligation_topay_cancel...   \n",
       "101                 How many cases are credit collected before 2002-12-24?   \n",
       "102  How many cases have credit_collected == True AND time_timestamp_en...   \n",
       "\n",
       "                   example                     answer LM_EVAL  \n",
       "0                   561470                     561470  ‚úîÔ∏è [2]  \n",
       "1    1/1/2000 / 2000-01-01  2000-01-01 00:00:00+00:00  ‚úîÔ∏è [2]  \n",
       "2    6/18/2013/ 2013-06-18  2013-06-18 00:00:00+00:00  ‚úîÔ∏è [2]  \n",
       "3                     4141                       4188  ‚úîÔ∏è [1]  \n",
       "4                       11                         11  ‚úîÔ∏è [2]  \n",
       "..                     ...                        ...     ...  \n",
       "98                  C23364                     C23364  ‚úîÔ∏è [2]  \n",
       "99                   13395                      13395  ‚úîÔ∏è [2]  \n",
       "100                      2                          6          \n",
       "101                   9383                      20930          \n",
       "102                   9383                       9383  ‚úîÔ∏è [2]  \n",
       "\n",
       "[103 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "score, outputs, scores = evaluate(program = sql_fewshot_2, return_all_scores= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = save_report_v2(outputs,scores, \"/Users/sulzair/Documents/Bachelor Thesis/dspy_v2/Results_SQL/pm_sql_multi_sp_4o_bootstrap_fewshot_2\", sql_fewshot_2, judge_adjusted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gpt 4o-mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 40.00 / 26 (153.8%):  25%|‚ñà‚ñà‚ñå       | 26/103 [03:45<08:45,  6.82s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/22 13:23:53 INFO dspy.primitives.assertions: SuggestionFailed: Error executing SQLite query near \"DISTINCT\": syntax error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 74.00 / 47 (157.4%):  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 47/103 [06:04<05:41,  6.11s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/22 13:26:11 INFO dspy.primitives.assertions: SuggestionFailed: Error executing SQLite query near \"DISTINCT\": syntax error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 180.00 / 103 (174.8%): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 103/103 [12:40<00:00,  7.38s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/22 13:32:42 INFO dspy.evaluate.evaluate: Average Metric: 180 / 103 (174.8%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>example</th>\n",
       "      <th>answer</th>\n",
       "      <th>LM_EVAL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How many events are in the log?</td>\n",
       "      <td>561470</td>\n",
       "      <td>561470</td>\n",
       "      <td>‚úîÔ∏è [2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When is the start of the event log?</td>\n",
       "      <td>1/1/2000 / 2000-01-01</td>\n",
       "      <td>2000-01-01 00:00:00+00:00</td>\n",
       "      <td>‚úîÔ∏è [2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>When is the end of the event log?</td>\n",
       "      <td>6/18/2013/ 2013-06-18</td>\n",
       "      <td>2013-06-18 00:00:00+00:00</td>\n",
       "      <td>‚úîÔ∏è [2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How many cases have sent an appeal to the Prefecture?</td>\n",
       "      <td>4141</td>\n",
       "      <td>4188</td>\n",
       "      <td>‚úîÔ∏è [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How many event types are there?</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>‚úîÔ∏è [2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Which case is underpaid == True AND part_paid == True AND payment_...</td>\n",
       "      <td>C23364</td>\n",
       "      <td>C23364</td>\n",
       "      <td>‚úîÔ∏è [2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>How many cases have undresolved == True AND obligation_topay_cance...</td>\n",
       "      <td>13395</td>\n",
       "      <td>13395</td>\n",
       "      <td>‚úîÔ∏è [2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>How many cases have unresolved == True AND obligation_topay_cancel...</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>How many cases are credit collected before 2002-12-24?</td>\n",
       "      <td>9383</td>\n",
       "      <td>20930</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>How many cases have credit_collected == True AND time_timestamp_en...</td>\n",
       "      <td>9383</td>\n",
       "      <td>9383</td>\n",
       "      <td>‚úîÔ∏è [2]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>103 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                  question  \\\n",
       "0                                          How many events are in the log?   \n",
       "1                                      When is the start of the event log?   \n",
       "2                                        When is the end of the event log?   \n",
       "3                    How many cases have sent an appeal to the Prefecture?   \n",
       "4                                          How many event types are there?   \n",
       "..                                                                     ...   \n",
       "98   Which case is underpaid == True AND part_paid == True AND payment_...   \n",
       "99   How many cases have undresolved == True AND obligation_topay_cance...   \n",
       "100  How many cases have unresolved == True AND obligation_topay_cancel...   \n",
       "101                 How many cases are credit collected before 2002-12-24?   \n",
       "102  How many cases have credit_collected == True AND time_timestamp_en...   \n",
       "\n",
       "                   example                     answer LM_EVAL  \n",
       "0                   561470                     561470  ‚úîÔ∏è [2]  \n",
       "1    1/1/2000 / 2000-01-01  2000-01-01 00:00:00+00:00  ‚úîÔ∏è [2]  \n",
       "2    6/18/2013/ 2013-06-18  2013-06-18 00:00:00+00:00  ‚úîÔ∏è [2]  \n",
       "3                     4141                       4188  ‚úîÔ∏è [1]  \n",
       "4                       11                         11  ‚úîÔ∏è [2]  \n",
       "..                     ...                        ...     ...  \n",
       "98                  C23364                     C23364  ‚úîÔ∏è [2]  \n",
       "99                   13395                      13395  ‚úîÔ∏è [2]  \n",
       "100                      2                          6          \n",
       "101                   9383                      20930          \n",
       "102                   9383                       9383  ‚úîÔ∏è [2]  \n",
       "\n",
       "[103 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "score, outputs, scores = evaluate(program = sql_compiled, return_all_scores= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = save_report_v2(outputs,scores, \"/Users/sulzair/Documents/Bachelor Thesis/dspy_v2/Results_SQL/compiled/pm_sql_multi_sp_mini_bootstrap_fewshot_1\", sql_compiled, judge_adjusted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BootStrap Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_uncompiled = PM_SQL_multi_sp(pool=pool).activate_assertions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Going to sample between 1 and 8 traces per predictor.\n",
      "Will attempt to bootstrap 8 candidate sets.\n",
      "Average Metric: 120.00 / 76 (157.9%):  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 76/78 [05:48<00:12,  6.15s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/22 15:30:21 INFO dspy.primitives.assertions: SuggestionFailed: Error executing SQLite query near \"'15 days'\": syntax error\n",
      "2024/12/22 15:30:27 INFO dspy.primitives.assertions: SuggestionFailed: Error executing SQLite query near \"15\": syntax error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 122.00 / 78 (156.4%): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 78/78 [06:12<00:00,  4.77s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/22 15:30:40 INFO dspy.evaluate.evaluate: Average Metric: 122 / 78 (156.4%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best score: 156.41 for seed -3\n",
      "Scores so far: [156.41]\n",
      "Best score so far: 156.41\n",
      "Average Metric: 119.00 / 74 (160.8%):  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 74/78 [05:36<00:20,  5.21s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/22 15:36:20 INFO dspy.primitives.assertions: SuggestionFailed: Your reasoning should be fewer than 1400 characters long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 123.00 / 76 (161.8%):  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 76/78 [05:52<00:12,  6.46s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/22 15:36:37 INFO dspy.primitives.assertions: SuggestionFailed: Your reasoning should be fewer than 1400 characters long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 123.00 / 77 (159.7%):  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 77/78 [06:03<00:07,  7.76s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/22 15:36:48 INFO dspy.primitives.assertions: SuggestionFailed: Your reasoning should be fewer than 1400 characters long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 125.00 / 78 (160.3%): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 78/78 [06:13<00:00,  4.79s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/22 15:36:54 INFO dspy.evaluate.evaluate: Average Metric: 125 / 78 (160.3%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best score: 160.26 for seed -2\n",
      "Scores so far: [156.41, 160.26]\n",
      "Best score so far: 160.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|‚ñè         | 1/78 [00:02<03:20,  2.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trace is being used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|‚ñé         | 2/78 [00:05<03:21,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trace is being used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|‚ñç         | 3/78 [00:08<03:41,  2.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trace is being used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|‚ñå         | 4/78 [00:12<04:00,  3.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trace is being used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|‚ñã         | 5/78 [00:16<04:30,  3.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trace is being used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|‚ñä         | 6/78 [00:20<04:23,  3.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trace is being used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|‚ñâ         | 7/78 [00:23<04:18,  3.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trace is being used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|‚ñà         | 8/78 [00:27<04:17,  3.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trace is being used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|‚ñà‚ñè        | 9/78 [00:31<04:09,  3.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trace is being used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|‚ñà‚ñé        | 10/78 [00:35<04:01,  3.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trace is being used\n",
      "Bootstrapped 8 full traces after 10 examples for up to 1 rounds, amounting to 10 attempts.\n",
      "Average Metric: 140.00 / 78 (179.5%): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 78/78 [13:55<00:00, 10.71s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/22 15:51:24 INFO dspy.evaluate.evaluate: Average Metric: 140 / 78 (179.5%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best score: 179.49 for seed -1\n",
      "Scores so far: [156.41, 160.26, 179.49]\n",
      "Best score so far: 179.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|‚ñè         | 1/78 [00:04<06:17,  4.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trace is being used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|‚ñé         | 2/78 [00:12<07:52,  6.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trace is being used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|‚ñç         | 3/78 [00:18<07:57,  6.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trace is being used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|‚ñå         | 4/78 [00:23<07:03,  5.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trace is being used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|‚ñã         | 5/78 [00:29<07:17,  6.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trace is being used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|‚ñä         | 6/78 [00:36<07:40,  6.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trace is being used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|‚ñâ         | 7/78 [00:43<07:32,  6.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trace is being used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|‚ñà         | 8/78 [00:48<06:51,  5.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trace is being used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|‚ñà‚ñè        | 9/78 [00:59<08:44,  7.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trace is being used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|‚ñà‚ñé        | 10/78 [01:03<07:10,  6.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trace is being used\n",
      "Bootstrapped 7 full traces after 10 examples for up to 1 rounds, amounting to 10 attempts.\n",
      "Average Metric: 134.00 / 78 (171.8%): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 78/78 [09:18<00:00,  7.16s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/22 16:01:46 INFO dspy.evaluate.evaluate: Average Metric: 134 / 78 (171.8%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scores so far: [156.41, 160.26, 179.49, 171.79]\n",
      "Best score so far: 179.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|‚ñè         | 1/78 [00:04<05:12,  4.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trace is being used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|‚ñé         | 2/78 [00:12<08:06,  6.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trace is being used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|‚ñç         | 3/78 [00:15<06:37,  5.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trace is being used\n",
      "Bootstrapped 3 full traces after 3 examples for up to 1 rounds, amounting to 3 attempts.\n",
      "Average Metric: 134.00 / 76 (176.3%):  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 76/78 [07:06<00:12,  6.17s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/22 16:09:13 INFO dspy.primitives.assertions: SuggestionFailed: Your reasoning should be fewer than 1400 characters long\n",
      "2024/12/22 16:09:19 INFO dspy.primitives.assertions: SuggestionFailed: Error executing SQLite query near \"15\": syntax error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 138.00 / 78 (176.9%): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 78/78 [07:32<00:00,  5.80s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/22 16:09:34 INFO dspy.evaluate.evaluate: Average Metric: 138 / 78 (176.9%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scores so far: [156.41, 160.26, 179.49, 171.79, 176.92]\n",
      "Best score so far: 179.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|‚ñè         | 1/78 [00:03<04:58,  3.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trace is being used\n",
      "Bootstrapped 1 full traces after 1 examples for up to 1 rounds, amounting to 1 attempts.\n",
      "Average Metric: 120.00 / 78 (153.8%): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 78/78 [06:12<00:00,  4.78s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/22 16:15:51 INFO dspy.evaluate.evaluate: Average Metric: 120 / 78 (153.8%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scores so far: [156.41, 160.26, 179.49, 171.79, 176.92, 153.85]\n",
      "Best score so far: 179.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|‚ñè         | 1/78 [00:02<03:49,  2.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trace is being used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|‚ñé         | 2/78 [00:06<04:20,  3.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trace is being used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|‚ñç         | 3/78 [00:16<07:39,  6.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trace is being used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|‚ñå         | 4/78 [00:21<07:16,  5.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trace is being used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|‚ñã         | 5/78 [00:26<06:55,  5.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trace is being used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|‚ñä         | 6/78 [00:30<05:57,  4.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trace is being used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|‚ñâ         | 7/78 [00:36<06:18,  5.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trace is being used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|‚ñà         | 8/78 [00:43<06:16,  5.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trace is being used\n",
      "Bootstrapped 4 full traces after 8 examples for up to 1 rounds, amounting to 8 attempts.\n",
      "Average Metric: 133.00 / 78 (170.5%): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 78/78 [07:13<00:00,  5.56s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/22 16:23:48 INFO dspy.evaluate.evaluate: Average Metric: 133 / 78 (170.5%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scores so far: [156.41, 160.26, 179.49, 171.79, 176.92, 153.85, 170.51]\n",
      "Best score so far: 179.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|‚ñè         | 1/78 [00:04<05:50,  4.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trace is being used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|‚ñé         | 2/78 [00:10<06:53,  5.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trace is being used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|‚ñç         | 3/78 [00:14<05:55,  4.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trace is being used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|‚ñå         | 4/78 [00:19<06:01,  4.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trace is being used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|‚ñã         | 5/78 [00:23<05:40,  4.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trace is being used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|‚ñä         | 6/78 [00:26<04:54,  4.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trace is being used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|‚ñâ         | 7/78 [00:30<04:45,  4.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trace is being used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|‚ñà         | 8/78 [00:36<05:18,  4.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trace is being used\n",
      "Bootstrapped 4 full traces after 8 examples for up to 1 rounds, amounting to 8 attempts.\n",
      "Average Metric: 137.00 / 78 (175.6%): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 78/78 [06:27<00:00,  4.97s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/22 16:30:51 INFO dspy.evaluate.evaluate: Average Metric: 137 / 78 (175.6%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scores so far: [156.41, 160.26, 179.49, 171.79, 176.92, 153.85, 170.51, 175.64]\n",
      "Best score so far: 179.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|‚ñè         | 1/78 [00:06<07:43,  6.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trace is being used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|‚ñé         | 2/78 [00:10<06:17,  4.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trace is being used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|‚ñç         | 3/78 [00:14<05:45,  4.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trace is being used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/22 16:31:13 INFO dspy.primitives.assertions: SuggestionFailed: Your reasoning should be fewer than 1400 characters long\n",
      "  5%|‚ñå         | 4/78 [00:27<09:38,  7.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trace is being used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|‚ñã         | 5/78 [00:31<07:50,  6.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trace is being used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|‚ñä         | 6/78 [00:34<06:34,  5.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trace is being used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|‚ñâ         | 7/78 [00:39<06:42,  5.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trace is being used\n",
      "Bootstrapped 5 full traces after 7 examples for up to 1 rounds, amounting to 7 attempts.\n",
      "Average Metric: 138.00 / 78 (176.9%): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 78/78 [08:04<00:00,  6.22s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/22 16:39:36 INFO dspy.evaluate.evaluate: Average Metric: 138 / 78 (176.9%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scores so far: [156.41, 160.26, 179.49, 171.79, 176.92, 153.85, 170.51, 175.64, 176.92]\n",
      "Best score so far: 179.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|‚ñè         | 1/78 [00:03<05:04,  3.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trace is being used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|‚ñé         | 2/78 [00:10<06:54,  5.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trace is being used\n",
      "Bootstrapped 2 full traces after 2 examples for up to 1 rounds, amounting to 2 attempts.\n",
      "Average Metric: 124.00 / 76 (163.2%):  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 76/78 [06:26<00:10,  5.25s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/22 16:46:23 INFO dspy.primitives.assertions: SuggestionFailed: Error executing SQLite query near \"'15 days'\": syntax error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 126.00 / 78 (161.5%): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 78/78 [06:51<00:00,  5.27s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/22 16:46:38 INFO dspy.evaluate.evaluate: Average Metric: 126 / 78 (161.5%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scores so far: [156.41, 160.26, 179.49, 171.79, 176.92, 153.85, 170.51, 175.64, 176.92, 161.54]\n",
      "Best score so far: 179.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|‚ñè         | 1/78 [00:04<05:31,  4.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trace is being used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|‚ñé         | 2/78 [00:07<04:25,  3.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trace is being used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/22 16:46:50 INFO dspy.primitives.assertions: SuggestionFailed: Your reasoning should be fewer than 1400 characters long\n",
      "  4%|‚ñç         | 3/78 [00:18<09:03,  7.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trace is being used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|‚ñå         | 4/78 [00:22<07:13,  5.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trace is being used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|‚ñã         | 5/78 [00:28<07:12,  5.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trace is being used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|‚ñä         | 6/78 [00:32<06:20,  5.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trace is being used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|‚ñâ         | 7/78 [00:37<06:17,  5.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trace is being used\n",
      "Bootstrapped 6 full traces after 7 examples for up to 1 rounds, amounting to 7 attempts.\n",
      "Average Metric: 128.00 / 78 (164.1%): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 78/78 [06:49<00:00,  5.25s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/22 16:54:05 INFO dspy.evaluate.evaluate: Average Metric: 128 / 78 (164.1%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scores so far: [156.41, 160.26, 179.49, 171.79, 176.92, 153.85, 170.51, 175.64, 176.92, 161.54, 164.1]\n",
      "Best score so far: 179.49\n",
      "11 candidate programs found.\n"
     ]
    }
   ],
   "source": [
    "from dspy.teleprompt import BootstrapFewShotWithRandomSearch\n",
    "\n",
    "fewshot_optimizer = BootstrapFewShotWithRandomSearch(metric=judge_adjusted, \n",
    "                                                     max_bootstrapped_demos=8, \n",
    "                                                     num_candidate_programs=8, \n",
    "                                                     max_labeled_demos=0,\n",
    "                                                     num_threads=8)\n",
    "\n",
    "sql_random_search = fewshot_optimizer.compile(student = sql_uncompiled,\n",
    "                                               trainset=trainset, valset=trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"/Users/sulzair/Documents/Bachelor Thesis/dspy_v2/Optimized_prompts/sql_random_search_3.json\"\n",
    "sql_random_search.save(path=save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_random_search._compiled = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dspy.teleprompt import MIPROv2\n",
    "\n",
    "teleprompter = MIPROv2(\n",
    "    metric=judge_adjusted,\n",
    "    verbose=True,\n",
    "    max_bootstrapped_demos = 0,\n",
    "    max_labeled_demos = 0,\n",
    "    auto=\"light\", # Can choose between light, medium, and heavy optimization runs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/23 12:13:49 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "RUNNING WITH THE FOLLOWING LIGHT AUTO RUN SETTINGS:\n",
      "num_trials: 7\n",
      "minibatch: True\n",
      "num_candidates: 4\n",
      "valset size: 62\n",
      "\n",
      "2024/12/23 12:13:49 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "==> STEP 1: BOOTSTRAP FEWSHOT EXAMPLES <==\n",
      "2024/12/23 12:13:49 INFO dspy.teleprompt.mipro_optimizer_v2: These will be used for informing instruction proposal.\n",
      "\n",
      "2024/12/23 12:13:49 INFO dspy.teleprompt.mipro_optimizer_v2: Bootstrapping N=4 sets of demonstrations...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapping set 1/4\n",
      "Bootstrapping set 2/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|‚ñã         | 1/16 [00:06<01:31,  6.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trace is being used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|‚ñà‚ñé        | 2/16 [00:15<01:54,  8.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trace is being used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|‚ñà‚ñâ        | 3/16 [00:20<01:29,  6.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trace is being used\n",
      "Bootstrapped 3 full traces after 3 examples for up to 1 rounds, amounting to 3 attempts.\n",
      "Bootstrapping set 3/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|‚ñã         | 1/16 [00:04<01:10,  4.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trace is being used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|‚ñà‚ñé        | 2/16 [00:09<01:05,  4.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trace is being used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|‚ñà‚ñâ        | 3/16 [00:15<01:05,  5.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trace is being used\n",
      "Bootstrapped 3 full traces after 3 examples for up to 1 rounds, amounting to 3 attempts.\n",
      "Bootstrapping set 4/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|‚ñã         | 1/16 [00:05<01:27,  5.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trace is being used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|‚ñà‚ñé        | 2/16 [00:11<01:23,  5.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trace is being used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|‚ñà‚ñâ        | 3/16 [00:17<01:15,  5.80s/it]\n",
      "2024/12/23 12:14:42 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "==> STEP 2: PROPOSE INSTRUCTION CANDIDATES <==\n",
      "2024/12/23 12:14:42 INFO dspy.teleprompt.mipro_optimizer_v2: We will use the few-shot examples from the previous step, a generated dataset summary, a summary of the program code, and a randomly selected prompting tip to propose instructions.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trace is being used\n",
      "Bootstrapped 3 full traces after 3 examples for up to 1 rounds, amounting to 3 attempts.\n",
      "Error getting source code: unhashable type: 'CodeOutput'.\n",
      "\n",
      "Running without program aware proposer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/23 12:14:53 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "Proposing instructions...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA SUMMARY: The dataset captures detailed logs of events related to cases involving fines and penalties, emphasizing statistical analysis through counts, averages, and frequencies of events such as \"Create Fine,\" \"Send Appeal to Prefecture,\" and \"Payment.\" Its well-structured questions indicate a focus on precise event tracking, potentially supporting automated reporting to enhance administrative efficiency. The large volume of records and use of comparative metrics suggest its utility in improving process optimization for case management systems.\n",
      "Using a randomly generated configuration for our grounded proposer.\n",
      "Selected tip: simple\n",
      "task_demos \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[34m[2024-12-23T12:14:56.186999]\u001b[0m\n",
      "\n",
      "\u001b[31mSystem message:\u001b[0m\n",
      "\n",
      "Your input fields are:\n",
      "1. `dataset_description` (str): A description of the dataset that we are using.\n",
      "2. `task_demos` (str): Example inputs/outputs of our module.\n",
      "3. `basic_instruction` (str): Basic instruction.\n",
      "4. `tip` (str): A suggestion for how to go about generating the new instruction.\n",
      "\n",
      "Your output fields are:\n",
      "1. `proposed_instruction` (str): Propose an instruction that will be used to prompt a Language Model to perform this task.\n",
      "\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## dataset_description ## ]]\n",
      "{dataset_description}\n",
      "\n",
      "[[ ## task_demos ## ]]\n",
      "{task_demos}\n",
      "\n",
      "[[ ## basic_instruction ## ]]\n",
      "{basic_instruction}\n",
      "\n",
      "[[ ## tip ## ]]\n",
      "{tip}\n",
      "\n",
      "[[ ## proposed_instruction ## ]]\n",
      "{proposed_instruction}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "In adhering to this structure, your objective is: \n",
      "        Use the information below to learn about a task that we are trying to solve using calls to an LM, then generate a new instruction that will be used to prompt a Language Model to better solve the task.\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## dataset_description ## ]]\n",
      "The dataset captures detailed logs of events related to cases involving fines and penalties, emphasizing statistical analysis through counts, averages, and frequencies of events such as \"Create Fine,\" \"Send Appeal to Prefecture,\" and \"Payment.\" Its well-structured questions indicate a focus on precise event tracking, potentially supporting automated reporting to enhance administrative efficiency. The large volume of records and use of comparative metrics suggest its utility in improving process optimization for case management systems.\n",
      "\n",
      "[[ ## task_demos ## ]]\n",
      "\n",
      "\n",
      "[[ ## basic_instruction ## ]]\n",
      "Generate a single SQLite query that returns the specific information requested in the question \n",
      "and include relevant details such as duration or amount. When asked about information pertaining \n",
      "to cases (not events), group by case to avoid counting the same case multiple times. Aggregate when necessary,\n",
      "using subqueries and outer queries to limit the output size and results in a table that answers the question directly.\n",
      "Be aware to make a distinction between questions that ask about cases and question that ask about events, since some of the available columns are aggregated over cases and might lead to wrong results when used in the wrong context.\n",
      "\n",
      "[[ ## tip ## ]]\n",
      "Keep the instruction clear and concise.\n",
      "\n",
      "Respond with the corresponding output fields, starting with the field `[[ ## proposed_instruction ## ]]`, and then ending with the marker for `[[ ## completed ## ]]`.\n",
      "\n",
      "\n",
      "\u001b[31mResponse:\u001b[0m\n",
      "\n",
      "\u001b[32m[[ ## proposed_instruction ## ]]\n",
      "Craft an SQLite query that accurately retrieves the requested data, ensuring to specify details like duration or amount where applicable. If the inquiry pertains to cases, ensure grouping by case to prevent duplicate counts. Use aggregation judiciously, employing subqueries and outer queries to refine the results and present a concise table that directly addresses the query. Differentiate between case-related and event-related questions, as some columns aggregate data over cases, which can lead to inaccuracies if misapplied.\n",
      "\n",
      "[[ ## completed ## ]]\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "PROPOSED INSTRUCTION: Craft an SQLite query that accurately retrieves the requested data, ensuring to specify details like duration or amount where applicable. If the inquiry pertains to cases, ensure grouping by case to prevent duplicate counts. Use aggregation judiciously, employing subqueries and outer queries to refine the results and present a concise table that directly addresses the query. Differentiate between case-related and event-related questions, as some columns aggregate data over cases, which can lead to inaccuracies if misapplied.\n",
      "Using a randomly generated configuration for our grounded proposer.\n",
      "Selected tip: persona\n",
      "task_demos Question: Which case has the most payment events?\n",
      "Column Description: THE DATABASE CONTAINS THE TABLE: event_log CONTAINING THE FOLLOWING COLUMNS (only the ones denoted by a \"-\", )\n",
      "- 'case_concept_name' (string): the case identifier, use this to group by cases (retrieve information about cases as a whole)\n",
      "- 'time_timestamp' (datetime): the timestamp of the activity.\n",
      "- 'payment_count' (int): The number of times the event 'Payment' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'send_for_credit_collection_count' (int): The number of times the event 'Send for Credit Collection' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'event_count' (int): The number of events recorded for each case, consistent across all rows pertaining to the same case.\n",
      "- 'credit_collected_AND_fully_paid' (int): A boolean indicator (stored as an integer) showing whether any event in a case involves both credit collection ('Send for Credit Collection') and full payment of the fine. 1 if any event in the case involves both, 0 otherwise. This value is consistent across all rows pertaining to the same case.\n",
      "- 'credit_collected' (int): A boolean indicator (stored as an integer) showing whether any event in a case involves sending the fine for credit collection ('Send for Credit Collection'). 1 if any event in the case involves credit collection, 0 otherwise. This value is consistent across all rows pertaining to the same case.\n",
      "- 'credit_collected_AND_dismissed' (int): A boolean indicator (stored as an integer) showing whether any event in a case involves both dismissal of the fine and credit collection. 1 if any event in the case involves both, 0 otherwise. This value is consistent across all rows pertaining to the same case.\n",
      "- 'insert_date_appeal_to_prefecture_count' (int): The number of times the event 'Insert Date Appeal to Prefecture' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'send_appeal_to_prefecture_count' (int): The number of times the event 'Send Appeal to Prefecture' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'appeal_to_judge_count' (int): The number of times the event 'Appeal to Judge' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "Approach: To find the case with the most payment events, we need to focus on the 'payment_count' column, which indicates the number of payment events for each case. Since this column is consistent across all rows for a given case, we can directly use it to identify the case with the maximum number of payments. The steps to construct the query are as follows: 1. Select the 'case_concept_name' and 'payment_count' columns from the 'event_log' table. 2. Order the results by 'payment_count' in descending order to bring the case with the highest payment count to the top. 3. Use the LIMIT clause to restrict the result to the top case(s) with the highest payment count. Since there might be multiple cases with the same highest payment count, consider using LIMIT 10 to capture all such cases. This will provide the case(s) with the most payment events.\n",
      "Sqlite Query: sql='SELECT case_concept_name, payment_count FROM event_log ORDER BY payment_count DESC LIMIT 1;'\n",
      "Question: How many cases are Sent for Credit Collection?\n",
      "Column Description: THE DATABASE CONTAINS THE TABLE: event_log CONTAINING THE FOLLOWING COLUMNS (only the ones denoted by a \"-\", )\n",
      "- 'case_concept_name' (string): the case identifier, use this to group by cases (retrieve information about cases as a whole)\n",
      "- 'time_timestamp' (datetime): the timestamp of the activity.\n",
      "- 'send_for_credit_collection_count' (int): The number of times the event 'Send for Credit Collection' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'credit_collected' (int): A boolean indicator (stored as an integer) showing whether any event in a case involves sending the fine for credit collection ('Send for Credit Collection'). 1 if any event in the case involves credit collection, 0 otherwise. This value is consistent across all rows pertaining to the same case.\n",
      "- 'credit_collected_AND_fully_paid' (int): A boolean indicator (stored as an integer) showing whether any event in a case involves both credit collection ('Send for Credit Collection') and full payment of the fine. 1 if any event in the case involves both, 0 otherwise. This value is consistent across all rows pertaining to the same case.\n",
      "- 'credit_collected_AND_dismissed' (int): A boolean indicator (stored as an integer) showing whether any event in a case involves both dismissal of the fine and credit collection. 1 if any event in the case involves both, 0 otherwise. This value is consistent across all rows pertaining to the same case.\n",
      "- 'unresolved' (int): A boolean indicator (stored as an integer) showing whether a case remains unresolved, i.e., not fully paid, not collected for credit, and not dismissed. 1 for unresolved, 0 otherwise. This value is consistent across all rows pertaining to the same case.\n",
      "- 'payment_count' (int): The number of times the event 'Payment' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'fully_paid' (int): A boolean indicator (stored as an integer) showing whether the outstanding balance for each case is zero or less, indicating that the fine has been fully paid. 1 for fully paid, 0 otherwise. This value is consistent across all rows pertaining to the same case.\n",
      "- 'appeal_to_judge_count' (int): The number of times the event 'Appeal to Judge' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'notify_result_appeal_to_offender_count' (int): The number of times the event 'Notify Result Appeal to Offender' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "Approach: To determine how many cases are 'Sent for Credit Collection', we need to use the 'credit_collected' column, which acts as a boolean indicator showing whether any event in a case involves sending the fine for credit collection. This value is consistent across all rows for a given case. Therefore, we need to count the distinct cases where 'credit_collected' equals 1. The query should group by 'case_concept_name' and filter the results where 'credit_collected' is 1, then count the number of distinct 'case_concept_name' values to obtain the total number of cases that have been sent for credit collection.\n",
      "Sqlite Query: sql='SELECT COUNT(DISTINCT case_concept_name) AS cases_sent_for_credit_collection FROM event_log WHERE credit_collected = 1;'\n",
      "Question: How many Add penalty events occur?\n",
      "Column Description: THE DATABASE CONTAINS THE TABLE: event_log CONTAINING THE FOLLOWING COLUMNS (only the ones denoted by a \"-\", )\n",
      "- 'case_concept_name' (string): the case identifier, use this to group by cases (retrieve information about cases as a whole)\n",
      "- 'time_timestamp' (datetime): the timestamp of the activity.\n",
      "- 'add_penalty_count' (int): The number of times the event 'Add penalty' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'penalty_added' (int): A boolean indicator (stored as an integer) showing whether any event in a case involves adding a penalty ('Add penalty'). 1 if any event in the case involves adding a penalty, 0 otherwise. This value is consistent across all rows pertaining to the same case.\n",
      "- 'insert_fine_notification_count' (int): The number of times the event 'Insert Fine Notification' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'event_count' (int): The number of events recorded for each case, consistent across all rows pertaining to the same case.\n",
      "- 'send_fine_count' (int): The number of times the event 'Send Fine' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'notify_result_appeal_to_offender_count' (int): The number of times the event 'Notify Result Appeal to Offender' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'concept_name' (string): the activity/ event type name\n",
      "    Activity Description, column: 'concept_name':\n",
      "        > 'Create Fine': The initial creation of the fine in the information system. It initializes event log attributes amount, dismissal, points and totalPaymentAmount.\n",
      "        > 'Send Fine': A notification about the fine is sent by post to the offender.\n",
      "        > 'Insert Fine Notification': The notification is received by the offender.\n",
      "        > 'Add penalty': An additional penalty is applied.\n",
      "        > 'Payment': A payment made by the offender is registered.\n",
      "        > 'Send for Credit Collection': Unpaid fines are sent for credit collection. A separate process is started by a collection agency to collect the money of the unpaid fines.\n",
      "        > 'Insert Date Appeal to Prefecture': The offender appeals against the fine to the prefecture. A prefecture in Italy is an administrative body representing the national government in each province.\n",
      "        > 'Send Appeal to Prefecture': The appeal is sent to the prefecture by the local police.\n",
      "        > 'Receive Result Appeal from Prefecture': The local police receives the result of the appeal. If the prefecture dismisses the fine, the appeal is deemed accepted, and the obligation to pay the fine is cancelled. In this case, there is no need for the police to receive the result from the prefecture (Receive Result Appeal from Prefecture) and notify the offender (Notify Result Appeal to Offender).\n",
      "        > 'Notify Result Appeal to Offender': The local police informs the offender of the appeal result. \n",
      "        > 'Appeal to Judge': The offender appeals against the fine to a judge.\n",
      "    IMPORTANT: The last event in a case can be arbitrary. There is no guarantee that the last event is 'Send Fine' or 'Payment'. The last event can be any event in the log.\n",
      "- 'insert_date_appeal_to_prefecture_count' (int): The number of times the event 'Insert Date Appeal to Prefecture' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'send_for_credit_collection_count' (int): The number of times the event 'Send for Credit Collection' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "Approach: To determine the total number of 'Add penalty' events, we should use the 'add_penalty_count' column, which records the number of 'Add penalty' events for each case. Since this column is consistent across all rows of the same case, we can sum the 'add_penalty_count' values across all cases to get the total number of 'Add penalty' events. The query should select the sum of 'add_penalty_count' from the 'event_log' table, ensuring that each case is only counted once by using a GROUP BY clause on 'case_concept_name'. This will prevent counting the same 'add_penalty_count' value multiple times for cases with multiple events.\n",
      "Sqlite Query: sql='SELECT SUM(add_penalty_count) AS total_add_penalty_events FROM (SELECT DISTINCT case_concept_name, add_penalty_count FROM event_log);'\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[34m[2024-12-23T12:14:59.684964]\u001b[0m\n",
      "\n",
      "\u001b[31mSystem message:\u001b[0m\n",
      "\n",
      "Your input fields are:\n",
      "1. `dataset_description` (str): A description of the dataset that we are using.\n",
      "2. `task_demos` (str): Example inputs/outputs of our module.\n",
      "3. `basic_instruction` (str): Basic instruction.\n",
      "4. `tip` (str): A suggestion for how to go about generating the new instruction.\n",
      "\n",
      "Your output fields are:\n",
      "1. `proposed_instruction` (str): Propose an instruction that will be used to prompt a Language Model to perform this task.\n",
      "\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## dataset_description ## ]]\n",
      "{dataset_description}\n",
      "\n",
      "[[ ## task_demos ## ]]\n",
      "{task_demos}\n",
      "\n",
      "[[ ## basic_instruction ## ]]\n",
      "{basic_instruction}\n",
      "\n",
      "[[ ## tip ## ]]\n",
      "{tip}\n",
      "\n",
      "[[ ## proposed_instruction ## ]]\n",
      "{proposed_instruction}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "In adhering to this structure, your objective is: \n",
      "        Use the information below to learn about a task that we are trying to solve using calls to an LM, then generate a new instruction that will be used to prompt a Language Model to better solve the task.\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## dataset_description ## ]]\n",
      "The dataset captures detailed logs of events related to cases involving fines and penalties, emphasizing statistical analysis through counts, averages, and frequencies of events such as \"Create Fine,\" \"Send Appeal to Prefecture,\" and \"Payment.\" Its well-structured questions indicate a focus on precise event tracking, potentially supporting automated reporting to enhance administrative efficiency. The large volume of records and use of comparative metrics suggest its utility in improving process optimization for case management systems.\n",
      "\n",
      "[[ ## task_demos ## ]]\n",
      "Question: Which case has the most payment events?\n",
      "Column Description: THE DATABASE CONTAINS THE TABLE: event_log CONTAINING THE FOLLOWING COLUMNS (only the ones denoted by a \"-\", )\n",
      "- 'case_concept_name' (string): the case identifier, use this to group by cases (retrieve information about cases as a whole)\n",
      "- 'time_timestamp' (datetime): the timestamp of the activity.\n",
      "- 'payment_count' (int): The number of times the event 'Payment' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'send_for_credit_collection_count' (int): The number of times the event 'Send for Credit Collection' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'event_count' (int): The number of events recorded for each case, consistent across all rows pertaining to the same case.\n",
      "- 'credit_collected_AND_fully_paid' (int): A boolean indicator (stored as an integer) showing whether any event in a case involves both credit collection ('Send for Credit Collection') and full payment of the fine. 1 if any event in the case involves both, 0 otherwise. This value is consistent across all rows pertaining to the same case.\n",
      "- 'credit_collected' (int): A boolean indicator (stored as an integer) showing whether any event in a case involves sending the fine for credit collection ('Send for Credit Collection'). 1 if any event in the case involves credit collection, 0 otherwise. This value is consistent across all rows pertaining to the same case.\n",
      "- 'credit_collected_AND_dismissed' (int): A boolean indicator (stored as an integer) showing whether any event in a case involves both dismissal of the fine and credit collection. 1 if any event in the case involves both, 0 otherwise. This value is consistent across all rows pertaining to the same case.\n",
      "- 'insert_date_appeal_to_prefecture_count' (int): The number of times the event 'Insert Date Appeal to Prefecture' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'send_appeal_to_prefecture_count' (int): The number of times the event 'Send Appeal to Prefecture' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'appeal_to_judge_count' (int): The number of times the event 'Appeal to Judge' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "Approach: To find the case with the most payment events, we need to focus on the 'payment_count' column, which indicates the number of payment events for each case. Since this column is consistent across all rows for a given case, we can directly use it to identify the case with the maximum number of payments. The steps to construct the query are as follows: 1. Select the 'case_concept_name' and 'payment_count' columns from the 'event_log' table. 2. Order the results by 'payment_count' in descending order to bring the case with the highest payment count to the top. 3. Use the LIMIT clause to restrict the result to the top case(s) with the highest payment count. Since there might be multiple cases with the same highest payment count, consider using LIMIT 10 to capture all such cases. This will provide the case(s) with the most payment events.\n",
      "Sqlite Query: sql='SELECT case_concept_name, payment_count FROM event_log ORDER BY payment_count DESC LIMIT 1;'\n",
      "Question: How many cases are Sent for Credit Collection?\n",
      "Column Description: THE DATABASE CONTAINS THE TABLE: event_log CONTAINING THE FOLLOWING COLUMNS (only the ones denoted by a \"-\", )\n",
      "- 'case_concept_name' (string): the case identifier, use this to group by cases (retrieve information about cases as a whole)\n",
      "- 'time_timestamp' (datetime): the timestamp of the activity.\n",
      "- 'send_for_credit_collection_count' (int): The number of times the event 'Send for Credit Collection' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'credit_collected' (int): A boolean indicator (stored as an integer) showing whether any event in a case involves sending the fine for credit collection ('Send for Credit Collection'). 1 if any event in the case involves credit collection, 0 otherwise. This value is consistent across all rows pertaining to the same case.\n",
      "- 'credit_collected_AND_fully_paid' (int): A boolean indicator (stored as an integer) showing whether any event in a case involves both credit collection ('Send for Credit Collection') and full payment of the fine. 1 if any event in the case involves both, 0 otherwise. This value is consistent across all rows pertaining to the same case.\n",
      "- 'credit_collected_AND_dismissed' (int): A boolean indicator (stored as an integer) showing whether any event in a case involves both dismissal of the fine and credit collection. 1 if any event in the case involves both, 0 otherwise. This value is consistent across all rows pertaining to the same case.\n",
      "- 'unresolved' (int): A boolean indicator (stored as an integer) showing whether a case remains unresolved, i.e., not fully paid, not collected for credit, and not dismissed. 1 for unresolved, 0 otherwise. This value is consistent across all rows pertaining to the same case.\n",
      "- 'payment_count' (int): The number of times the event 'Payment' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'fully_paid' (int): A boolean indicator (stored as an integer) showing whether the outstanding balance for each case is zero or less, indicating that the fine has been fully paid. 1 for fully paid, 0 otherwise. This value is consistent across all rows pertaining to the same case.\n",
      "- 'appeal_to_judge_count' (int): The number of times the event 'Appeal to Judge' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'notify_result_appeal_to_offender_count' (int): The number of times the event 'Notify Result Appeal to Offender' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "Approach: To determine how many cases are 'Sent for Credit Collection', we need to use the 'credit_collected' column, which acts as a boolean indicator showing whether any event in a case involves sending the fine for credit collection. This value is consistent across all rows for a given case. Therefore, we need to count the distinct cases where 'credit_collected' equals 1. The query should group by 'case_concept_name' and filter the results where 'credit_collected' is 1, then count the number of distinct 'case_concept_name' values to obtain the total number of cases that have been sent for credit collection.\n",
      "Sqlite Query: sql='SELECT COUNT(DISTINCT case_concept_name) AS cases_sent_for_credit_collection FROM event_log WHERE credit_collected = 1;'\n",
      "Question: How many Add penalty events occur?\n",
      "Column Description: THE DATABASE CONTAINS THE TABLE: event_log CONTAINING THE FOLLOWING COLUMNS (only the ones denoted by a \"-\", )\n",
      "- 'case_concept_name' (string): the case identifier, use this to group by cases (retrieve information about cases as a whole)\n",
      "- 'time_timestamp' (datetime): the timestamp of the activity.\n",
      "- 'add_penalty_count' (int): The number of times the event 'Add penalty' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'penalty_added' (int): A boolean indicator (stored as an integer) showing whether any event in a case involves adding a penalty ('Add penalty'). 1 if any event in the case involves adding a penalty, 0 otherwise. This value is consistent across all rows pertaining to the same case.\n",
      "- 'insert_fine_notification_count' (int): The number of times the event 'Insert Fine Notification' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'event_count' (int): The number of events recorded for each case, consistent across all rows pertaining to the same case.\n",
      "- 'send_fine_count' (int): The number of times the event 'Send Fine' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'notify_result_appeal_to_offender_count' (int): The number of times the event 'Notify Result Appeal to Offender' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'concept_name' (string): the activity/ event type name\n",
      "    Activity Description, column: 'concept_name':\n",
      "        > 'Create Fine': The initial creation of the fine in the information system. It initializes event log attributes amount, dismissal, points and totalPaymentAmount.\n",
      "        > 'Send Fine': A notification about the fine is sent by post to the offender.\n",
      "        > 'Insert Fine Notification': The notification is received by the offender.\n",
      "        > 'Add penalty': An additional penalty is applied.\n",
      "        > 'Payment': A payment made by the offender is registered.\n",
      "        > 'Send for Credit Collection': Unpaid fines are sent for credit collection. A separate process is started by a collection agency to collect the money of the unpaid fines.\n",
      "        > 'Insert Date Appeal to Prefecture': The offender appeals against the fine to the prefecture. A prefecture in Italy is an administrative body representing the national government in each province.\n",
      "        > 'Send Appeal to Prefecture': The appeal is sent to the prefecture by the local police.\n",
      "        > 'Receive Result Appeal from Prefecture': The local police receives the result of the appeal. If the prefecture dismisses the fine, the appeal is deemed accepted, and the obligation to pay the fine is cancelled. In this case, there is no need for the police to receive the result from the prefecture (Receive Result Appeal from Prefecture) and notify the offender (Notify Result Appeal to Offender).\n",
      "        > 'Notify Result Appeal to Offender': The local police informs the offender of the appeal result. \n",
      "        > 'Appeal to Judge': The offender appeals against the fine to a judge.\n",
      "    IMPORTANT: The last event in a case can be arbitrary. There is no guarantee that the last event is 'Send Fine' or 'Payment'. The last event can be any event in the log.\n",
      "- 'insert_date_appeal_to_prefecture_count' (int): The number of times the event 'Insert Date Appeal to Prefecture' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'send_for_credit_collection_count' (int): The number of times the event 'Send for Credit Collection' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "Approach: To determine the total number of 'Add penalty' events, we should use the 'add_penalty_count' column, which records the number of 'Add penalty' events for each case. Since this column is consistent across all rows of the same case, we can sum the 'add_penalty_count' values across all cases to get the total number of 'Add penalty' events. The query should select the sum of 'add_penalty_count' from the 'event_log' table, ensuring that each case is only counted once by using a GROUP BY clause on 'case_concept_name'. This will prevent counting the same 'add_penalty_count' value multiple times for cases with multiple events.\n",
      "Sqlite Query: sql='SELECT SUM(add_penalty_count) AS total_add_penalty_events FROM (SELECT DISTINCT case_concept_name, add_penalty_count FROM event_log);'\n",
      "\n",
      "\n",
      "[[ ## basic_instruction ## ]]\n",
      "Generate a single SQLite query that returns the specific information requested in the question \n",
      "and include relevant details such as duration or amount. When asked about information pertaining \n",
      "to cases (not events), group by case to avoid counting the same case multiple times. Aggregate when necessary,\n",
      "using subqueries and outer queries to limit the output size and results in a table that answers the question directly.\n",
      "Be aware to make a distinction between questions that ask about cases and question that ask about events, since some of the available columns are aggregated over cases and might lead to wrong results when used in the wrong context.\n",
      "\n",
      "[[ ## tip ## ]]\n",
      "Include a persona that is relevant to the task in the instruction (ie. \"You are a ...\")\n",
      "\n",
      "Respond with the corresponding output fields, starting with the field `[[ ## proposed_instruction ## ]]`, and then ending with the marker for `[[ ## completed ## ]]`.\n",
      "\n",
      "\n",
      "\u001b[31mResponse:\u001b[0m\n",
      "\n",
      "\u001b[32m[[ ## proposed_instruction ## ]]\n",
      "You are a data analyst tasked with generating a single SQLite query to extract precise information from a detailed event log database concerning cases involving fines and penalties. Your goal is to construct a query that returns the specific information requested in the question, such as counts, averages, or frequencies of events like \"Create Fine\" or \"Payment.\" Ensure that when questions pertain to cases, you group by the case identifier to avoid counting the same case multiple times. Use aggregation functions and subqueries as needed to provide a concise and direct answer, and include additional relevant details like duration or amount. Be cautious to distinguish between questions about cases and those about events to avoid using aggregated columns incorrectly.\n",
      "\n",
      "[[ ## completed ## ]]\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "PROPOSED INSTRUCTION: You are a data analyst tasked with generating a single SQLite query to extract precise information from a detailed event log database concerning cases involving fines and penalties. Your goal is to construct a query that returns the specific information requested in the question, such as counts, averages, or frequencies of events like \"Create Fine\" or \"Payment.\" Ensure that when questions pertain to cases, you group by the case identifier to avoid counting the same case multiple times. Use aggregation functions and subqueries as needed to provide a concise and direct answer, and include additional relevant details like duration or amount. Be cautious to distinguish between questions about cases and those about events to avoid using aggregated columns incorrectly.\n",
      "Using a randomly generated configuration for our grounded proposer.\n",
      "Selected tip: high_stakes\n",
      "task_demos Question: How many cases are in the log?\n",
      "Column Description: THE DATABASE CONTAINS THE TABLE: event_log CONTAINING THE FOLLOWING COLUMNS (only the ones denoted by a \"-\", )\n",
      "- 'case_concept_name' (string): the case identifier, use this to group by cases (retrieve information about cases as a whole)\n",
      "- 'time_timestamp' (datetime): the timestamp of the activity.\n",
      "- 'event_count' (int): The number of events recorded for each case, consistent across all rows pertaining to the same case.\n",
      "- 'notify_result_appeal_to_offender_count' (int): The number of times the event 'Notify Result Appeal to Offender' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'appeal_to_judge_count' (int): The number of times the event 'Appeal to Judge' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'receive_result_appeal_from_prefecture_count' (int): The number of times the event 'Receive Result Appeal from Prefecture' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'insert_date_appeal_to_prefecture_count' (int): The number of times the event 'Insert Date Appeal to Prefecture' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'send_appeal_to_prefecture_count' (int): The number of times the event 'Send Appeal to Prefecture' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'insert_fine_notification_count' (int): The number of times the event 'Insert Fine Notification' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'send_fine_count' (int): The number of times the event 'Send Fine' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'add_penalty_count' (int): The number of times the event 'Add penalty' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "Approach: To determine the number of cases in the log, we need to count the distinct values of the 'case_concept_name' column. This column serves as the unique identifier for each case and remains consistent across all events pertaining to the same case. Therefore, the query should select the distinct 'case_concept_name' values and count them. This will give us the total number of unique cases in the event log. The SQL query would look like: SELECT COUNT(DISTINCT case_concept_name) FROM event_log.\n",
      "Sqlite Query: sql='SELECT COUNT(DISTINCT case_concept_name) AS number_of_cases FROM event_log;'\n",
      "Question: How many Create Fine events occur?\n",
      "Column Description: THE DATABASE CONTAINS THE TABLE: event_log CONTAINING THE FOLLOWING COLUMNS (only the ones denoted by a \"-\", )\n",
      "- 'case_concept_name' (string): the case identifier, use this to group by cases (retrieve information about cases as a whole)\n",
      "- 'time_timestamp' (datetime): the timestamp of the activity.\n",
      "- 'insert_fine_notification_count' (int): The number of times the event 'Insert Fine Notification' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'send_fine_count' (int): The number of times the event 'Send Fine' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'event_count' (int): The number of events recorded for each case, consistent across all rows pertaining to the same case.\n",
      "- 'add_penalty_count' (int): The number of times the event 'Add penalty' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'concept_name' (string): the activity/ event type name\n",
      "    Activity Description, column: 'concept_name':\n",
      "        > 'Create Fine': The initial creation of the fine in the information system. It initializes event log attributes amount, dismissal, points and totalPaymentAmount.\n",
      "        > 'Send Fine': A notification about the fine is sent by post to the offender.\n",
      "        > 'Insert Fine Notification': The notification is received by the offender.\n",
      "        > 'Add penalty': An additional penalty is applied.\n",
      "        > 'Payment': A payment made by the offender is registered.\n",
      "        > 'Send for Credit Collection': Unpaid fines are sent for credit collection. A separate process is started by a collection agency to collect the money of the unpaid fines.\n",
      "        > 'Insert Date Appeal to Prefecture': The offender appeals against the fine to the prefecture. A prefecture in Italy is an administrative body representing the national government in each province.\n",
      "        > 'Send Appeal to Prefecture': The appeal is sent to the prefecture by the local police.\n",
      "        > 'Receive Result Appeal from Prefecture': The local police receives the result of the appeal. If the prefecture dismisses the fine, the appeal is deemed accepted, and the obligation to pay the fine is cancelled. In this case, there is no need for the police to receive the result from the prefecture (Receive Result Appeal from Prefecture) and notify the offender (Notify Result Appeal to Offender).\n",
      "        > 'Notify Result Appeal to Offender': The local police informs the offender of the appeal result. \n",
      "        > 'Appeal to Judge': The offender appeals against the fine to a judge.\n",
      "    IMPORTANT: The last event in a case can be arbitrary. There is no guarantee that the last event is 'Send Fine' or 'Payment'. The last event can be any event in the log.\n",
      "- 'insert_date_appeal_to_prefecture_count' (int): The number of times the event 'Insert Date Appeal to Prefecture' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'send_for_credit_collection_count' (int): The number of times the event 'Send for Credit Collection' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'send_appeal_to_prefecture_count' (int): The number of times the event 'Send Appeal to Prefecture' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'notify_result_appeal_to_offender_count' (int): The number of times the event 'Notify Result Appeal to Offender' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "Approach: To determine the number of 'Create Fine' events, we need to count the occurrences of rows in the 'event_log' table where the 'concept_name' column is equal to 'Create Fine'. The 'concept_name' column specifies the type of event for each row, and each row represents an individual event. Therefore, the query should be structured to select and count all rows where 'concept_name' = 'Create Fine'. The query will look like: SELECT COUNT(*) FROM event_log WHERE concept_name = 'Create Fine'. This will provide the total number of 'Create Fine' events recorded in the database.\n",
      "Sqlite Query: sql=\"SELECT COUNT(*) FROM event_log WHERE concept_name = 'Create Fine';\"\n",
      "Question: How many Add penalty events occur?\n",
      "Column Description: THE DATABASE CONTAINS THE TABLE: event_log CONTAINING THE FOLLOWING COLUMNS (only the ones denoted by a \"-\", )\n",
      "- 'case_concept_name' (string): the case identifier, use this to group by cases (retrieve information about cases as a whole)\n",
      "- 'time_timestamp' (datetime): the timestamp of the activity.\n",
      "- 'add_penalty_count' (int): The number of times the event 'Add penalty' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'penalty_added' (int): A boolean indicator (stored as an integer) showing whether any event in a case involves adding a penalty ('Add penalty'). 1 if any event in the case involves adding a penalty, 0 otherwise. This value is consistent across all rows pertaining to the same case.\n",
      "- 'insert_fine_notification_count' (int): The number of times the event 'Insert Fine Notification' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'event_count' (int): The number of events recorded for each case, consistent across all rows pertaining to the same case.\n",
      "- 'send_fine_count' (int): The number of times the event 'Send Fine' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'notify_result_appeal_to_offender_count' (int): The number of times the event 'Notify Result Appeal to Offender' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'concept_name' (string): the activity/ event type name\n",
      "    Activity Description, column: 'concept_name':\n",
      "        > 'Create Fine': The initial creation of the fine in the information system. It initializes event log attributes amount, dismissal, points and totalPaymentAmount.\n",
      "        > 'Send Fine': A notification about the fine is sent by post to the offender.\n",
      "        > 'Insert Fine Notification': The notification is received by the offender.\n",
      "        > 'Add penalty': An additional penalty is applied.\n",
      "        > 'Payment': A payment made by the offender is registered.\n",
      "        > 'Send for Credit Collection': Unpaid fines are sent for credit collection. A separate process is started by a collection agency to collect the money of the unpaid fines.\n",
      "        > 'Insert Date Appeal to Prefecture': The offender appeals against the fine to the prefecture. A prefecture in Italy is an administrative body representing the national government in each province.\n",
      "        > 'Send Appeal to Prefecture': The appeal is sent to the prefecture by the local police.\n",
      "        > 'Receive Result Appeal from Prefecture': The local police receives the result of the appeal. If the prefecture dismisses the fine, the appeal is deemed accepted, and the obligation to pay the fine is cancelled. In this case, there is no need for the police to receive the result from the prefecture (Receive Result Appeal from Prefecture) and notify the offender (Notify Result Appeal to Offender).\n",
      "        > 'Notify Result Appeal to Offender': The local police informs the offender of the appeal result. \n",
      "        > 'Appeal to Judge': The offender appeals against the fine to a judge.\n",
      "    IMPORTANT: The last event in a case can be arbitrary. There is no guarantee that the last event is 'Send Fine' or 'Payment'. The last event can be any event in the log.\n",
      "- 'insert_date_appeal_to_prefecture_count' (int): The number of times the event 'Insert Date Appeal to Prefecture' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'send_for_credit_collection_count' (int): The number of times the event 'Send for Credit Collection' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "Approach: To determine the total number of 'Add penalty' events, we should use the 'add_penalty_count' column, which records the number of 'Add penalty' events for each case. Since this column is consistent across all rows of the same case, we can sum the 'add_penalty_count' values across all cases to get the total number of 'Add penalty' events. The query should select the sum of 'add_penalty_count' from the 'event_log' table, ensuring that each case is only counted once by using a GROUP BY clause on 'case_concept_name'. This will prevent counting the same 'add_penalty_count' value multiple times for cases with multiple events.\n",
      "Sqlite Query: sql='SELECT SUM(add_penalty_count) AS total_add_penalty_events FROM (SELECT DISTINCT case_concept_name, add_penalty_count FROM event_log);'\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[34m[2024-12-23T12:15:02.599440]\u001b[0m\n",
      "\n",
      "\u001b[31mSystem message:\u001b[0m\n",
      "\n",
      "Your input fields are:\n",
      "1. `dataset_description` (str): A description of the dataset that we are using.\n",
      "2. `task_demos` (str): Example inputs/outputs of our module.\n",
      "3. `basic_instruction` (str): Basic instruction.\n",
      "4. `tip` (str): A suggestion for how to go about generating the new instruction.\n",
      "\n",
      "Your output fields are:\n",
      "1. `proposed_instruction` (str): Propose an instruction that will be used to prompt a Language Model to perform this task.\n",
      "\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## dataset_description ## ]]\n",
      "{dataset_description}\n",
      "\n",
      "[[ ## task_demos ## ]]\n",
      "{task_demos}\n",
      "\n",
      "[[ ## basic_instruction ## ]]\n",
      "{basic_instruction}\n",
      "\n",
      "[[ ## tip ## ]]\n",
      "{tip}\n",
      "\n",
      "[[ ## proposed_instruction ## ]]\n",
      "{proposed_instruction}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "In adhering to this structure, your objective is: \n",
      "        Use the information below to learn about a task that we are trying to solve using calls to an LM, then generate a new instruction that will be used to prompt a Language Model to better solve the task.\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## dataset_description ## ]]\n",
      "The dataset captures detailed logs of events related to cases involving fines and penalties, emphasizing statistical analysis through counts, averages, and frequencies of events such as \"Create Fine,\" \"Send Appeal to Prefecture,\" and \"Payment.\" Its well-structured questions indicate a focus on precise event tracking, potentially supporting automated reporting to enhance administrative efficiency. The large volume of records and use of comparative metrics suggest its utility in improving process optimization for case management systems.\n",
      "\n",
      "[[ ## task_demos ## ]]\n",
      "Question: How many cases are in the log?\n",
      "Column Description: THE DATABASE CONTAINS THE TABLE: event_log CONTAINING THE FOLLOWING COLUMNS (only the ones denoted by a \"-\", )\n",
      "- 'case_concept_name' (string): the case identifier, use this to group by cases (retrieve information about cases as a whole)\n",
      "- 'time_timestamp' (datetime): the timestamp of the activity.\n",
      "- 'event_count' (int): The number of events recorded for each case, consistent across all rows pertaining to the same case.\n",
      "- 'notify_result_appeal_to_offender_count' (int): The number of times the event 'Notify Result Appeal to Offender' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'appeal_to_judge_count' (int): The number of times the event 'Appeal to Judge' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'receive_result_appeal_from_prefecture_count' (int): The number of times the event 'Receive Result Appeal from Prefecture' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'insert_date_appeal_to_prefecture_count' (int): The number of times the event 'Insert Date Appeal to Prefecture' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'send_appeal_to_prefecture_count' (int): The number of times the event 'Send Appeal to Prefecture' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'insert_fine_notification_count' (int): The number of times the event 'Insert Fine Notification' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'send_fine_count' (int): The number of times the event 'Send Fine' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'add_penalty_count' (int): The number of times the event 'Add penalty' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "Approach: To determine the number of cases in the log, we need to count the distinct values of the 'case_concept_name' column. This column serves as the unique identifier for each case and remains consistent across all events pertaining to the same case. Therefore, the query should select the distinct 'case_concept_name' values and count them. This will give us the total number of unique cases in the event log. The SQL query would look like: SELECT COUNT(DISTINCT case_concept_name) FROM event_log.\n",
      "Sqlite Query: sql='SELECT COUNT(DISTINCT case_concept_name) AS number_of_cases FROM event_log;'\n",
      "Question: How many Create Fine events occur?\n",
      "Column Description: THE DATABASE CONTAINS THE TABLE: event_log CONTAINING THE FOLLOWING COLUMNS (only the ones denoted by a \"-\", )\n",
      "- 'case_concept_name' (string): the case identifier, use this to group by cases (retrieve information about cases as a whole)\n",
      "- 'time_timestamp' (datetime): the timestamp of the activity.\n",
      "- 'insert_fine_notification_count' (int): The number of times the event 'Insert Fine Notification' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'send_fine_count' (int): The number of times the event 'Send Fine' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'event_count' (int): The number of events recorded for each case, consistent across all rows pertaining to the same case.\n",
      "- 'add_penalty_count' (int): The number of times the event 'Add penalty' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'concept_name' (string): the activity/ event type name\n",
      "    Activity Description, column: 'concept_name':\n",
      "        > 'Create Fine': The initial creation of the fine in the information system. It initializes event log attributes amount, dismissal, points and totalPaymentAmount.\n",
      "        > 'Send Fine': A notification about the fine is sent by post to the offender.\n",
      "        > 'Insert Fine Notification': The notification is received by the offender.\n",
      "        > 'Add penalty': An additional penalty is applied.\n",
      "        > 'Payment': A payment made by the offender is registered.\n",
      "        > 'Send for Credit Collection': Unpaid fines are sent for credit collection. A separate process is started by a collection agency to collect the money of the unpaid fines.\n",
      "        > 'Insert Date Appeal to Prefecture': The offender appeals against the fine to the prefecture. A prefecture in Italy is an administrative body representing the national government in each province.\n",
      "        > 'Send Appeal to Prefecture': The appeal is sent to the prefecture by the local police.\n",
      "        > 'Receive Result Appeal from Prefecture': The local police receives the result of the appeal. If the prefecture dismisses the fine, the appeal is deemed accepted, and the obligation to pay the fine is cancelled. In this case, there is no need for the police to receive the result from the prefecture (Receive Result Appeal from Prefecture) and notify the offender (Notify Result Appeal to Offender).\n",
      "        > 'Notify Result Appeal to Offender': The local police informs the offender of the appeal result. \n",
      "        > 'Appeal to Judge': The offender appeals against the fine to a judge.\n",
      "    IMPORTANT: The last event in a case can be arbitrary. There is no guarantee that the last event is 'Send Fine' or 'Payment'. The last event can be any event in the log.\n",
      "- 'insert_date_appeal_to_prefecture_count' (int): The number of times the event 'Insert Date Appeal to Prefecture' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'send_for_credit_collection_count' (int): The number of times the event 'Send for Credit Collection' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'send_appeal_to_prefecture_count' (int): The number of times the event 'Send Appeal to Prefecture' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'notify_result_appeal_to_offender_count' (int): The number of times the event 'Notify Result Appeal to Offender' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "Approach: To determine the number of 'Create Fine' events, we need to count the occurrences of rows in the 'event_log' table where the 'concept_name' column is equal to 'Create Fine'. The 'concept_name' column specifies the type of event for each row, and each row represents an individual event. Therefore, the query should be structured to select and count all rows where 'concept_name' = 'Create Fine'. The query will look like: SELECT COUNT(*) FROM event_log WHERE concept_name = 'Create Fine'. This will provide the total number of 'Create Fine' events recorded in the database.\n",
      "Sqlite Query: sql=\"SELECT COUNT(*) FROM event_log WHERE concept_name = 'Create Fine';\"\n",
      "Question: How many Add penalty events occur?\n",
      "Column Description: THE DATABASE CONTAINS THE TABLE: event_log CONTAINING THE FOLLOWING COLUMNS (only the ones denoted by a \"-\", )\n",
      "- 'case_concept_name' (string): the case identifier, use this to group by cases (retrieve information about cases as a whole)\n",
      "- 'time_timestamp' (datetime): the timestamp of the activity.\n",
      "- 'add_penalty_count' (int): The number of times the event 'Add penalty' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'penalty_added' (int): A boolean indicator (stored as an integer) showing whether any event in a case involves adding a penalty ('Add penalty'). 1 if any event in the case involves adding a penalty, 0 otherwise. This value is consistent across all rows pertaining to the same case.\n",
      "- 'insert_fine_notification_count' (int): The number of times the event 'Insert Fine Notification' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'event_count' (int): The number of events recorded for each case, consistent across all rows pertaining to the same case.\n",
      "- 'send_fine_count' (int): The number of times the event 'Send Fine' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'notify_result_appeal_to_offender_count' (int): The number of times the event 'Notify Result Appeal to Offender' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'concept_name' (string): the activity/ event type name\n",
      "    Activity Description, column: 'concept_name':\n",
      "        > 'Create Fine': The initial creation of the fine in the information system. It initializes event log attributes amount, dismissal, points and totalPaymentAmount.\n",
      "        > 'Send Fine': A notification about the fine is sent by post to the offender.\n",
      "        > 'Insert Fine Notification': The notification is received by the offender.\n",
      "        > 'Add penalty': An additional penalty is applied.\n",
      "        > 'Payment': A payment made by the offender is registered.\n",
      "        > 'Send for Credit Collection': Unpaid fines are sent for credit collection. A separate process is started by a collection agency to collect the money of the unpaid fines.\n",
      "        > 'Insert Date Appeal to Prefecture': The offender appeals against the fine to the prefecture. A prefecture in Italy is an administrative body representing the national government in each province.\n",
      "        > 'Send Appeal to Prefecture': The appeal is sent to the prefecture by the local police.\n",
      "        > 'Receive Result Appeal from Prefecture': The local police receives the result of the appeal. If the prefecture dismisses the fine, the appeal is deemed accepted, and the obligation to pay the fine is cancelled. In this case, there is no need for the police to receive the result from the prefecture (Receive Result Appeal from Prefecture) and notify the offender (Notify Result Appeal to Offender).\n",
      "        > 'Notify Result Appeal to Offender': The local police informs the offender of the appeal result. \n",
      "        > 'Appeal to Judge': The offender appeals against the fine to a judge.\n",
      "    IMPORTANT: The last event in a case can be arbitrary. There is no guarantee that the last event is 'Send Fine' or 'Payment'. The last event can be any event in the log.\n",
      "- 'insert_date_appeal_to_prefecture_count' (int): The number of times the event 'Insert Date Appeal to Prefecture' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'send_for_credit_collection_count' (int): The number of times the event 'Send for Credit Collection' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "Approach: To determine the total number of 'Add penalty' events, we should use the 'add_penalty_count' column, which records the number of 'Add penalty' events for each case. Since this column is consistent across all rows of the same case, we can sum the 'add_penalty_count' values across all cases to get the total number of 'Add penalty' events. The query should select the sum of 'add_penalty_count' from the 'event_log' table, ensuring that each case is only counted once by using a GROUP BY clause on 'case_concept_name'. This will prevent counting the same 'add_penalty_count' value multiple times for cases with multiple events.\n",
      "Sqlite Query: sql='SELECT SUM(add_penalty_count) AS total_add_penalty_events FROM (SELECT DISTINCT case_concept_name, add_penalty_count FROM event_log);'\n",
      "\n",
      "\n",
      "[[ ## basic_instruction ## ]]\n",
      "Generate a single SQLite query that returns the specific information requested in the question \n",
      "and include relevant details such as duration or amount. When asked about information pertaining \n",
      "to cases (not events), group by case to avoid counting the same case multiple times. Aggregate when necessary,\n",
      "using subqueries and outer queries to limit the output size and results in a table that answers the question directly.\n",
      "Be aware to make a distinction between questions that ask about cases and question that ask about events, since some of the available columns are aggregated over cases and might lead to wrong results when used in the wrong context.\n",
      "\n",
      "[[ ## tip ## ]]\n",
      "The instruction should include a high stakes scenario in which the LM must solve the task!\n",
      "\n",
      "Respond with the corresponding output fields, starting with the field `[[ ## proposed_instruction ## ]]`, and then ending with the marker for `[[ ## completed ## ]]`.\n",
      "\n",
      "\n",
      "\u001b[31mResponse:\u001b[0m\n",
      "\n",
      "\u001b[32m[[ ## proposed_instruction ## ]]\n",
      "Imagine you are tasked with generating a critical report for the city's administrative body to assess the efficiency of their case management system. Your goal is to write a precise SQLite query that extracts specific information from the event log database. This query must accurately differentiate between case-related and event-related questions, ensuring that aggregated data is grouped appropriately to prevent misinterpretation. Your report will influence key decisions on process optimization, so it is essential to ensure the accuracy and reliability of the data you provide. Use subqueries and outer queries effectively to handle complex data retrieval, and always keep in mind the distinction between cases and events to avoid skewing the results.\n",
      "\n",
      "[[ ## completed ## ]]\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "PROPOSED INSTRUCTION: Imagine you are tasked with generating a critical report for the city's administrative body to assess the efficiency of their case management system. Your goal is to write a precise SQLite query that extracts specific information from the event log database. This query must accurately differentiate between case-related and event-related questions, ensuring that aggregated data is grouped appropriately to prevent misinterpretation. Your report will influence key decisions on process optimization, so it is essential to ensure the accuracy and reliability of the data you provide. Use subqueries and outer queries effectively to handle complex data retrieval, and always keep in mind the distinction between cases and events to avoid skewing the results.\n",
      "Using a randomly generated configuration for our grounded proposer.\n",
      "Selected tip: none\n",
      "task_demos Question: How many cases have been added two or more penalties?\n",
      "Column Description: THE DATABASE CONTAINS THE TABLE: event_log CONTAINING THE FOLLOWING COLUMNS (only the ones denoted by a \"-\", )\n",
      "- 'case_concept_name' (string): the case identifier, use this to group by cases (retrieve information about cases as a whole)\n",
      "- 'time_timestamp' (datetime): the timestamp of the activity.\n",
      "- 'add_penalty_count' (int): The number of times the event 'Add penalty' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'penalty_added' (int): A boolean indicator (stored as an integer) showing whether any event in a case involves adding a penalty ('Add penalty'). 1 if any event in the case involves adding a penalty, 0 otherwise. This value is consistent across all rows pertaining to the same case.\n",
      "- 'notify_result_appeal_to_offender_count' (int): The number of times the event 'Notify Result Appeal to Offender' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'appeal_to_judge_count' (int): The number of times the event 'Appeal to Judge' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'concept_name' (string): the activity/ event type name\n",
      "    Activity Description, column: 'concept_name':\n",
      "        > 'Create Fine': The initial creation of the fine in the information system. It initializes event log attributes amount, dismissal, points and totalPaymentAmount.\n",
      "        > 'Send Fine': A notification about the fine is sent by post to the offender.\n",
      "        > 'Insert Fine Notification': The notification is received by the offender.\n",
      "        > 'Add penalty': An additional penalty is applied.\n",
      "        > 'Payment': A payment made by the offender is registered.\n",
      "        > 'Send for Credit Collection': Unpaid fines are sent for credit collection. A separate process is started by a collection agency to collect the money of the unpaid fines.\n",
      "        > 'Insert Date Appeal to Prefecture': The offender appeals against the fine to the prefecture. A prefecture in Italy is an administrative body representing the national government in each province.\n",
      "        > 'Send Appeal to Prefecture': The appeal is sent to the prefecture by the local police.\n",
      "        > 'Receive Result Appeal from Prefecture': The local police receives the result of the appeal. If the prefecture dismisses the fine, the appeal is deemed accepted, and the obligation to pay the fine is cancelled. In this case, there is no need for the police to receive the result from the prefecture (Receive Result Appeal from Prefecture) and notify the offender (Notify Result Appeal to Offender).\n",
      "        > 'Notify Result Appeal to Offender': The local police informs the offender of the appeal result. \n",
      "        > 'Appeal to Judge': The offender appeals against the fine to a judge.\n",
      "    IMPORTANT: The last event in a case can be arbitrary. There is no guarantee that the last event is 'Send Fine' or 'Payment'. The last event can be any event in the log.\n",
      "- 'insert_fine_notification_count' (int): The number of times the event 'Insert Fine Notification' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'dismissed_AND_fully_paid' (int): A boolean indicator (stored as an integer) showing whether any event in a case involves both the dismissal of the fine and the full payment of the fine. 1 if any event in the case involves both, 0 otherwise. This value is consistent across all rows pertaining to the same case.\n",
      "- 'insert_date_appeal_to_prefecture_count' (int): The number of times the event 'Insert Date Appeal to Prefecture' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'dismissed_by_prefecture' (int): A boolean indicator (stored as an integer) showing whether the fine was dismissed by the prefecture ('#') across all events of a case. 1 for dismissed by the prefecture, 0 otherwise.\n",
      "Approach: To determine how many cases have been added two or more penalties, we need to use the 'add_penalty_count' column. This column indicates the number of 'Add penalty' events for each case and is consistent across all rows pertaining to the same case. We are interested in counting the number of distinct cases where 'add_penalty_count' is greater than or equal to 2. The steps to construct the query are as follows: 1. Select the 'case_concept_name' and 'add_penalty_count' columns from the 'event_log' table. 2. Filter the results to include only those cases where 'add_penalty_count' is greater than or equal to 2. 3. Use the COUNT function to count the number of distinct 'case_concept_name' values that satisfy this condition. This will give us the total number of cases that have been added two or more penalties.\n",
      "Sqlite Query: sql='SELECT COUNT(DISTINCT case_concept_name) AS number_of_cases_with_two_or_more_penalties FROM event_log WHERE add_penalty_count >= 2;'\n",
      "Question: What is the average number of payment events per case?\n",
      "Column Description: THE DATABASE CONTAINS THE TABLE: event_log CONTAINING THE FOLLOWING COLUMNS (only the ones denoted by a \"-\", )\n",
      "- 'case_concept_name' (string): the case identifier, use this to group by cases (retrieve information about cases as a whole)\n",
      "- 'time_timestamp' (datetime): the timestamp of the activity.\n",
      "- 'payment_count' (int): The number of times the event 'Payment' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'send_for_credit_collection_count' (int): The number of times the event 'Send for Credit Collection' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'event_count' (int): The number of events recorded for each case, consistent across all rows pertaining to the same case.\n",
      "- 'send_fine_count' (int): The number of times the event 'Send Fine' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'notify_result_appeal_to_offender_count' (int): The number of times the event 'Notify Result Appeal to Offender' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'appeal_to_judge_count' (int): The number of times the event 'Appeal to Judge' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'send_appeal_to_prefecture_count' (int): The number of times the event 'Send Appeal to Prefecture' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'insert_date_appeal_to_prefecture_count' (int): The number of times the event 'Insert Date Appeal to Prefecture' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'credit_collected' (int): A boolean indicator (stored as an integer) showing whether any event in a case involves sending the fine for credit collection ('Send for Credit Collection'). 1 if any event in the case involves credit collection, 0 otherwise. This value is consistent across all rows pertaining to the same case.\n",
      "Approach: To calculate the average number of payment events per case, we need to use the 'payment_count' column, which indicates the number of payment events for each case. Since this value is consistent across all rows for a given case, we can directly use it to compute the average. The steps to construct the query are as follows: 1. Select the 'payment_count' values from the 'event_log' table. 2. Use the AVG function to calculate the average of these 'payment_count' values. 3. Since each 'payment_count' is consistent per case, we don't need to group by 'case_concept_name'. The SQL query would look like: SELECT AVG(payment_count) FROM event_log. This will give us the average number of payment events per case.\n",
      "Sqlite Query: sql='SELECT AVG(payment_count) AS average_payment_events_per_case FROM (SELECT DISTINCT case_concept_name, payment_count FROM event_log);'\n",
      "Question: How many cases have two or more payment events?\n",
      "Column Description: THE DATABASE CONTAINS THE TABLE: event_log CONTAINING THE FOLLOWING COLUMNS (only the ones denoted by a \"-\", )\n",
      "- 'case_concept_name' (string): the case identifier, use this to group by cases (retrieve information about cases as a whole)\n",
      "- 'time_timestamp' (datetime): the timestamp of the activity.\n",
      "- 'payment_count' (int): The number of times the event 'Payment' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'send_for_credit_collection_count' (int): The number of times the event 'Send for Credit Collection' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'event_count' (int): The number of events recorded for each case, consistent across all rows pertaining to the same case.\n",
      "- 'credit_collected_AND_fully_paid' (int): A boolean indicator (stored as an integer) showing whether any event in a case involves both credit collection ('Send for Credit Collection') and full payment of the fine. 1 if any event in the case involves both, 0 otherwise. This value is consistent across all rows pertaining to the same case.\n",
      "- 'credit_collected' (int): A boolean indicator (stored as an integer) showing whether any event in a case involves sending the fine for credit collection ('Send for Credit Collection'). 1 if any event in the case involves credit collection, 0 otherwise. This value is consistent across all rows pertaining to the same case.\n",
      "- 'credit_collected_AND_dismissed' (int): A boolean indicator (stored as an integer) showing whether any event in a case involves both dismissal of the fine and credit collection. 1 if any event in the case involves both, 0 otherwise. This value is consistent across all rows pertaining to the same case.\n",
      "- 'add_penalty_count' (int): The number of times the event 'Add penalty' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'send_appeal_to_prefecture_count' (int): The number of times the event 'Send Appeal to Prefecture' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'appeal_to_judge_count' (int): The number of times the event 'Appeal to Judge' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "Approach: To determine how many cases have two or more payment events, we should utilize the 'payment_count' column, which indicates the number of payment events for each case and is consistent across all rows pertaining to the same case. We need to count the distinct cases where 'payment_count' is greater than or equal to 2. The query should select from the 'event_log' table, filter where 'payment_count' >= 2, and count the distinct 'case_concept_name' values to ensure each case is counted only once. This will give us the total number of cases with two or more payment events.\n",
      "Sqlite Query: sql='SELECT COUNT(DISTINCT case_concept_name) AS case_count FROM event_log WHERE payment_count >= 2;'\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[34m[2024-12-23T12:15:06.625968]\u001b[0m\n",
      "\n",
      "\u001b[31mSystem message:\u001b[0m\n",
      "\n",
      "Your input fields are:\n",
      "1. `dataset_description` (str): A description of the dataset that we are using.\n",
      "2. `task_demos` (str): Example inputs/outputs of our module.\n",
      "3. `basic_instruction` (str): Basic instruction.\n",
      "\n",
      "Your output fields are:\n",
      "1. `proposed_instruction` (str): Propose an instruction that will be used to prompt a Language Model to perform this task.\n",
      "\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## dataset_description ## ]]\n",
      "{dataset_description}\n",
      "\n",
      "[[ ## task_demos ## ]]\n",
      "{task_demos}\n",
      "\n",
      "[[ ## basic_instruction ## ]]\n",
      "{basic_instruction}\n",
      "\n",
      "[[ ## proposed_instruction ## ]]\n",
      "{proposed_instruction}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "In adhering to this structure, your objective is: \n",
      "        Use the information below to learn about a task that we are trying to solve using calls to an LM, then generate a new instruction that will be used to prompt a Language Model to better solve the task.\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## dataset_description ## ]]\n",
      "The dataset captures detailed logs of events related to cases involving fines and penalties, emphasizing statistical analysis through counts, averages, and frequencies of events such as \"Create Fine,\" \"Send Appeal to Prefecture,\" and \"Payment.\" Its well-structured questions indicate a focus on precise event tracking, potentially supporting automated reporting to enhance administrative efficiency. The large volume of records and use of comparative metrics suggest its utility in improving process optimization for case management systems.\n",
      "\n",
      "[[ ## task_demos ## ]]\n",
      "Question: How many cases have been added two or more penalties?\n",
      "Column Description: THE DATABASE CONTAINS THE TABLE: event_log CONTAINING THE FOLLOWING COLUMNS (only the ones denoted by a \"-\", )\n",
      "- 'case_concept_name' (string): the case identifier, use this to group by cases (retrieve information about cases as a whole)\n",
      "- 'time_timestamp' (datetime): the timestamp of the activity.\n",
      "- 'add_penalty_count' (int): The number of times the event 'Add penalty' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'penalty_added' (int): A boolean indicator (stored as an integer) showing whether any event in a case involves adding a penalty ('Add penalty'). 1 if any event in the case involves adding a penalty, 0 otherwise. This value is consistent across all rows pertaining to the same case.\n",
      "- 'notify_result_appeal_to_offender_count' (int): The number of times the event 'Notify Result Appeal to Offender' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'appeal_to_judge_count' (int): The number of times the event 'Appeal to Judge' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'concept_name' (string): the activity/ event type name\n",
      "    Activity Description, column: 'concept_name':\n",
      "        > 'Create Fine': The initial creation of the fine in the information system. It initializes event log attributes amount, dismissal, points and totalPaymentAmount.\n",
      "        > 'Send Fine': A notification about the fine is sent by post to the offender.\n",
      "        > 'Insert Fine Notification': The notification is received by the offender.\n",
      "        > 'Add penalty': An additional penalty is applied.\n",
      "        > 'Payment': A payment made by the offender is registered.\n",
      "        > 'Send for Credit Collection': Unpaid fines are sent for credit collection. A separate process is started by a collection agency to collect the money of the unpaid fines.\n",
      "        > 'Insert Date Appeal to Prefecture': The offender appeals against the fine to the prefecture. A prefecture in Italy is an administrative body representing the national government in each province.\n",
      "        > 'Send Appeal to Prefecture': The appeal is sent to the prefecture by the local police.\n",
      "        > 'Receive Result Appeal from Prefecture': The local police receives the result of the appeal. If the prefecture dismisses the fine, the appeal is deemed accepted, and the obligation to pay the fine is cancelled. In this case, there is no need for the police to receive the result from the prefecture (Receive Result Appeal from Prefecture) and notify the offender (Notify Result Appeal to Offender).\n",
      "        > 'Notify Result Appeal to Offender': The local police informs the offender of the appeal result. \n",
      "        > 'Appeal to Judge': The offender appeals against the fine to a judge.\n",
      "    IMPORTANT: The last event in a case can be arbitrary. There is no guarantee that the last event is 'Send Fine' or 'Payment'. The last event can be any event in the log.\n",
      "- 'insert_fine_notification_count' (int): The number of times the event 'Insert Fine Notification' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'dismissed_AND_fully_paid' (int): A boolean indicator (stored as an integer) showing whether any event in a case involves both the dismissal of the fine and the full payment of the fine. 1 if any event in the case involves both, 0 otherwise. This value is consistent across all rows pertaining to the same case.\n",
      "- 'insert_date_appeal_to_prefecture_count' (int): The number of times the event 'Insert Date Appeal to Prefecture' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'dismissed_by_prefecture' (int): A boolean indicator (stored as an integer) showing whether the fine was dismissed by the prefecture ('#') across all events of a case. 1 for dismissed by the prefecture, 0 otherwise.\n",
      "Approach: To determine how many cases have been added two or more penalties, we need to use the 'add_penalty_count' column. This column indicates the number of 'Add penalty' events for each case and is consistent across all rows pertaining to the same case. We are interested in counting the number of distinct cases where 'add_penalty_count' is greater than or equal to 2. The steps to construct the query are as follows: 1. Select the 'case_concept_name' and 'add_penalty_count' columns from the 'event_log' table. 2. Filter the results to include only those cases where 'add_penalty_count' is greater than or equal to 2. 3. Use the COUNT function to count the number of distinct 'case_concept_name' values that satisfy this condition. This will give us the total number of cases that have been added two or more penalties.\n",
      "Sqlite Query: sql='SELECT COUNT(DISTINCT case_concept_name) AS number_of_cases_with_two_or_more_penalties FROM event_log WHERE add_penalty_count >= 2;'\n",
      "Question: What is the average number of payment events per case?\n",
      "Column Description: THE DATABASE CONTAINS THE TABLE: event_log CONTAINING THE FOLLOWING COLUMNS (only the ones denoted by a \"-\", )\n",
      "- 'case_concept_name' (string): the case identifier, use this to group by cases (retrieve information about cases as a whole)\n",
      "- 'time_timestamp' (datetime): the timestamp of the activity.\n",
      "- 'payment_count' (int): The number of times the event 'Payment' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'send_for_credit_collection_count' (int): The number of times the event 'Send for Credit Collection' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'event_count' (int): The number of events recorded for each case, consistent across all rows pertaining to the same case.\n",
      "- 'send_fine_count' (int): The number of times the event 'Send Fine' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'notify_result_appeal_to_offender_count' (int): The number of times the event 'Notify Result Appeal to Offender' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'appeal_to_judge_count' (int): The number of times the event 'Appeal to Judge' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'send_appeal_to_prefecture_count' (int): The number of times the event 'Send Appeal to Prefecture' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'insert_date_appeal_to_prefecture_count' (int): The number of times the event 'Insert Date Appeal to Prefecture' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'credit_collected' (int): A boolean indicator (stored as an integer) showing whether any event in a case involves sending the fine for credit collection ('Send for Credit Collection'). 1 if any event in the case involves credit collection, 0 otherwise. This value is consistent across all rows pertaining to the same case.\n",
      "Approach: To calculate the average number of payment events per case, we need to use the 'payment_count' column, which indicates the number of payment events for each case. Since this value is consistent across all rows for a given case, we can directly use it to compute the average. The steps to construct the query are as follows: 1. Select the 'payment_count' values from the 'event_log' table. 2. Use the AVG function to calculate the average of these 'payment_count' values. 3. Since each 'payment_count' is consistent per case, we don't need to group by 'case_concept_name'. The SQL query would look like: SELECT AVG(payment_count) FROM event_log. This will give us the average number of payment events per case.\n",
      "Sqlite Query: sql='SELECT AVG(payment_count) AS average_payment_events_per_case FROM (SELECT DISTINCT case_concept_name, payment_count FROM event_log);'\n",
      "Question: How many cases have two or more payment events?\n",
      "Column Description: THE DATABASE CONTAINS THE TABLE: event_log CONTAINING THE FOLLOWING COLUMNS (only the ones denoted by a \"-\", )\n",
      "- 'case_concept_name' (string): the case identifier, use this to group by cases (retrieve information about cases as a whole)\n",
      "- 'time_timestamp' (datetime): the timestamp of the activity.\n",
      "- 'payment_count' (int): The number of times the event 'Payment' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'send_for_credit_collection_count' (int): The number of times the event 'Send for Credit Collection' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'event_count' (int): The number of events recorded for each case, consistent across all rows pertaining to the same case.\n",
      "- 'credit_collected_AND_fully_paid' (int): A boolean indicator (stored as an integer) showing whether any event in a case involves both credit collection ('Send for Credit Collection') and full payment of the fine. 1 if any event in the case involves both, 0 otherwise. This value is consistent across all rows pertaining to the same case.\n",
      "- 'credit_collected' (int): A boolean indicator (stored as an integer) showing whether any event in a case involves sending the fine for credit collection ('Send for Credit Collection'). 1 if any event in the case involves credit collection, 0 otherwise. This value is consistent across all rows pertaining to the same case.\n",
      "- 'credit_collected_AND_dismissed' (int): A boolean indicator (stored as an integer) showing whether any event in a case involves both dismissal of the fine and credit collection. 1 if any event in the case involves both, 0 otherwise. This value is consistent across all rows pertaining to the same case.\n",
      "- 'add_penalty_count' (int): The number of times the event 'Add penalty' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'send_appeal_to_prefecture_count' (int): The number of times the event 'Send Appeal to Prefecture' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'appeal_to_judge_count' (int): The number of times the event 'Appeal to Judge' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "Approach: To determine how many cases have two or more payment events, we should utilize the 'payment_count' column, which indicates the number of payment events for each case and is consistent across all rows pertaining to the same case. We need to count the distinct cases where 'payment_count' is greater than or equal to 2. The query should select from the 'event_log' table, filter where 'payment_count' >= 2, and count the distinct 'case_concept_name' values to ensure each case is counted only once. This will give us the total number of cases with two or more payment events.\n",
      "Sqlite Query: sql='SELECT COUNT(DISTINCT case_concept_name) AS case_count FROM event_log WHERE payment_count >= 2;'\n",
      "\n",
      "\n",
      "[[ ## basic_instruction ## ]]\n",
      "Generate a single SQLite query that returns the specific information requested in the question \n",
      "and include relevant details such as duration or amount. When asked about information pertaining \n",
      "to cases (not events), group by case to avoid counting the same case multiple times. Aggregate when necessary,\n",
      "using subqueries and outer queries to limit the output size and results in a table that answers the question directly.\n",
      "Be aware to make a distinction between questions that ask about cases and question that ask about events, since some of the available columns are aggregated over cases and might lead to wrong results when used in the wrong context.\n",
      "\n",
      "Respond with the corresponding output fields, starting with the field `[[ ## proposed_instruction ## ]]`, and then ending with the marker for `[[ ## completed ## ]]`.\n",
      "\n",
      "\n",
      "\u001b[31mResponse:\u001b[0m\n",
      "\n",
      "\u001b[32m[[ ## proposed_instruction ## ]]\n",
      "Create a SQLite query that accurately retrieves the requested information from the dataset, ensuring to differentiate between case-level and event-level inquiries. When the question pertains to cases, group the results by 'case_concept_name' to prevent duplicate counting of cases. Utilize appropriate SQL functions such as COUNT, AVG, or others as needed for aggregation. If the query involves calculating averages or totals, consider using subqueries or outer queries to refine the output and ensure it directly addresses the question. Always verify the context of the question to select the right columns and avoid misinterpretation of aggregated data.\n",
      "\n",
      "[[ ## completed ## ]]\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "PROPOSED INSTRUCTION: Create a SQLite query that accurately retrieves the requested information from the dataset, ensuring to differentiate between case-level and event-level inquiries. When the question pertains to cases, group the results by 'case_concept_name' to prevent duplicate counting of cases. Utilize appropriate SQL functions such as COUNT, AVG, or others as needed for aggregation. If the query involves calculating averages or totals, consider using subqueries or outer queries to refine the output and ensure it directly addresses the question. Always verify the context of the question to select the right columns and avoid misinterpretation of aggregated data.\n",
      "Using a randomly generated configuration for our grounded proposer.\n",
      "Selected tip: none\n",
      "task_demos \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[34m[2024-12-23T12:15:11.054573]\u001b[0m\n",
      "\n",
      "\u001b[31mSystem message:\u001b[0m\n",
      "\n",
      "Your input fields are:\n",
      "1. `dataset_description` (str): A description of the dataset that we are using.\n",
      "2. `task_demos` (str): Example inputs/outputs of our module.\n",
      "3. `basic_instruction` (str): Basic instruction.\n",
      "\n",
      "Your output fields are:\n",
      "1. `proposed_instruction` (str): Propose an instruction that will be used to prompt a Language Model to perform this task.\n",
      "\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## dataset_description ## ]]\n",
      "{dataset_description}\n",
      "\n",
      "[[ ## task_demos ## ]]\n",
      "{task_demos}\n",
      "\n",
      "[[ ## basic_instruction ## ]]\n",
      "{basic_instruction}\n",
      "\n",
      "[[ ## proposed_instruction ## ]]\n",
      "{proposed_instruction}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "In adhering to this structure, your objective is: \n",
      "        Use the information below to learn about a task that we are trying to solve using calls to an LM, then generate a new instruction that will be used to prompt a Language Model to better solve the task.\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## dataset_description ## ]]\n",
      "The dataset captures detailed logs of events related to cases involving fines and penalties, emphasizing statistical analysis through counts, averages, and frequencies of events such as \"Create Fine,\" \"Send Appeal to Prefecture,\" and \"Payment.\" Its well-structured questions indicate a focus on precise event tracking, potentially supporting automated reporting to enhance administrative efficiency. The large volume of records and use of comparative metrics suggest its utility in improving process optimization for case management systems.\n",
      "\n",
      "[[ ## task_demos ## ]]\n",
      "\n",
      "\n",
      "[[ ## basic_instruction ## ]]\n",
      "Objective: Develop a strategy and logic to create a single SQLite query that will answer a given question.\n",
      "Database Information: Use the details about the database and its columns to guide your approach. \n",
      "Be specific about whether the question pertains to \"cases\" or \"events,\" since every row is an event, and multiple events can be part of a single case.\n",
      "Column Details: Some columns contain the same information for each event (row) per case (referred to as \"case predicate\"). Other columns are independent of cases and refer to events directly.\n",
      "You can determine this, based on whether the column description mentions that all values are the same for a case or if the column is aggregated over a case.\n",
      "Grouping: When asked about questions independent of cases and you are using a column that is a case predicate, group by case to avoid counting an aggregated value multiple times.\n",
      "Do not forget about this for percentage calculations as well (using something like (DISTINCT case_concept_name) FILTER (WHERE col = 1) instead of not grouping by case first for case predicates).\n",
      "Query Construction: Do not write the actual query. Instead, provide a detailed explanation of how to construct the query.\n",
      "Aggregation: Aggregate data when necessary. Use subqueries and outer queries to limit the output size. Ensure the final result is a table that directly answers the question.\n",
      "Some questions might have multiple valid anwers(i.e finding case with highest value x, might have mutliple cases with the same highest value), be aware of this and consider LIMIT 10 instead of LIMIT 1 in such cases.\n",
      "\n",
      "Respond with the corresponding output fields, starting with the field `[[ ## proposed_instruction ## ]]`, and then ending with the marker for `[[ ## completed ## ]]`.\n",
      "\n",
      "\n",
      "\u001b[31mResponse:\u001b[0m\n",
      "\n",
      "\u001b[32m[[ ## proposed_instruction ## ]]\n",
      "Given a dataset of event logs related to fines and penalties, develop a strategy to construct a single SQLite query that effectively answers a specified question. Use the database structure, including details about columns and their relation to cases and events, to guide your approach. Distinguish between \"cases\" and \"events\" as each row represents an event, while multiple events can belong to a single case. Pay attention to whether a column is a case predicate or event-specific and group by case when necessary to avoid miscounting aggregated values. Provide a detailed explanation of the query construction process, focusing on aggregation, subqueries, and limiting the output size to directly answer the question. Consider multiple valid answers and use LIMIT 10 for cases with equal highest values. Avoid writing the actual query; instead, describe the logic and steps needed to construct it.\n",
      "\n",
      "[[ ## completed ## ]]\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "PROPOSED INSTRUCTION: Given a dataset of event logs related to fines and penalties, develop a strategy to construct a single SQLite query that effectively answers a specified question. Use the database structure, including details about columns and their relation to cases and events, to guide your approach. Distinguish between \"cases\" and \"events\" as each row represents an event, while multiple events can belong to a single case. Pay attention to whether a column is a case predicate or event-specific and group by case when necessary to avoid miscounting aggregated values. Provide a detailed explanation of the query construction process, focusing on aggregation, subqueries, and limiting the output size to directly answer the question. Consider multiple valid answers and use LIMIT 10 for cases with equal highest values. Avoid writing the actual query; instead, describe the logic and steps needed to construct it.\n",
      "Using a randomly generated configuration for our grounded proposer.\n",
      "Selected tip: persona\n",
      "task_demos Question: Which case has the most payment events?\n",
      "Column Description: THE DATABASE CONTAINS THE TABLE: event_log CONTAINING THE FOLLOWING COLUMNS (only the ones denoted by a \"-\", )\n",
      "- 'case_concept_name' (string): the case identifier, use this to group by cases (retrieve information about cases as a whole)\n",
      "- 'time_timestamp' (datetime): the timestamp of the activity.\n",
      "- 'payment_count' (int): The number of times the event 'Payment' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'send_for_credit_collection_count' (int): The number of times the event 'Send for Credit Collection' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'event_count' (int): The number of events recorded for each case, consistent across all rows pertaining to the same case.\n",
      "- 'credit_collected_AND_fully_paid' (int): A boolean indicator (stored as an integer) showing whether any event in a case involves both credit collection ('Send for Credit Collection') and full payment of the fine. 1 if any event in the case involves both, 0 otherwise. This value is consistent across all rows pertaining to the same case.\n",
      "- 'credit_collected' (int): A boolean indicator (stored as an integer) showing whether any event in a case involves sending the fine for credit collection ('Send for Credit Collection'). 1 if any event in the case involves credit collection, 0 otherwise. This value is consistent across all rows pertaining to the same case.\n",
      "- 'credit_collected_AND_dismissed' (int): A boolean indicator (stored as an integer) showing whether any event in a case involves both dismissal of the fine and credit collection. 1 if any event in the case involves both, 0 otherwise. This value is consistent across all rows pertaining to the same case.\n",
      "- 'insert_date_appeal_to_prefecture_count' (int): The number of times the event 'Insert Date Appeal to Prefecture' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'send_appeal_to_prefecture_count' (int): The number of times the event 'Send Appeal to Prefecture' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'appeal_to_judge_count' (int): The number of times the event 'Appeal to Judge' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "Reasoning: approach=\"To find the case with the most payment events, we need to focus on the 'payment_count' column, which indicates the number of payment events for each case. Since this column is consistent across all rows for a given case, we can directly use it to identify the case with the maximum number of payments. The steps to construct the query are as follows: 1. Select the 'case_concept_name' and 'payment_count' columns from the 'event_log' table. 2. Order the results by 'payment_count' in descending order to bring the case with the highest payment count to the top. 3. Use the LIMIT clause to restrict the result to the top case(s) with the highest payment count. Since there might be multiple cases with the same highest payment count, consider using LIMIT 10 to capture all such cases. This will provide the case(s) with the most payment events.\"\n",
      "Question: How many cases are Sent for Credit Collection?\n",
      "Column Description: THE DATABASE CONTAINS THE TABLE: event_log CONTAINING THE FOLLOWING COLUMNS (only the ones denoted by a \"-\", )\n",
      "- 'case_concept_name' (string): the case identifier, use this to group by cases (retrieve information about cases as a whole)\n",
      "- 'time_timestamp' (datetime): the timestamp of the activity.\n",
      "- 'send_for_credit_collection_count' (int): The number of times the event 'Send for Credit Collection' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'credit_collected' (int): A boolean indicator (stored as an integer) showing whether any event in a case involves sending the fine for credit collection ('Send for Credit Collection'). 1 if any event in the case involves credit collection, 0 otherwise. This value is consistent across all rows pertaining to the same case.\n",
      "- 'credit_collected_AND_fully_paid' (int): A boolean indicator (stored as an integer) showing whether any event in a case involves both credit collection ('Send for Credit Collection') and full payment of the fine. 1 if any event in the case involves both, 0 otherwise. This value is consistent across all rows pertaining to the same case.\n",
      "- 'credit_collected_AND_dismissed' (int): A boolean indicator (stored as an integer) showing whether any event in a case involves both dismissal of the fine and credit collection. 1 if any event in the case involves both, 0 otherwise. This value is consistent across all rows pertaining to the same case.\n",
      "- 'unresolved' (int): A boolean indicator (stored as an integer) showing whether a case remains unresolved, i.e., not fully paid, not collected for credit, and not dismissed. 1 for unresolved, 0 otherwise. This value is consistent across all rows pertaining to the same case.\n",
      "- 'payment_count' (int): The number of times the event 'Payment' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'fully_paid' (int): A boolean indicator (stored as an integer) showing whether the outstanding balance for each case is zero or less, indicating that the fine has been fully paid. 1 for fully paid, 0 otherwise. This value is consistent across all rows pertaining to the same case.\n",
      "- 'appeal_to_judge_count' (int): The number of times the event 'Appeal to Judge' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'notify_result_appeal_to_offender_count' (int): The number of times the event 'Notify Result Appeal to Offender' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "Reasoning: approach=\"To determine how many cases are 'Sent for Credit Collection', we need to use the 'credit_collected' column, which acts as a boolean indicator showing whether any event in a case involves sending the fine for credit collection. This value is consistent across all rows for a given case. Therefore, we need to count the distinct cases where 'credit_collected' equals 1. The query should group by 'case_concept_name' and filter the results where 'credit_collected' is 1, then count the number of distinct 'case_concept_name' values to obtain the total number of cases that have been sent for credit collection.\"\n",
      "Question: How many Add penalty events occur?\n",
      "Column Description: THE DATABASE CONTAINS THE TABLE: event_log CONTAINING THE FOLLOWING COLUMNS (only the ones denoted by a \"-\", )\n",
      "- 'case_concept_name' (string): the case identifier, use this to group by cases (retrieve information about cases as a whole)\n",
      "- 'time_timestamp' (datetime): the timestamp of the activity.\n",
      "- 'add_penalty_count' (int): The number of times the event 'Add penalty' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'penalty_added' (int): A boolean indicator (stored as an integer) showing whether any event in a case involves adding a penalty ('Add penalty'). 1 if any event in the case involves adding a penalty, 0 otherwise. This value is consistent across all rows pertaining to the same case.\n",
      "- 'insert_fine_notification_count' (int): The number of times the event 'Insert Fine Notification' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'event_count' (int): The number of events recorded for each case, consistent across all rows pertaining to the same case.\n",
      "- 'send_fine_count' (int): The number of times the event 'Send Fine' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'notify_result_appeal_to_offender_count' (int): The number of times the event 'Notify Result Appeal to Offender' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'concept_name' (string): the activity/ event type name\n",
      "    Activity Description, column: 'concept_name':\n",
      "        > 'Create Fine': The initial creation of the fine in the information system. It initializes event log attributes amount, dismissal, points and totalPaymentAmount.\n",
      "        > 'Send Fine': A notification about the fine is sent by post to the offender.\n",
      "        > 'Insert Fine Notification': The notification is received by the offender.\n",
      "        > 'Add penalty': An additional penalty is applied.\n",
      "        > 'Payment': A payment made by the offender is registered.\n",
      "        > 'Send for Credit Collection': Unpaid fines are sent for credit collection. A separate process is started by a collection agency to collect the money of the unpaid fines.\n",
      "        > 'Insert Date Appeal to Prefecture': The offender appeals against the fine to the prefecture. A prefecture in Italy is an administrative body representing the national government in each province.\n",
      "        > 'Send Appeal to Prefecture': The appeal is sent to the prefecture by the local police.\n",
      "        > 'Receive Result Appeal from Prefecture': The local police receives the result of the appeal. If the prefecture dismisses the fine, the appeal is deemed accepted, and the obligation to pay the fine is cancelled. In this case, there is no need for the police to receive the result from the prefecture (Receive Result Appeal from Prefecture) and notify the offender (Notify Result Appeal to Offender).\n",
      "        > 'Notify Result Appeal to Offender': The local police informs the offender of the appeal result. \n",
      "        > 'Appeal to Judge': The offender appeals against the fine to a judge.\n",
      "    IMPORTANT: The last event in a case can be arbitrary. There is no guarantee that the last event is 'Send Fine' or 'Payment'. The last event can be any event in the log.\n",
      "- 'insert_date_appeal_to_prefecture_count' (int): The number of times the event 'Insert Date Appeal to Prefecture' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'send_for_credit_collection_count' (int): The number of times the event 'Send for Credit Collection' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "Reasoning: approach=\"To determine the total number of 'Add penalty' events, we should use the 'add_penalty_count' column, which records the number of 'Add penalty' events for each case. Since this column is consistent across all rows of the same case, we can sum the 'add_penalty_count' values across all cases to get the total number of 'Add penalty' events. The query should select the sum of 'add_penalty_count' from the 'event_log' table, ensuring that each case is only counted once by using a GROUP BY clause on 'case_concept_name'. This will prevent counting the same 'add_penalty_count' value multiple times for cases with multiple events.\"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[34m[2024-12-23T12:15:15.658572]\u001b[0m\n",
      "\n",
      "\u001b[31mSystem message:\u001b[0m\n",
      "\n",
      "Your input fields are:\n",
      "1. `dataset_description` (str): A description of the dataset that we are using.\n",
      "2. `task_demos` (str): Example inputs/outputs of our module.\n",
      "3. `basic_instruction` (str): Basic instruction.\n",
      "4. `tip` (str): A suggestion for how to go about generating the new instruction.\n",
      "\n",
      "Your output fields are:\n",
      "1. `proposed_instruction` (str): Propose an instruction that will be used to prompt a Language Model to perform this task.\n",
      "\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## dataset_description ## ]]\n",
      "{dataset_description}\n",
      "\n",
      "[[ ## task_demos ## ]]\n",
      "{task_demos}\n",
      "\n",
      "[[ ## basic_instruction ## ]]\n",
      "{basic_instruction}\n",
      "\n",
      "[[ ## tip ## ]]\n",
      "{tip}\n",
      "\n",
      "[[ ## proposed_instruction ## ]]\n",
      "{proposed_instruction}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "In adhering to this structure, your objective is: \n",
      "        Use the information below to learn about a task that we are trying to solve using calls to an LM, then generate a new instruction that will be used to prompt a Language Model to better solve the task.\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## dataset_description ## ]]\n",
      "The dataset captures detailed logs of events related to cases involving fines and penalties, emphasizing statistical analysis through counts, averages, and frequencies of events such as \"Create Fine,\" \"Send Appeal to Prefecture,\" and \"Payment.\" Its well-structured questions indicate a focus on precise event tracking, potentially supporting automated reporting to enhance administrative efficiency. The large volume of records and use of comparative metrics suggest its utility in improving process optimization for case management systems.\n",
      "\n",
      "[[ ## task_demos ## ]]\n",
      "Question: Which case has the most payment events?\n",
      "Column Description: THE DATABASE CONTAINS THE TABLE: event_log CONTAINING THE FOLLOWING COLUMNS (only the ones denoted by a \"-\", )\n",
      "- 'case_concept_name' (string): the case identifier, use this to group by cases (retrieve information about cases as a whole)\n",
      "- 'time_timestamp' (datetime): the timestamp of the activity.\n",
      "- 'payment_count' (int): The number of times the event 'Payment' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'send_for_credit_collection_count' (int): The number of times the event 'Send for Credit Collection' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'event_count' (int): The number of events recorded for each case, consistent across all rows pertaining to the same case.\n",
      "- 'credit_collected_AND_fully_paid' (int): A boolean indicator (stored as an integer) showing whether any event in a case involves both credit collection ('Send for Credit Collection') and full payment of the fine. 1 if any event in the case involves both, 0 otherwise. This value is consistent across all rows pertaining to the same case.\n",
      "- 'credit_collected' (int): A boolean indicator (stored as an integer) showing whether any event in a case involves sending the fine for credit collection ('Send for Credit Collection'). 1 if any event in the case involves credit collection, 0 otherwise. This value is consistent across all rows pertaining to the same case.\n",
      "- 'credit_collected_AND_dismissed' (int): A boolean indicator (stored as an integer) showing whether any event in a case involves both dismissal of the fine and credit collection. 1 if any event in the case involves both, 0 otherwise. This value is consistent across all rows pertaining to the same case.\n",
      "- 'insert_date_appeal_to_prefecture_count' (int): The number of times the event 'Insert Date Appeal to Prefecture' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'send_appeal_to_prefecture_count' (int): The number of times the event 'Send Appeal to Prefecture' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'appeal_to_judge_count' (int): The number of times the event 'Appeal to Judge' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "Reasoning: approach=\"To find the case with the most payment events, we need to focus on the 'payment_count' column, which indicates the number of payment events for each case. Since this column is consistent across all rows for a given case, we can directly use it to identify the case with the maximum number of payments. The steps to construct the query are as follows: 1. Select the 'case_concept_name' and 'payment_count' columns from the 'event_log' table. 2. Order the results by 'payment_count' in descending order to bring the case with the highest payment count to the top. 3. Use the LIMIT clause to restrict the result to the top case(s) with the highest payment count. Since there might be multiple cases with the same highest payment count, consider using LIMIT 10 to capture all such cases. This will provide the case(s) with the most payment events.\"\n",
      "Question: How many cases are Sent for Credit Collection?\n",
      "Column Description: THE DATABASE CONTAINS THE TABLE: event_log CONTAINING THE FOLLOWING COLUMNS (only the ones denoted by a \"-\", )\n",
      "- 'case_concept_name' (string): the case identifier, use this to group by cases (retrieve information about cases as a whole)\n",
      "- 'time_timestamp' (datetime): the timestamp of the activity.\n",
      "- 'send_for_credit_collection_count' (int): The number of times the event 'Send for Credit Collection' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'credit_collected' (int): A boolean indicator (stored as an integer) showing whether any event in a case involves sending the fine for credit collection ('Send for Credit Collection'). 1 if any event in the case involves credit collection, 0 otherwise. This value is consistent across all rows pertaining to the same case.\n",
      "- 'credit_collected_AND_fully_paid' (int): A boolean indicator (stored as an integer) showing whether any event in a case involves both credit collection ('Send for Credit Collection') and full payment of the fine. 1 if any event in the case involves both, 0 otherwise. This value is consistent across all rows pertaining to the same case.\n",
      "- 'credit_collected_AND_dismissed' (int): A boolean indicator (stored as an integer) showing whether any event in a case involves both dismissal of the fine and credit collection. 1 if any event in the case involves both, 0 otherwise. This value is consistent across all rows pertaining to the same case.\n",
      "- 'unresolved' (int): A boolean indicator (stored as an integer) showing whether a case remains unresolved, i.e., not fully paid, not collected for credit, and not dismissed. 1 for unresolved, 0 otherwise. This value is consistent across all rows pertaining to the same case.\n",
      "- 'payment_count' (int): The number of times the event 'Payment' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'fully_paid' (int): A boolean indicator (stored as an integer) showing whether the outstanding balance for each case is zero or less, indicating that the fine has been fully paid. 1 for fully paid, 0 otherwise. This value is consistent across all rows pertaining to the same case.\n",
      "- 'appeal_to_judge_count' (int): The number of times the event 'Appeal to Judge' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'notify_result_appeal_to_offender_count' (int): The number of times the event 'Notify Result Appeal to Offender' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "Reasoning: approach=\"To determine how many cases are 'Sent for Credit Collection', we need to use the 'credit_collected' column, which acts as a boolean indicator showing whether any event in a case involves sending the fine for credit collection. This value is consistent across all rows for a given case. Therefore, we need to count the distinct cases where 'credit_collected' equals 1. The query should group by 'case_concept_name' and filter the results where 'credit_collected' is 1, then count the number of distinct 'case_concept_name' values to obtain the total number of cases that have been sent for credit collection.\"\n",
      "Question: How many Add penalty events occur?\n",
      "Column Description: THE DATABASE CONTAINS THE TABLE: event_log CONTAINING THE FOLLOWING COLUMNS (only the ones denoted by a \"-\", )\n",
      "- 'case_concept_name' (string): the case identifier, use this to group by cases (retrieve information about cases as a whole)\n",
      "- 'time_timestamp' (datetime): the timestamp of the activity.\n",
      "- 'add_penalty_count' (int): The number of times the event 'Add penalty' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'penalty_added' (int): A boolean indicator (stored as an integer) showing whether any event in a case involves adding a penalty ('Add penalty'). 1 if any event in the case involves adding a penalty, 0 otherwise. This value is consistent across all rows pertaining to the same case.\n",
      "- 'insert_fine_notification_count' (int): The number of times the event 'Insert Fine Notification' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'event_count' (int): The number of events recorded for each case, consistent across all rows pertaining to the same case.\n",
      "- 'send_fine_count' (int): The number of times the event 'Send Fine' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'notify_result_appeal_to_offender_count' (int): The number of times the event 'Notify Result Appeal to Offender' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'concept_name' (string): the activity/ event type name\n",
      "    Activity Description, column: 'concept_name':\n",
      "        > 'Create Fine': The initial creation of the fine in the information system. It initializes event log attributes amount, dismissal, points and totalPaymentAmount.\n",
      "        > 'Send Fine': A notification about the fine is sent by post to the offender.\n",
      "        > 'Insert Fine Notification': The notification is received by the offender.\n",
      "        > 'Add penalty': An additional penalty is applied.\n",
      "        > 'Payment': A payment made by the offender is registered.\n",
      "        > 'Send for Credit Collection': Unpaid fines are sent for credit collection. A separate process is started by a collection agency to collect the money of the unpaid fines.\n",
      "        > 'Insert Date Appeal to Prefecture': The offender appeals against the fine to the prefecture. A prefecture in Italy is an administrative body representing the national government in each province.\n",
      "        > 'Send Appeal to Prefecture': The appeal is sent to the prefecture by the local police.\n",
      "        > 'Receive Result Appeal from Prefecture': The local police receives the result of the appeal. If the prefecture dismisses the fine, the appeal is deemed accepted, and the obligation to pay the fine is cancelled. In this case, there is no need for the police to receive the result from the prefecture (Receive Result Appeal from Prefecture) and notify the offender (Notify Result Appeal to Offender).\n",
      "        > 'Notify Result Appeal to Offender': The local police informs the offender of the appeal result. \n",
      "        > 'Appeal to Judge': The offender appeals against the fine to a judge.\n",
      "    IMPORTANT: The last event in a case can be arbitrary. There is no guarantee that the last event is 'Send Fine' or 'Payment'. The last event can be any event in the log.\n",
      "- 'insert_date_appeal_to_prefecture_count' (int): The number of times the event 'Insert Date Appeal to Prefecture' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'send_for_credit_collection_count' (int): The number of times the event 'Send for Credit Collection' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "Reasoning: approach=\"To determine the total number of 'Add penalty' events, we should use the 'add_penalty_count' column, which records the number of 'Add penalty' events for each case. Since this column is consistent across all rows of the same case, we can sum the 'add_penalty_count' values across all cases to get the total number of 'Add penalty' events. The query should select the sum of 'add_penalty_count' from the 'event_log' table, ensuring that each case is only counted once by using a GROUP BY clause on 'case_concept_name'. This will prevent counting the same 'add_penalty_count' value multiple times for cases with multiple events.\"\n",
      "\n",
      "\n",
      "[[ ## basic_instruction ## ]]\n",
      "Objective: Develop a strategy and logic to create a single SQLite query that will answer a given question.\n",
      "Database Information: Use the details about the database and its columns to guide your approach. \n",
      "Be specific about whether the question pertains to \"cases\" or \"events,\" since every row is an event, and multiple events can be part of a single case.\n",
      "Column Details: Some columns contain the same information for each event (row) per case (referred to as \"case predicate\"). Other columns are independent of cases and refer to events directly.\n",
      "You can determine this, based on whether the column description mentions that all values are the same for a case or if the column is aggregated over a case.\n",
      "Grouping: When asked about questions independent of cases and you are using a column that is a case predicate, group by case to avoid counting an aggregated value multiple times.\n",
      "Do not forget about this for percentage calculations as well (using something like (DISTINCT case_concept_name) FILTER (WHERE col = 1) instead of not grouping by case first for case predicates).\n",
      "Query Construction: Do not write the actual query. Instead, provide a detailed explanation of how to construct the query.\n",
      "Aggregation: Aggregate data when necessary. Use subqueries and outer queries to limit the output size. Ensure the final result is a table that directly answers the question.\n",
      "Some questions might have multiple valid anwers(i.e finding case with highest value x, might have mutliple cases with the same highest value), be aware of this and consider LIMIT 10 instead of LIMIT 1 in such cases.\n",
      "\n",
      "[[ ## tip ## ]]\n",
      "Include a persona that is relevant to the task in the instruction (ie. \"You are a ...\")\n",
      "\n",
      "Respond with the corresponding output fields, starting with the field `[[ ## proposed_instruction ## ]]`, and then ending with the marker for `[[ ## completed ## ]]`.\n",
      "\n",
      "\n",
      "\u001b[31mResponse:\u001b[0m\n",
      "\n",
      "\u001b[32m[[ ## proposed_instruction ## ]]\n",
      "You are a data analyst tasked with optimizing the efficiency of case management systems by analyzing event logs related to fines and penalties. Your goal is to develop a strategy and logic to create a single SQLite query that will answer a given question about these events. Use the detailed information about the database columns to guide your approach. Be specific about whether the question pertains to \"cases\" or \"events,\" as each row represents an event, and multiple events can be part of a single case. Pay attention to columns that contain consistent information across all events of a case, and ensure you group by case when necessary to avoid counting aggregated values multiple times. Provide a detailed explanation of how to construct the query without writing the actual query, focusing on data aggregation and the use of subqueries and outer queries to limit the output size. Consider using LIMIT 10 in scenarios where multiple valid answers exist. Your analysis will help improve process optimization and automated reporting in administrative systems.\n",
      "\n",
      "[[ ## completed ## ]]\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "PROPOSED INSTRUCTION: You are a data analyst tasked with optimizing the efficiency of case management systems by analyzing event logs related to fines and penalties. Your goal is to develop a strategy and logic to create a single SQLite query that will answer a given question about these events. Use the detailed information about the database columns to guide your approach. Be specific about whether the question pertains to \"cases\" or \"events,\" as each row represents an event, and multiple events can be part of a single case. Pay attention to columns that contain consistent information across all events of a case, and ensure you group by case when necessary to avoid counting aggregated values multiple times. Provide a detailed explanation of how to construct the query without writing the actual query, focusing on data aggregation and the use of subqueries and outer queries to limit the output size. Consider using LIMIT 10 in scenarios where multiple valid answers exist. Your analysis will help improve process optimization and automated reporting in administrative systems.\n",
      "Using a randomly generated configuration for our grounded proposer.\n",
      "Selected tip: description\n",
      "task_demos Question: How many cases are in the log?\n",
      "Column Description: THE DATABASE CONTAINS THE TABLE: event_log CONTAINING THE FOLLOWING COLUMNS (only the ones denoted by a \"-\", )\n",
      "- 'case_concept_name' (string): the case identifier, use this to group by cases (retrieve information about cases as a whole)\n",
      "- 'time_timestamp' (datetime): the timestamp of the activity.\n",
      "- 'event_count' (int): The number of events recorded for each case, consistent across all rows pertaining to the same case.\n",
      "- 'notify_result_appeal_to_offender_count' (int): The number of times the event 'Notify Result Appeal to Offender' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'appeal_to_judge_count' (int): The number of times the event 'Appeal to Judge' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'receive_result_appeal_from_prefecture_count' (int): The number of times the event 'Receive Result Appeal from Prefecture' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'insert_date_appeal_to_prefecture_count' (int): The number of times the event 'Insert Date Appeal to Prefecture' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'send_appeal_to_prefecture_count' (int): The number of times the event 'Send Appeal to Prefecture' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'insert_fine_notification_count' (int): The number of times the event 'Insert Fine Notification' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'send_fine_count' (int): The number of times the event 'Send Fine' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'add_penalty_count' (int): The number of times the event 'Add penalty' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "Reasoning: approach=\"To determine the number of cases in the log, we need to count the distinct values of the 'case_concept_name' column. This column serves as the unique identifier for each case and remains consistent across all events pertaining to the same case. Therefore, the query should select the distinct 'case_concept_name' values and count them. This will give us the total number of unique cases in the event log. The SQL query would look like: SELECT COUNT(DISTINCT case_concept_name) FROM event_log.\"\n",
      "Question: How many Create Fine events occur?\n",
      "Column Description: THE DATABASE CONTAINS THE TABLE: event_log CONTAINING THE FOLLOWING COLUMNS (only the ones denoted by a \"-\", )\n",
      "- 'case_concept_name' (string): the case identifier, use this to group by cases (retrieve information about cases as a whole)\n",
      "- 'time_timestamp' (datetime): the timestamp of the activity.\n",
      "- 'insert_fine_notification_count' (int): The number of times the event 'Insert Fine Notification' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'send_fine_count' (int): The number of times the event 'Send Fine' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'event_count' (int): The number of events recorded for each case, consistent across all rows pertaining to the same case.\n",
      "- 'add_penalty_count' (int): The number of times the event 'Add penalty' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'concept_name' (string): the activity/ event type name\n",
      "    Activity Description, column: 'concept_name':\n",
      "        > 'Create Fine': The initial creation of the fine in the information system. It initializes event log attributes amount, dismissal, points and totalPaymentAmount.\n",
      "        > 'Send Fine': A notification about the fine is sent by post to the offender.\n",
      "        > 'Insert Fine Notification': The notification is received by the offender.\n",
      "        > 'Add penalty': An additional penalty is applied.\n",
      "        > 'Payment': A payment made by the offender is registered.\n",
      "        > 'Send for Credit Collection': Unpaid fines are sent for credit collection. A separate process is started by a collection agency to collect the money of the unpaid fines.\n",
      "        > 'Insert Date Appeal to Prefecture': The offender appeals against the fine to the prefecture. A prefecture in Italy is an administrative body representing the national government in each province.\n",
      "        > 'Send Appeal to Prefecture': The appeal is sent to the prefecture by the local police.\n",
      "        > 'Receive Result Appeal from Prefecture': The local police receives the result of the appeal. If the prefecture dismisses the fine, the appeal is deemed accepted, and the obligation to pay the fine is cancelled. In this case, there is no need for the police to receive the result from the prefecture (Receive Result Appeal from Prefecture) and notify the offender (Notify Result Appeal to Offender).\n",
      "        > 'Notify Result Appeal to Offender': The local police informs the offender of the appeal result. \n",
      "        > 'Appeal to Judge': The offender appeals against the fine to a judge.\n",
      "    IMPORTANT: The last event in a case can be arbitrary. There is no guarantee that the last event is 'Send Fine' or 'Payment'. The last event can be any event in the log.\n",
      "- 'insert_date_appeal_to_prefecture_count' (int): The number of times the event 'Insert Date Appeal to Prefecture' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'send_for_credit_collection_count' (int): The number of times the event 'Send for Credit Collection' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'send_appeal_to_prefecture_count' (int): The number of times the event 'Send Appeal to Prefecture' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'notify_result_appeal_to_offender_count' (int): The number of times the event 'Notify Result Appeal to Offender' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "Reasoning: approach=\"To determine the number of 'Create Fine' events, we need to count the occurrences of rows in the 'event_log' table where the 'concept_name' column is equal to 'Create Fine'. The 'concept_name' column specifies the type of event for each row, and each row represents an individual event. Therefore, the query should be structured to select and count all rows where 'concept_name' = 'Create Fine'. The query will look like: SELECT COUNT(*) FROM event_log WHERE concept_name = 'Create Fine'. This will provide the total number of 'Create Fine' events recorded in the database.\"\n",
      "Question: How many Add penalty events occur?\n",
      "Column Description: THE DATABASE CONTAINS THE TABLE: event_log CONTAINING THE FOLLOWING COLUMNS (only the ones denoted by a \"-\", )\n",
      "- 'case_concept_name' (string): the case identifier, use this to group by cases (retrieve information about cases as a whole)\n",
      "- 'time_timestamp' (datetime): the timestamp of the activity.\n",
      "- 'add_penalty_count' (int): The number of times the event 'Add penalty' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'penalty_added' (int): A boolean indicator (stored as an integer) showing whether any event in a case involves adding a penalty ('Add penalty'). 1 if any event in the case involves adding a penalty, 0 otherwise. This value is consistent across all rows pertaining to the same case.\n",
      "- 'insert_fine_notification_count' (int): The number of times the event 'Insert Fine Notification' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'event_count' (int): The number of events recorded for each case, consistent across all rows pertaining to the same case.\n",
      "- 'send_fine_count' (int): The number of times the event 'Send Fine' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'notify_result_appeal_to_offender_count' (int): The number of times the event 'Notify Result Appeal to Offender' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'concept_name' (string): the activity/ event type name\n",
      "    Activity Description, column: 'concept_name':\n",
      "        > 'Create Fine': The initial creation of the fine in the information system. It initializes event log attributes amount, dismissal, points and totalPaymentAmount.\n",
      "        > 'Send Fine': A notification about the fine is sent by post to the offender.\n",
      "        > 'Insert Fine Notification': The notification is received by the offender.\n",
      "        > 'Add penalty': An additional penalty is applied.\n",
      "        > 'Payment': A payment made by the offender is registered.\n",
      "        > 'Send for Credit Collection': Unpaid fines are sent for credit collection. A separate process is started by a collection agency to collect the money of the unpaid fines.\n",
      "        > 'Insert Date Appeal to Prefecture': The offender appeals against the fine to the prefecture. A prefecture in Italy is an administrative body representing the national government in each province.\n",
      "        > 'Send Appeal to Prefecture': The appeal is sent to the prefecture by the local police.\n",
      "        > 'Receive Result Appeal from Prefecture': The local police receives the result of the appeal. If the prefecture dismisses the fine, the appeal is deemed accepted, and the obligation to pay the fine is cancelled. In this case, there is no need for the police to receive the result from the prefecture (Receive Result Appeal from Prefecture) and notify the offender (Notify Result Appeal to Offender).\n",
      "        > 'Notify Result Appeal to Offender': The local police informs the offender of the appeal result. \n",
      "        > 'Appeal to Judge': The offender appeals against the fine to a judge.\n",
      "    IMPORTANT: The last event in a case can be arbitrary. There is no guarantee that the last event is 'Send Fine' or 'Payment'. The last event can be any event in the log.\n",
      "- 'insert_date_appeal_to_prefecture_count' (int): The number of times the event 'Insert Date Appeal to Prefecture' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'send_for_credit_collection_count' (int): The number of times the event 'Send for Credit Collection' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "Reasoning: approach=\"To determine the total number of 'Add penalty' events, we should use the 'add_penalty_count' column, which records the number of 'Add penalty' events for each case. Since this column is consistent across all rows of the same case, we can sum the 'add_penalty_count' values across all cases to get the total number of 'Add penalty' events. The query should select the sum of 'add_penalty_count' from the 'event_log' table, ensuring that each case is only counted once by using a GROUP BY clause on 'case_concept_name'. This will prevent counting the same 'add_penalty_count' value multiple times for cases with multiple events.\"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[34m[2024-12-23T12:15:22.728065]\u001b[0m\n",
      "\n",
      "\u001b[31mSystem message:\u001b[0m\n",
      "\n",
      "Your input fields are:\n",
      "1. `dataset_description` (str): A description of the dataset that we are using.\n",
      "2. `task_demos` (str): Example inputs/outputs of our module.\n",
      "3. `basic_instruction` (str): Basic instruction.\n",
      "4. `tip` (str): A suggestion for how to go about generating the new instruction.\n",
      "\n",
      "Your output fields are:\n",
      "1. `proposed_instruction` (str): Propose an instruction that will be used to prompt a Language Model to perform this task.\n",
      "\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## dataset_description ## ]]\n",
      "{dataset_description}\n",
      "\n",
      "[[ ## task_demos ## ]]\n",
      "{task_demos}\n",
      "\n",
      "[[ ## basic_instruction ## ]]\n",
      "{basic_instruction}\n",
      "\n",
      "[[ ## tip ## ]]\n",
      "{tip}\n",
      "\n",
      "[[ ## proposed_instruction ## ]]\n",
      "{proposed_instruction}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "In adhering to this structure, your objective is: \n",
      "        Use the information below to learn about a task that we are trying to solve using calls to an LM, then generate a new instruction that will be used to prompt a Language Model to better solve the task.\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## dataset_description ## ]]\n",
      "The dataset captures detailed logs of events related to cases involving fines and penalties, emphasizing statistical analysis through counts, averages, and frequencies of events such as \"Create Fine,\" \"Send Appeal to Prefecture,\" and \"Payment.\" Its well-structured questions indicate a focus on precise event tracking, potentially supporting automated reporting to enhance administrative efficiency. The large volume of records and use of comparative metrics suggest its utility in improving process optimization for case management systems.\n",
      "\n",
      "[[ ## task_demos ## ]]\n",
      "Question: How many cases are in the log?\n",
      "Column Description: THE DATABASE CONTAINS THE TABLE: event_log CONTAINING THE FOLLOWING COLUMNS (only the ones denoted by a \"-\", )\n",
      "- 'case_concept_name' (string): the case identifier, use this to group by cases (retrieve information about cases as a whole)\n",
      "- 'time_timestamp' (datetime): the timestamp of the activity.\n",
      "- 'event_count' (int): The number of events recorded for each case, consistent across all rows pertaining to the same case.\n",
      "- 'notify_result_appeal_to_offender_count' (int): The number of times the event 'Notify Result Appeal to Offender' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'appeal_to_judge_count' (int): The number of times the event 'Appeal to Judge' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'receive_result_appeal_from_prefecture_count' (int): The number of times the event 'Receive Result Appeal from Prefecture' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'insert_date_appeal_to_prefecture_count' (int): The number of times the event 'Insert Date Appeal to Prefecture' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'send_appeal_to_prefecture_count' (int): The number of times the event 'Send Appeal to Prefecture' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'insert_fine_notification_count' (int): The number of times the event 'Insert Fine Notification' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'send_fine_count' (int): The number of times the event 'Send Fine' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'add_penalty_count' (int): The number of times the event 'Add penalty' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "Reasoning: approach=\"To determine the number of cases in the log, we need to count the distinct values of the 'case_concept_name' column. This column serves as the unique identifier for each case and remains consistent across all events pertaining to the same case. Therefore, the query should select the distinct 'case_concept_name' values and count them. This will give us the total number of unique cases in the event log. The SQL query would look like: SELECT COUNT(DISTINCT case_concept_name) FROM event_log.\"\n",
      "Question: How many Create Fine events occur?\n",
      "Column Description: THE DATABASE CONTAINS THE TABLE: event_log CONTAINING THE FOLLOWING COLUMNS (only the ones denoted by a \"-\", )\n",
      "- 'case_concept_name' (string): the case identifier, use this to group by cases (retrieve information about cases as a whole)\n",
      "- 'time_timestamp' (datetime): the timestamp of the activity.\n",
      "- 'insert_fine_notification_count' (int): The number of times the event 'Insert Fine Notification' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'send_fine_count' (int): The number of times the event 'Send Fine' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'event_count' (int): The number of events recorded for each case, consistent across all rows pertaining to the same case.\n",
      "- 'add_penalty_count' (int): The number of times the event 'Add penalty' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'concept_name' (string): the activity/ event type name\n",
      "    Activity Description, column: 'concept_name':\n",
      "        > 'Create Fine': The initial creation of the fine in the information system. It initializes event log attributes amount, dismissal, points and totalPaymentAmount.\n",
      "        > 'Send Fine': A notification about the fine is sent by post to the offender.\n",
      "        > 'Insert Fine Notification': The notification is received by the offender.\n",
      "        > 'Add penalty': An additional penalty is applied.\n",
      "        > 'Payment': A payment made by the offender is registered.\n",
      "        > 'Send for Credit Collection': Unpaid fines are sent for credit collection. A separate process is started by a collection agency to collect the money of the unpaid fines.\n",
      "        > 'Insert Date Appeal to Prefecture': The offender appeals against the fine to the prefecture. A prefecture in Italy is an administrative body representing the national government in each province.\n",
      "        > 'Send Appeal to Prefecture': The appeal is sent to the prefecture by the local police.\n",
      "        > 'Receive Result Appeal from Prefecture': The local police receives the result of the appeal. If the prefecture dismisses the fine, the appeal is deemed accepted, and the obligation to pay the fine is cancelled. In this case, there is no need for the police to receive the result from the prefecture (Receive Result Appeal from Prefecture) and notify the offender (Notify Result Appeal to Offender).\n",
      "        > 'Notify Result Appeal to Offender': The local police informs the offender of the appeal result. \n",
      "        > 'Appeal to Judge': The offender appeals against the fine to a judge.\n",
      "    IMPORTANT: The last event in a case can be arbitrary. There is no guarantee that the last event is 'Send Fine' or 'Payment'. The last event can be any event in the log.\n",
      "- 'insert_date_appeal_to_prefecture_count' (int): The number of times the event 'Insert Date Appeal to Prefecture' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'send_for_credit_collection_count' (int): The number of times the event 'Send for Credit Collection' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'send_appeal_to_prefecture_count' (int): The number of times the event 'Send Appeal to Prefecture' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'notify_result_appeal_to_offender_count' (int): The number of times the event 'Notify Result Appeal to Offender' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "Reasoning: approach=\"To determine the number of 'Create Fine' events, we need to count the occurrences of rows in the 'event_log' table where the 'concept_name' column is equal to 'Create Fine'. The 'concept_name' column specifies the type of event for each row, and each row represents an individual event. Therefore, the query should be structured to select and count all rows where 'concept_name' = 'Create Fine'. The query will look like: SELECT COUNT(*) FROM event_log WHERE concept_name = 'Create Fine'. This will provide the total number of 'Create Fine' events recorded in the database.\"\n",
      "Question: How many Add penalty events occur?\n",
      "Column Description: THE DATABASE CONTAINS THE TABLE: event_log CONTAINING THE FOLLOWING COLUMNS (only the ones denoted by a \"-\", )\n",
      "- 'case_concept_name' (string): the case identifier, use this to group by cases (retrieve information about cases as a whole)\n",
      "- 'time_timestamp' (datetime): the timestamp of the activity.\n",
      "- 'add_penalty_count' (int): The number of times the event 'Add penalty' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'penalty_added' (int): A boolean indicator (stored as an integer) showing whether any event in a case involves adding a penalty ('Add penalty'). 1 if any event in the case involves adding a penalty, 0 otherwise. This value is consistent across all rows pertaining to the same case.\n",
      "- 'insert_fine_notification_count' (int): The number of times the event 'Insert Fine Notification' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'event_count' (int): The number of events recorded for each case, consistent across all rows pertaining to the same case.\n",
      "- 'send_fine_count' (int): The number of times the event 'Send Fine' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'notify_result_appeal_to_offender_count' (int): The number of times the event 'Notify Result Appeal to Offender' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'concept_name' (string): the activity/ event type name\n",
      "    Activity Description, column: 'concept_name':\n",
      "        > 'Create Fine': The initial creation of the fine in the information system. It initializes event log attributes amount, dismissal, points and totalPaymentAmount.\n",
      "        > 'Send Fine': A notification about the fine is sent by post to the offender.\n",
      "        > 'Insert Fine Notification': The notification is received by the offender.\n",
      "        > 'Add penalty': An additional penalty is applied.\n",
      "        > 'Payment': A payment made by the offender is registered.\n",
      "        > 'Send for Credit Collection': Unpaid fines are sent for credit collection. A separate process is started by a collection agency to collect the money of the unpaid fines.\n",
      "        > 'Insert Date Appeal to Prefecture': The offender appeals against the fine to the prefecture. A prefecture in Italy is an administrative body representing the national government in each province.\n",
      "        > 'Send Appeal to Prefecture': The appeal is sent to the prefecture by the local police.\n",
      "        > 'Receive Result Appeal from Prefecture': The local police receives the result of the appeal. If the prefecture dismisses the fine, the appeal is deemed accepted, and the obligation to pay the fine is cancelled. In this case, there is no need for the police to receive the result from the prefecture (Receive Result Appeal from Prefecture) and notify the offender (Notify Result Appeal to Offender).\n",
      "        > 'Notify Result Appeal to Offender': The local police informs the offender of the appeal result. \n",
      "        > 'Appeal to Judge': The offender appeals against the fine to a judge.\n",
      "    IMPORTANT: The last event in a case can be arbitrary. There is no guarantee that the last event is 'Send Fine' or 'Payment'. The last event can be any event in the log.\n",
      "- 'insert_date_appeal_to_prefecture_count' (int): The number of times the event 'Insert Date Appeal to Prefecture' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'send_for_credit_collection_count' (int): The number of times the event 'Send for Credit Collection' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "Reasoning: approach=\"To determine the total number of 'Add penalty' events, we should use the 'add_penalty_count' column, which records the number of 'Add penalty' events for each case. Since this column is consistent across all rows of the same case, we can sum the 'add_penalty_count' values across all cases to get the total number of 'Add penalty' events. The query should select the sum of 'add_penalty_count' from the 'event_log' table, ensuring that each case is only counted once by using a GROUP BY clause on 'case_concept_name'. This will prevent counting the same 'add_penalty_count' value multiple times for cases with multiple events.\"\n",
      "\n",
      "\n",
      "[[ ## basic_instruction ## ]]\n",
      "Objective: Develop a strategy and logic to create a single SQLite query that will answer a given question.\n",
      "Database Information: Use the details about the database and its columns to guide your approach. \n",
      "Be specific about whether the question pertains to \"cases\" or \"events,\" since every row is an event, and multiple events can be part of a single case.\n",
      "Column Details: Some columns contain the same information for each event (row) per case (referred to as \"case predicate\"). Other columns are independent of cases and refer to events directly.\n",
      "You can determine this, based on whether the column description mentions that all values are the same for a case or if the column is aggregated over a case.\n",
      "Grouping: When asked about questions independent of cases and you are using a column that is a case predicate, group by case to avoid counting an aggregated value multiple times.\n",
      "Do not forget about this for percentage calculations as well (using something like (DISTINCT case_concept_name) FILTER (WHERE col = 1) instead of not grouping by case first for case predicates).\n",
      "Query Construction: Do not write the actual query. Instead, provide a detailed explanation of how to construct the query.\n",
      "Aggregation: Aggregate data when necessary. Use subqueries and outer queries to limit the output size. Ensure the final result is a table that directly answers the question.\n",
      "Some questions might have multiple valid anwers(i.e finding case with highest value x, might have mutliple cases with the same highest value), be aware of this and consider LIMIT 10 instead of LIMIT 1 in such cases.\n",
      "\n",
      "[[ ## tip ## ]]\n",
      "Make sure your instruction is very informative and descriptive.\n",
      "\n",
      "Respond with the corresponding output fields, starting with the field `[[ ## proposed_instruction ## ]]`, and then ending with the marker for `[[ ## completed ## ]]`.\n",
      "\n",
      "\n",
      "\u001b[31mResponse:\u001b[0m\n",
      "\n",
      "\u001b[32m[[ ## proposed_instruction ## ]]\n",
      "To create an SQLite query that addresses a specific question about the event log dataset, follow these steps: \n",
      "\n",
      "1. **Understand the Question Context**: Determine whether the question is about \"cases\" or \"events.\" This differentiation is crucial because each row represents an event, but multiple events can belong to a single case. \n",
      "\n",
      "2. **Identify Relevant Columns**: Based on the question, identify which columns are relevant. For example, if the question pertains to a specific event type, focus on columns like 'concept_name' and the corresponding event count columns.\n",
      "\n",
      "3. **Determine Case Predicate Columns**: Recognize which columns have consistent values across all events for a case (case predicate) and which are event-specific. This will guide how you group or aggregate data.\n",
      "\n",
      "4. **Decide on Grouping and Aggregation**: If the question is case-related, group by 'case_concept_name' to ensure you don't count aggregated values multiple times. For event-specific questions, consider whether you need to sum, count, or filter specific events.\n",
      "\n",
      "5. **Construct the Query Explanation**: Provide a detailed explanation of how to construct the query without writing the actual query. Explain the logic for selecting columns, grouping, and any necessary aggregation. Discuss the use of subqueries if needed to limit the output size or to achieve the desired result.\n",
      "\n",
      "6. **Consider Multiple Answers**: If the question can have multiple valid answers (e.g., finding cases with the highest value of a metric), mention the possibility of using LIMIT 10 instead of LIMIT 1 to accommodate multiple results.\n",
      "\n",
      "By following these steps, you can develop a logical strategy for constructing an SQLite query that effectively answers the question using the dataset's structure and content.\n",
      "\n",
      "[[ ## completed ## ]]\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "PROPOSED INSTRUCTION: To create an SQLite query that addresses a specific question about the event log dataset, follow these steps: \n",
      "\n",
      "1. **Understand the Question Context**: Determine whether the question is about \"cases\" or \"events.\" This differentiation is crucial because each row represents an event, but multiple events can belong to a single case. \n",
      "\n",
      "2. **Identify Relevant Columns**: Based on the question, identify which columns are relevant. For example, if the question pertains to a specific event type, focus on columns like 'concept_name' and the corresponding event count columns.\n",
      "\n",
      "3. **Determine Case Predicate Columns**: Recognize which columns have consistent values across all events for a case (case predicate) and which are event-specific. This will guide how you group or aggregate data.\n",
      "\n",
      "4. **Decide on Grouping and Aggregation**: If the question is case-related, group by 'case_concept_name' to ensure you don't count aggregated values multiple times. For event-specific questions, consider whether you need to sum, count, or filter specific events.\n",
      "\n",
      "5. **Construct the Query Explanation**: Provide a detailed explanation of how to construct the query without writing the actual query. Explain the logic for selecting columns, grouping, and any necessary aggregation. Discuss the use of subqueries if needed to limit the output size or to achieve the desired result.\n",
      "\n",
      "6. **Consider Multiple Answers**: If the question can have multiple valid answers (e.g., finding cases with the highest value of a metric), mention the possibility of using LIMIT 10 instead of LIMIT 1 to accommodate multiple results.\n",
      "\n",
      "By following these steps, you can develop a logical strategy for constructing an SQLite query that effectively answers the question using the dataset's structure and content.\n",
      "Using a randomly generated configuration for our grounded proposer.\n",
      "Selected tip: creative\n",
      "task_demos Question: How many cases have been added two or more penalties?\n",
      "Column Description: THE DATABASE CONTAINS THE TABLE: event_log CONTAINING THE FOLLOWING COLUMNS (only the ones denoted by a \"-\", )\n",
      "- 'case_concept_name' (string): the case identifier, use this to group by cases (retrieve information about cases as a whole)\n",
      "- 'time_timestamp' (datetime): the timestamp of the activity.\n",
      "- 'add_penalty_count' (int): The number of times the event 'Add penalty' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'penalty_added' (int): A boolean indicator (stored as an integer) showing whether any event in a case involves adding a penalty ('Add penalty'). 1 if any event in the case involves adding a penalty, 0 otherwise. This value is consistent across all rows pertaining to the same case.\n",
      "- 'notify_result_appeal_to_offender_count' (int): The number of times the event 'Notify Result Appeal to Offender' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'appeal_to_judge_count' (int): The number of times the event 'Appeal to Judge' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'concept_name' (string): the activity/ event type name\n",
      "    Activity Description, column: 'concept_name':\n",
      "        > 'Create Fine': The initial creation of the fine in the information system. It initializes event log attributes amount, dismissal, points and totalPaymentAmount.\n",
      "        > 'Send Fine': A notification about the fine is sent by post to the offender.\n",
      "        > 'Insert Fine Notification': The notification is received by the offender.\n",
      "        > 'Add penalty': An additional penalty is applied.\n",
      "        > 'Payment': A payment made by the offender is registered.\n",
      "        > 'Send for Credit Collection': Unpaid fines are sent for credit collection. A separate process is started by a collection agency to collect the money of the unpaid fines.\n",
      "        > 'Insert Date Appeal to Prefecture': The offender appeals against the fine to the prefecture. A prefecture in Italy is an administrative body representing the national government in each province.\n",
      "        > 'Send Appeal to Prefecture': The appeal is sent to the prefecture by the local police.\n",
      "        > 'Receive Result Appeal from Prefecture': The local police receives the result of the appeal. If the prefecture dismisses the fine, the appeal is deemed accepted, and the obligation to pay the fine is cancelled. In this case, there is no need for the police to receive the result from the prefecture (Receive Result Appeal from Prefecture) and notify the offender (Notify Result Appeal to Offender).\n",
      "        > 'Notify Result Appeal to Offender': The local police informs the offender of the appeal result. \n",
      "        > 'Appeal to Judge': The offender appeals against the fine to a judge.\n",
      "    IMPORTANT: The last event in a case can be arbitrary. There is no guarantee that the last event is 'Send Fine' or 'Payment'. The last event can be any event in the log.\n",
      "- 'insert_fine_notification_count' (int): The number of times the event 'Insert Fine Notification' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'dismissed_AND_fully_paid' (int): A boolean indicator (stored as an integer) showing whether any event in a case involves both the dismissal of the fine and the full payment of the fine. 1 if any event in the case involves both, 0 otherwise. This value is consistent across all rows pertaining to the same case.\n",
      "- 'insert_date_appeal_to_prefecture_count' (int): The number of times the event 'Insert Date Appeal to Prefecture' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'dismissed_by_prefecture' (int): A boolean indicator (stored as an integer) showing whether the fine was dismissed by the prefecture ('#') across all events of a case. 1 for dismissed by the prefecture, 0 otherwise.\n",
      "Reasoning: approach=\"To determine how many cases have been added two or more penalties, we need to use the 'add_penalty_count' column. This column indicates the number of 'Add penalty' events for each case and is consistent across all rows pertaining to the same case. We are interested in counting the number of distinct cases where 'add_penalty_count' is greater than or equal to 2. The steps to construct the query are as follows: 1. Select the 'case_concept_name' and 'add_penalty_count' columns from the 'event_log' table. 2. Filter the results to include only those cases where 'add_penalty_count' is greater than or equal to 2. 3. Use the COUNT function to count the number of distinct 'case_concept_name' values that satisfy this condition. This will give us the total number of cases that have been added two or more penalties.\"\n",
      "Question: What is the average number of payment events per case?\n",
      "Column Description: THE DATABASE CONTAINS THE TABLE: event_log CONTAINING THE FOLLOWING COLUMNS (only the ones denoted by a \"-\", )\n",
      "- 'case_concept_name' (string): the case identifier, use this to group by cases (retrieve information about cases as a whole)\n",
      "- 'time_timestamp' (datetime): the timestamp of the activity.\n",
      "- 'payment_count' (int): The number of times the event 'Payment' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'send_for_credit_collection_count' (int): The number of times the event 'Send for Credit Collection' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'event_count' (int): The number of events recorded for each case, consistent across all rows pertaining to the same case.\n",
      "- 'send_fine_count' (int): The number of times the event 'Send Fine' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'notify_result_appeal_to_offender_count' (int): The number of times the event 'Notify Result Appeal to Offender' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'appeal_to_judge_count' (int): The number of times the event 'Appeal to Judge' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'send_appeal_to_prefecture_count' (int): The number of times the event 'Send Appeal to Prefecture' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'insert_date_appeal_to_prefecture_count' (int): The number of times the event 'Insert Date Appeal to Prefecture' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'credit_collected' (int): A boolean indicator (stored as an integer) showing whether any event in a case involves sending the fine for credit collection ('Send for Credit Collection'). 1 if any event in the case involves credit collection, 0 otherwise. This value is consistent across all rows pertaining to the same case.\n",
      "Reasoning: approach=\"To calculate the average number of payment events per case, we need to use the 'payment_count' column, which indicates the number of payment events for each case. Since this value is consistent across all rows for a given case, we can directly use it to compute the average. The steps to construct the query are as follows: 1. Select the 'payment_count' values from the 'event_log' table. 2. Use the AVG function to calculate the average of these 'payment_count' values. 3. Since each 'payment_count' is consistent per case, we don't need to group by 'case_concept_name'. The SQL query would look like: SELECT AVG(payment_count) FROM event_log. This will give us the average number of payment events per case.\"\n",
      "Question: How many cases have two or more payment events?\n",
      "Column Description: THE DATABASE CONTAINS THE TABLE: event_log CONTAINING THE FOLLOWING COLUMNS (only the ones denoted by a \"-\", )\n",
      "- 'case_concept_name' (string): the case identifier, use this to group by cases (retrieve information about cases as a whole)\n",
      "- 'time_timestamp' (datetime): the timestamp of the activity.\n",
      "- 'payment_count' (int): The number of times the event 'Payment' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'send_for_credit_collection_count' (int): The number of times the event 'Send for Credit Collection' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'event_count' (int): The number of events recorded for each case, consistent across all rows pertaining to the same case.\n",
      "- 'credit_collected_AND_fully_paid' (int): A boolean indicator (stored as an integer) showing whether any event in a case involves both credit collection ('Send for Credit Collection') and full payment of the fine. 1 if any event in the case involves both, 0 otherwise. This value is consistent across all rows pertaining to the same case.\n",
      "- 'credit_collected' (int): A boolean indicator (stored as an integer) showing whether any event in a case involves sending the fine for credit collection ('Send for Credit Collection'). 1 if any event in the case involves credit collection, 0 otherwise. This value is consistent across all rows pertaining to the same case.\n",
      "- 'credit_collected_AND_dismissed' (int): A boolean indicator (stored as an integer) showing whether any event in a case involves both dismissal of the fine and credit collection. 1 if any event in the case involves both, 0 otherwise. This value is consistent across all rows pertaining to the same case.\n",
      "- 'add_penalty_count' (int): The number of times the event 'Add penalty' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'send_appeal_to_prefecture_count' (int): The number of times the event 'Send Appeal to Prefecture' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'appeal_to_judge_count' (int): The number of times the event 'Appeal to Judge' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "Reasoning: approach=\"To determine how many cases have two or more payment events, we should utilize the 'payment_count' column, which indicates the number of payment events for each case and is consistent across all rows pertaining to the same case. We need to count the distinct cases where 'payment_count' is greater than or equal to 2. The query should select from the 'event_log' table, filter where 'payment_count' >= 2, and count the distinct 'case_concept_name' values to ensure each case is counted only once. This will give us the total number of cases with two or more payment events.\"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[34m[2024-12-23T12:15:30.608716]\u001b[0m\n",
      "\n",
      "\u001b[31mSystem message:\u001b[0m\n",
      "\n",
      "Your input fields are:\n",
      "1. `dataset_description` (str): A description of the dataset that we are using.\n",
      "2. `task_demos` (str): Example inputs/outputs of our module.\n",
      "3. `basic_instruction` (str): Basic instruction.\n",
      "4. `tip` (str): A suggestion for how to go about generating the new instruction.\n",
      "\n",
      "Your output fields are:\n",
      "1. `proposed_instruction` (str): Propose an instruction that will be used to prompt a Language Model to perform this task.\n",
      "\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## dataset_description ## ]]\n",
      "{dataset_description}\n",
      "\n",
      "[[ ## task_demos ## ]]\n",
      "{task_demos}\n",
      "\n",
      "[[ ## basic_instruction ## ]]\n",
      "{basic_instruction}\n",
      "\n",
      "[[ ## tip ## ]]\n",
      "{tip}\n",
      "\n",
      "[[ ## proposed_instruction ## ]]\n",
      "{proposed_instruction}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "In adhering to this structure, your objective is: \n",
      "        Use the information below to learn about a task that we are trying to solve using calls to an LM, then generate a new instruction that will be used to prompt a Language Model to better solve the task.\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## dataset_description ## ]]\n",
      "The dataset captures detailed logs of events related to cases involving fines and penalties, emphasizing statistical analysis through counts, averages, and frequencies of events such as \"Create Fine,\" \"Send Appeal to Prefecture,\" and \"Payment.\" Its well-structured questions indicate a focus on precise event tracking, potentially supporting automated reporting to enhance administrative efficiency. The large volume of records and use of comparative metrics suggest its utility in improving process optimization for case management systems.\n",
      "\n",
      "[[ ## task_demos ## ]]\n",
      "Question: How many cases have been added two or more penalties?\n",
      "Column Description: THE DATABASE CONTAINS THE TABLE: event_log CONTAINING THE FOLLOWING COLUMNS (only the ones denoted by a \"-\", )\n",
      "- 'case_concept_name' (string): the case identifier, use this to group by cases (retrieve information about cases as a whole)\n",
      "- 'time_timestamp' (datetime): the timestamp of the activity.\n",
      "- 'add_penalty_count' (int): The number of times the event 'Add penalty' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'penalty_added' (int): A boolean indicator (stored as an integer) showing whether any event in a case involves adding a penalty ('Add penalty'). 1 if any event in the case involves adding a penalty, 0 otherwise. This value is consistent across all rows pertaining to the same case.\n",
      "- 'notify_result_appeal_to_offender_count' (int): The number of times the event 'Notify Result Appeal to Offender' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'appeal_to_judge_count' (int): The number of times the event 'Appeal to Judge' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'concept_name' (string): the activity/ event type name\n",
      "    Activity Description, column: 'concept_name':\n",
      "        > 'Create Fine': The initial creation of the fine in the information system. It initializes event log attributes amount, dismissal, points and totalPaymentAmount.\n",
      "        > 'Send Fine': A notification about the fine is sent by post to the offender.\n",
      "        > 'Insert Fine Notification': The notification is received by the offender.\n",
      "        > 'Add penalty': An additional penalty is applied.\n",
      "        > 'Payment': A payment made by the offender is registered.\n",
      "        > 'Send for Credit Collection': Unpaid fines are sent for credit collection. A separate process is started by a collection agency to collect the money of the unpaid fines.\n",
      "        > 'Insert Date Appeal to Prefecture': The offender appeals against the fine to the prefecture. A prefecture in Italy is an administrative body representing the national government in each province.\n",
      "        > 'Send Appeal to Prefecture': The appeal is sent to the prefecture by the local police.\n",
      "        > 'Receive Result Appeal from Prefecture': The local police receives the result of the appeal. If the prefecture dismisses the fine, the appeal is deemed accepted, and the obligation to pay the fine is cancelled. In this case, there is no need for the police to receive the result from the prefecture (Receive Result Appeal from Prefecture) and notify the offender (Notify Result Appeal to Offender).\n",
      "        > 'Notify Result Appeal to Offender': The local police informs the offender of the appeal result. \n",
      "        > 'Appeal to Judge': The offender appeals against the fine to a judge.\n",
      "    IMPORTANT: The last event in a case can be arbitrary. There is no guarantee that the last event is 'Send Fine' or 'Payment'. The last event can be any event in the log.\n",
      "- 'insert_fine_notification_count' (int): The number of times the event 'Insert Fine Notification' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'dismissed_AND_fully_paid' (int): A boolean indicator (stored as an integer) showing whether any event in a case involves both the dismissal of the fine and the full payment of the fine. 1 if any event in the case involves both, 0 otherwise. This value is consistent across all rows pertaining to the same case.\n",
      "- 'insert_date_appeal_to_prefecture_count' (int): The number of times the event 'Insert Date Appeal to Prefecture' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'dismissed_by_prefecture' (int): A boolean indicator (stored as an integer) showing whether the fine was dismissed by the prefecture ('#') across all events of a case. 1 for dismissed by the prefecture, 0 otherwise.\n",
      "Reasoning: approach=\"To determine how many cases have been added two or more penalties, we need to use the 'add_penalty_count' column. This column indicates the number of 'Add penalty' events for each case and is consistent across all rows pertaining to the same case. We are interested in counting the number of distinct cases where 'add_penalty_count' is greater than or equal to 2. The steps to construct the query are as follows: 1. Select the 'case_concept_name' and 'add_penalty_count' columns from the 'event_log' table. 2. Filter the results to include only those cases where 'add_penalty_count' is greater than or equal to 2. 3. Use the COUNT function to count the number of distinct 'case_concept_name' values that satisfy this condition. This will give us the total number of cases that have been added two or more penalties.\"\n",
      "Question: What is the average number of payment events per case?\n",
      "Column Description: THE DATABASE CONTAINS THE TABLE: event_log CONTAINING THE FOLLOWING COLUMNS (only the ones denoted by a \"-\", )\n",
      "- 'case_concept_name' (string): the case identifier, use this to group by cases (retrieve information about cases as a whole)\n",
      "- 'time_timestamp' (datetime): the timestamp of the activity.\n",
      "- 'payment_count' (int): The number of times the event 'Payment' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'send_for_credit_collection_count' (int): The number of times the event 'Send for Credit Collection' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'event_count' (int): The number of events recorded for each case, consistent across all rows pertaining to the same case.\n",
      "- 'send_fine_count' (int): The number of times the event 'Send Fine' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'notify_result_appeal_to_offender_count' (int): The number of times the event 'Notify Result Appeal to Offender' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'appeal_to_judge_count' (int): The number of times the event 'Appeal to Judge' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'send_appeal_to_prefecture_count' (int): The number of times the event 'Send Appeal to Prefecture' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'insert_date_appeal_to_prefecture_count' (int): The number of times the event 'Insert Date Appeal to Prefecture' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'credit_collected' (int): A boolean indicator (stored as an integer) showing whether any event in a case involves sending the fine for credit collection ('Send for Credit Collection'). 1 if any event in the case involves credit collection, 0 otherwise. This value is consistent across all rows pertaining to the same case.\n",
      "Reasoning: approach=\"To calculate the average number of payment events per case, we need to use the 'payment_count' column, which indicates the number of payment events for each case. Since this value is consistent across all rows for a given case, we can directly use it to compute the average. The steps to construct the query are as follows: 1. Select the 'payment_count' values from the 'event_log' table. 2. Use the AVG function to calculate the average of these 'payment_count' values. 3. Since each 'payment_count' is consistent per case, we don't need to group by 'case_concept_name'. The SQL query would look like: SELECT AVG(payment_count) FROM event_log. This will give us the average number of payment events per case.\"\n",
      "Question: How many cases have two or more payment events?\n",
      "Column Description: THE DATABASE CONTAINS THE TABLE: event_log CONTAINING THE FOLLOWING COLUMNS (only the ones denoted by a \"-\", )\n",
      "- 'case_concept_name' (string): the case identifier, use this to group by cases (retrieve information about cases as a whole)\n",
      "- 'time_timestamp' (datetime): the timestamp of the activity.\n",
      "- 'payment_count' (int): The number of times the event 'Payment' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'send_for_credit_collection_count' (int): The number of times the event 'Send for Credit Collection' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'event_count' (int): The number of events recorded for each case, consistent across all rows pertaining to the same case.\n",
      "- 'credit_collected_AND_fully_paid' (int): A boolean indicator (stored as an integer) showing whether any event in a case involves both credit collection ('Send for Credit Collection') and full payment of the fine. 1 if any event in the case involves both, 0 otherwise. This value is consistent across all rows pertaining to the same case.\n",
      "- 'credit_collected' (int): A boolean indicator (stored as an integer) showing whether any event in a case involves sending the fine for credit collection ('Send for Credit Collection'). 1 if any event in the case involves credit collection, 0 otherwise. This value is consistent across all rows pertaining to the same case.\n",
      "- 'credit_collected_AND_dismissed' (int): A boolean indicator (stored as an integer) showing whether any event in a case involves both dismissal of the fine and credit collection. 1 if any event in the case involves both, 0 otherwise. This value is consistent across all rows pertaining to the same case.\n",
      "- 'add_penalty_count' (int): The number of times the event 'Add penalty' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'send_appeal_to_prefecture_count' (int): The number of times the event 'Send Appeal to Prefecture' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "- 'appeal_to_judge_count' (int): The number of times the event 'Appeal to Judge' occurs for each case, consistent across all rows pertaining to the same case.\n",
      "Reasoning: approach=\"To determine how many cases have two or more payment events, we should utilize the 'payment_count' column, which indicates the number of payment events for each case and is consistent across all rows pertaining to the same case. We need to count the distinct cases where 'payment_count' is greater than or equal to 2. The query should select from the 'event_log' table, filter where 'payment_count' >= 2, and count the distinct 'case_concept_name' values to ensure each case is counted only once. This will give us the total number of cases with two or more payment events.\"\n",
      "\n",
      "\n",
      "[[ ## basic_instruction ## ]]\n",
      "Objective: Develop a strategy and logic to create a single SQLite query that will answer a given question.\n",
      "Database Information: Use the details about the database and its columns to guide your approach. \n",
      "Be specific about whether the question pertains to \"cases\" or \"events,\" since every row is an event, and multiple events can be part of a single case.\n",
      "Column Details: Some columns contain the same information for each event (row) per case (referred to as \"case predicate\"). Other columns are independent of cases and refer to events directly.\n",
      "You can determine this, based on whether the column description mentions that all values are the same for a case or if the column is aggregated over a case.\n",
      "Grouping: When asked about questions independent of cases and you are using a column that is a case predicate, group by case to avoid counting an aggregated value multiple times.\n",
      "Do not forget about this for percentage calculations as well (using something like (DISTINCT case_concept_name) FILTER (WHERE col = 1) instead of not grouping by case first for case predicates).\n",
      "Query Construction: Do not write the actual query. Instead, provide a detailed explanation of how to construct the query.\n",
      "Aggregation: Aggregate data when necessary. Use subqueries and outer queries to limit the output size. Ensure the final result is a table that directly answers the question.\n",
      "Some questions might have multiple valid anwers(i.e finding case with highest value x, might have mutliple cases with the same highest value), be aware of this and consider LIMIT 10 instead of LIMIT 1 in such cases.\n",
      "\n",
      "[[ ## tip ## ]]\n",
      "Don't be afraid to be creative when creating the new instruction!\n",
      "\n",
      "Respond with the corresponding output fields, starting with the field `[[ ## proposed_instruction ## ]]`, and then ending with the marker for `[[ ## completed ## ]]`.\n",
      "\n",
      "\n",
      "\u001b[31mResponse:\u001b[0m\n",
      "\n",
      "\u001b[32m[[ ## proposed_instruction ## ]]\n",
      "To address questions related to fines and penalties, develop a comprehensive strategy to construct a single SQLite query that accurately answers the query. Begin by identifying whether the question pertains to individual cases or specific events within those cases. Use the provided column descriptions to determine if the data is consistent across events for a case or specific to individual events. When the question focuses on case-level data, ensure to group by 'case_concept_name' to avoid duplicating aggregated values. For event-specific inquiries, focus on the relevant columns that capture event details. When constructing the query, explain the process step-by-step, including any necessary aggregations or filtering, and ensure the final result is a succinct table that directly answers the question. Consider using subqueries for complex aggregations and apply LIMIT wisely when multiple cases might meet the query criteria equally. Avoid writing the actual query; instead, provide a clear, logical roadmap for query construction.\n",
      "\n",
      "[[ ## completed ## ]]\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "PROPOSED INSTRUCTION: To address questions related to fines and penalties, develop a comprehensive strategy to construct a single SQLite query that accurately answers the query. Begin by identifying whether the question pertains to individual cases or specific events within those cases. Use the provided column descriptions to determine if the data is consistent across events for a case or specific to individual events. When the question focuses on case-level data, ensure to group by 'case_concept_name' to avoid duplicating aggregated values. For event-specific inquiries, focus on the relevant columns that capture event details. When constructing the query, explain the process step-by-step, including any necessary aggregations or filtering, and ensure the final result is a succinct table that directly answers the question. Consider using subqueries for complex aggregations and apply LIMIT wisely when multiple cases might meet the query criteria equally. Avoid writing the actual query; instead, provide a clear, logical roadmap for query construction.\n",
      "Using a randomly generated configuration for our grounded proposer.\n",
      "Selected tip: creative\n",
      "task_demos \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[34m[2024-12-23T12:15:34.198529]\u001b[0m\n",
      "\n",
      "\u001b[31mSystem message:\u001b[0m\n",
      "\n",
      "Your input fields are:\n",
      "1. `dataset_description` (str): A description of the dataset that we are using.\n",
      "2. `task_demos` (str): Example inputs/outputs of our module.\n",
      "3. `basic_instruction` (str): Basic instruction.\n",
      "4. `tip` (str): A suggestion for how to go about generating the new instruction.\n",
      "\n",
      "Your output fields are:\n",
      "1. `proposed_instruction` (str): Propose an instruction that will be used to prompt a Language Model to perform this task.\n",
      "\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## dataset_description ## ]]\n",
      "{dataset_description}\n",
      "\n",
      "[[ ## task_demos ## ]]\n",
      "{task_demos}\n",
      "\n",
      "[[ ## basic_instruction ## ]]\n",
      "{basic_instruction}\n",
      "\n",
      "[[ ## tip ## ]]\n",
      "{tip}\n",
      "\n",
      "[[ ## proposed_instruction ## ]]\n",
      "{proposed_instruction}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "In adhering to this structure, your objective is: \n",
      "        Use the information below to learn about a task that we are trying to solve using calls to an LM, then generate a new instruction that will be used to prompt a Language Model to better solve the task.\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## dataset_description ## ]]\n",
      "The dataset captures detailed logs of events related to cases involving fines and penalties, emphasizing statistical analysis through counts, averages, and frequencies of events such as \"Create Fine,\" \"Send Appeal to Prefecture,\" and \"Payment.\" Its well-structured questions indicate a focus on precise event tracking, potentially supporting automated reporting to enhance administrative efficiency. The large volume of records and use of comparative metrics suggest its utility in improving process optimization for case management systems.\n",
      "\n",
      "[[ ## task_demos ## ]]\n",
      "\n",
      "\n",
      "[[ ## basic_instruction ## ]]\n",
      "Carefully analyze the question and information in the table to form a helpful response. Use all the columns from the table (information) when writing your answer (don't leave away any additional information).\n",
      "\n",
      "[[ ## tip ## ]]\n",
      "Don't be afraid to be creative when creating the new instruction!\n",
      "\n",
      "Respond with the corresponding output fields, starting with the field `[[ ## proposed_instruction ## ]]`, and then ending with the marker for `[[ ## completed ## ]]`.\n",
      "\n",
      "\n",
      "\u001b[31mResponse:\u001b[0m\n",
      "\n",
      "\u001b[32m[[ ## proposed_instruction ## ]]\n",
      "Analyze the dataset to extract meaningful insights by examining the detailed logs of events related to fines and penalties. Pay particular attention to statistical metrics such as counts, averages, and frequencies of events like \"Create Fine,\" \"Send Appeal to Prefecture,\" and \"Payment.\" Utilize all available data columns to construct a comprehensive response that supports automated reporting and enhances administrative efficiency. Consider how comparative metrics can be leveraged to optimize case management processes.\n",
      "\n",
      "[[ ## completed ## ]]\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "PROPOSED INSTRUCTION: Analyze the dataset to extract meaningful insights by examining the detailed logs of events related to fines and penalties. Pay particular attention to statistical metrics such as counts, averages, and frequencies of events like \"Create Fine,\" \"Send Appeal to Prefecture,\" and \"Payment.\" Utilize all available data columns to construct a comprehensive response that supports automated reporting and enhances administrative efficiency. Consider how comparative metrics can be leveraged to optimize case management processes.\n",
      "Using a randomly generated configuration for our grounded proposer.\n",
      "Selected tip: high_stakes\n",
      "task_demos Question: Which case has the most payment events?\n",
      "Table: case_concept_name|payment_count \n",
      "C20817 | 15\n",
      "Sql: SELECT case_concept_name, payment_count FROM event_log ORDER BY payment_count DESC LIMIT 1;\n",
      "Answer: Case C20817 has the most payment events with a total of 15 payments.\n",
      "Question: How many cases are Sent for Credit Collection?\n",
      "Table: cases_sent_for_credit_collection \n",
      "59013\n",
      "Sql: SELECT COUNT(DISTINCT case_concept_name) AS cases_sent_for_credit_collection FROM event_log WHERE credit_collected = 1;\n",
      "Answer: 59013\n",
      "Question: How many Add penalty events occur?\n",
      "Table: total_add_penalty_events \n",
      "79860\n",
      "Sql: SELECT SUM(add_penalty_count) AS total_add_penalty_events FROM (SELECT DISTINCT case_concept_name, add_penalty_count FROM event_log);\n",
      "Answer: 79860\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[34m[2024-12-23T12:15:36.343950]\u001b[0m\n",
      "\n",
      "\u001b[31mSystem message:\u001b[0m\n",
      "\n",
      "Your input fields are:\n",
      "1. `dataset_description` (str): A description of the dataset that we are using.\n",
      "2. `task_demos` (str): Example inputs/outputs of our module.\n",
      "3. `basic_instruction` (str): Basic instruction.\n",
      "4. `tip` (str): A suggestion for how to go about generating the new instruction.\n",
      "\n",
      "Your output fields are:\n",
      "1. `proposed_instruction` (str): Propose an instruction that will be used to prompt a Language Model to perform this task.\n",
      "\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## dataset_description ## ]]\n",
      "{dataset_description}\n",
      "\n",
      "[[ ## task_demos ## ]]\n",
      "{task_demos}\n",
      "\n",
      "[[ ## basic_instruction ## ]]\n",
      "{basic_instruction}\n",
      "\n",
      "[[ ## tip ## ]]\n",
      "{tip}\n",
      "\n",
      "[[ ## proposed_instruction ## ]]\n",
      "{proposed_instruction}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "In adhering to this structure, your objective is: \n",
      "        Use the information below to learn about a task that we are trying to solve using calls to an LM, then generate a new instruction that will be used to prompt a Language Model to better solve the task.\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## dataset_description ## ]]\n",
      "The dataset captures detailed logs of events related to cases involving fines and penalties, emphasizing statistical analysis through counts, averages, and frequencies of events such as \"Create Fine,\" \"Send Appeal to Prefecture,\" and \"Payment.\" Its well-structured questions indicate a focus on precise event tracking, potentially supporting automated reporting to enhance administrative efficiency. The large volume of records and use of comparative metrics suggest its utility in improving process optimization for case management systems.\n",
      "\n",
      "[[ ## task_demos ## ]]\n",
      "Question: Which case has the most payment events?\n",
      "Table: case_concept_name|payment_count \n",
      "C20817 | 15\n",
      "Sql: SELECT case_concept_name, payment_count FROM event_log ORDER BY payment_count DESC LIMIT 1;\n",
      "Answer: Case C20817 has the most payment events with a total of 15 payments.\n",
      "Question: How many cases are Sent for Credit Collection?\n",
      "Table: cases_sent_for_credit_collection \n",
      "59013\n",
      "Sql: SELECT COUNT(DISTINCT case_concept_name) AS cases_sent_for_credit_collection FROM event_log WHERE credit_collected = 1;\n",
      "Answer: 59013\n",
      "Question: How many Add penalty events occur?\n",
      "Table: total_add_penalty_events \n",
      "79860\n",
      "Sql: SELECT SUM(add_penalty_count) AS total_add_penalty_events FROM (SELECT DISTINCT case_concept_name, add_penalty_count FROM event_log);\n",
      "Answer: 79860\n",
      "\n",
      "\n",
      "[[ ## basic_instruction ## ]]\n",
      "Carefully analyze the question and information in the table to form a helpful response. Use all the columns from the table (information) when writing your answer (don't leave away any additional information).\n",
      "\n",
      "[[ ## tip ## ]]\n",
      "The instruction should include a high stakes scenario in which the LM must solve the task!\n",
      "\n",
      "Respond with the corresponding output fields, starting with the field `[[ ## proposed_instruction ## ]]`, and then ending with the marker for `[[ ## completed ## ]]`.\n",
      "\n",
      "\n",
      "\u001b[31mResponse:\u001b[0m\n",
      "\n",
      "\u001b[32m[[ ## proposed_instruction ## ]]\n",
      "Imagine you are tasked with ensuring the smooth operation of a case management system for a governmental agency. Your role is crucial as it directly impacts the efficiency of handling fines and penalties. Analyze the given question and the table data thoroughly to generate a precise SQL query that retrieves the necessary information. Your response should include all relevant columns from the table, providing a comprehensive answer. The accuracy of your response could significantly affect the agency's ability to optimize their processes and improve administrative efficiency. \n",
      "\n",
      "[[ ## completed ## ]]\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "PROPOSED INSTRUCTION: Imagine you are tasked with ensuring the smooth operation of a case management system for a governmental agency. Your role is crucial as it directly impacts the efficiency of handling fines and penalties. Analyze the given question and the table data thoroughly to generate a precise SQL query that retrieves the necessary information. Your response should include all relevant columns from the table, providing a comprehensive answer. The accuracy of your response could significantly affect the agency's ability to optimize their processes and improve administrative efficiency.\n",
      "Using a randomly generated configuration for our grounded proposer.\n",
      "Selected tip: high_stakes\n",
      "task_demos Question: How many cases are in the log?\n",
      "Table: number_of_cases \n",
      "150370\n",
      "Sql: SELECT COUNT(DISTINCT case_concept_name) AS number_of_cases FROM event_log;\n",
      "Answer: 150370\n",
      "Question: How many Create Fine events occur?\n",
      "Table: COUNT(*) \n",
      "150370\n",
      "Sql: SELECT COUNT(*) FROM event_log WHERE concept_name = 'Create Fine';\n",
      "Answer: 150370\n",
      "Question: How many Add penalty events occur?\n",
      "Table: total_add_penalty_events \n",
      "79860\n",
      "Sql: SELECT SUM(add_penalty_count) AS total_add_penalty_events FROM (SELECT DISTINCT case_concept_name, add_penalty_count FROM event_log);\n",
      "Answer: 79860\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[34m[2024-12-23T12:15:43.414820]\u001b[0m\n",
      "\n",
      "\u001b[31mSystem message:\u001b[0m\n",
      "\n",
      "Your input fields are:\n",
      "1. `dataset_description` (str): A description of the dataset that we are using.\n",
      "2. `task_demos` (str): Example inputs/outputs of our module.\n",
      "3. `basic_instruction` (str): Basic instruction.\n",
      "4. `tip` (str): A suggestion for how to go about generating the new instruction.\n",
      "\n",
      "Your output fields are:\n",
      "1. `proposed_instruction` (str): Propose an instruction that will be used to prompt a Language Model to perform this task.\n",
      "\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## dataset_description ## ]]\n",
      "{dataset_description}\n",
      "\n",
      "[[ ## task_demos ## ]]\n",
      "{task_demos}\n",
      "\n",
      "[[ ## basic_instruction ## ]]\n",
      "{basic_instruction}\n",
      "\n",
      "[[ ## tip ## ]]\n",
      "{tip}\n",
      "\n",
      "[[ ## proposed_instruction ## ]]\n",
      "{proposed_instruction}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "In adhering to this structure, your objective is: \n",
      "        Use the information below to learn about a task that we are trying to solve using calls to an LM, then generate a new instruction that will be used to prompt a Language Model to better solve the task.\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## dataset_description ## ]]\n",
      "The dataset captures detailed logs of events related to cases involving fines and penalties, emphasizing statistical analysis through counts, averages, and frequencies of events such as \"Create Fine,\" \"Send Appeal to Prefecture,\" and \"Payment.\" Its well-structured questions indicate a focus on precise event tracking, potentially supporting automated reporting to enhance administrative efficiency. The large volume of records and use of comparative metrics suggest its utility in improving process optimization for case management systems.\n",
      "\n",
      "[[ ## task_demos ## ]]\n",
      "Question: How many cases are in the log?\n",
      "Table: number_of_cases \n",
      "150370\n",
      "Sql: SELECT COUNT(DISTINCT case_concept_name) AS number_of_cases FROM event_log;\n",
      "Answer: 150370\n",
      "Question: How many Create Fine events occur?\n",
      "Table: COUNT(*) \n",
      "150370\n",
      "Sql: SELECT COUNT(*) FROM event_log WHERE concept_name = 'Create Fine';\n",
      "Answer: 150370\n",
      "Question: How many Add penalty events occur?\n",
      "Table: total_add_penalty_events \n",
      "79860\n",
      "Sql: SELECT SUM(add_penalty_count) AS total_add_penalty_events FROM (SELECT DISTINCT case_concept_name, add_penalty_count FROM event_log);\n",
      "Answer: 79860\n",
      "\n",
      "\n",
      "[[ ## basic_instruction ## ]]\n",
      "Carefully analyze the question and information in the table to form a helpful response. Use all the columns from the table (information) when writing your answer (don't leave away any additional information).\n",
      "\n",
      "[[ ## tip ## ]]\n",
      "The instruction should include a high stakes scenario in which the LM must solve the task!\n",
      "\n",
      "Respond with the corresponding output fields, starting with the field `[[ ## proposed_instruction ## ]]`, and then ending with the marker for `[[ ## completed ## ]]`.\n",
      "\n",
      "\n",
      "\u001b[31mResponse:\u001b[0m\n",
      "\n",
      "\u001b[32m[[ ## proposed_instruction ## ]]\n",
      "Imagine you are tasked with generating an urgent report for a high-level meeting in a government department responsible for case management systems. Your job is to analyze the event logs and provide precise statistical insights. Carefully examine the question and utilize all available data from the table to construct a comprehensive and accurate response. Consider the implications of each event type, such as \"Create Fine\" or \"Add Penalty,\" and ensure that your answer is not only correct but also provides valuable insights that can influence decision-making processes. Remember, the accuracy and depth of your response could significantly impact policy decisions and administrative efficiency improvements.\n",
      "\n",
      "[[ ## completed ## ]]\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "PROPOSED INSTRUCTION: Imagine you are tasked with generating an urgent report for a high-level meeting in a government department responsible for case management systems. Your job is to analyze the event logs and provide precise statistical insights. Carefully examine the question and utilize all available data from the table to construct a comprehensive and accurate response. Consider the implications of each event type, such as \"Create Fine\" or \"Add Penalty,\" and ensure that your answer is not only correct but also provides valuable insights that can influence decision-making processes. Remember, the accuracy and depth of your response could significantly impact policy decisions and administrative efficiency improvements.\n",
      "Using a randomly generated configuration for our grounded proposer.\n",
      "Selected tip: none\n",
      "task_demos Question: How many cases have been added two or more penalties?\n",
      "Table: number_of_cases_with_two_or_more_penalties \n",
      "0\n",
      "Sql: SELECT COUNT(DISTINCT case_concept_name) AS number_of_cases_with_two_or_more_penalties FROM event_log WHERE add_penalty_count >= 2;\n",
      "Answer: 0\n",
      "Question: What is the average number of payment events per case?\n",
      "Table: average_payment_events_per_case \n",
      "0.5160670346478686\n",
      "Sql: SELECT AVG(payment_count) AS average_payment_events_per_case FROM (SELECT DISTINCT case_concept_name, payment_count FROM event_log);\n",
      "Answer: 0.5160670346478686\n",
      "Question: How many cases have two or more payment events?\n",
      "Table: case_count \n",
      "7542\n",
      "Sql: SELECT COUNT(DISTINCT case_concept_name) AS case_count FROM event_log WHERE payment_count >= 2;\n",
      "Answer: 7542\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/23 12:15:45 INFO dspy.teleprompt.mipro_optimizer_v2: Proposed Instructions for Predictor 0:\n",
      "\n",
      "2024/12/23 12:15:45 INFO dspy.teleprompt.mipro_optimizer_v2: 0: Generate a single SQLite query that returns the specific information requested in the question \n",
      "and include relevant details such as duration or amount. When asked about information pertaining \n",
      "to cases (not events), group by case to avoid counting the same case multiple times. Aggregate when necessary,\n",
      "using subqueries and outer queries to limit the output size and results in a table that answers the question directly.\n",
      "Be aware to make a distinction between questions that ask about cases and question that ask about events, since some of the available columns are aggregated over cases and might lead to wrong results when used in the wrong context.\n",
      "\n",
      "2024/12/23 12:15:45 INFO dspy.teleprompt.mipro_optimizer_v2: 1: You are a data analyst tasked with generating a single SQLite query to extract precise information from a detailed event log database concerning cases involving fines and penalties. Your goal is to construct a query that returns the specific information requested in the question, such as counts, averages, or frequencies of events like \"Create Fine\" or \"Payment.\" Ensure that when questions pertain to cases, you group by the case identifier to avoid counting the same case multiple times. Use aggregation functions and subqueries as needed to provide a concise and direct answer, and include additional relevant details like duration or amount. Be cautious to distinguish between questions about cases and those about events to avoid using aggregated columns incorrectly.\n",
      "\n",
      "2024/12/23 12:15:45 INFO dspy.teleprompt.mipro_optimizer_v2: 2: Imagine you are tasked with generating a critical report for the city's administrative body to assess the efficiency of their case management system. Your goal is to write a precise SQLite query that extracts specific information from the event log database. This query must accurately differentiate between case-related and event-related questions, ensuring that aggregated data is grouped appropriately to prevent misinterpretation. Your report will influence key decisions on process optimization, so it is essential to ensure the accuracy and reliability of the data you provide. Use subqueries and outer queries effectively to handle complex data retrieval, and always keep in mind the distinction between cases and events to avoid skewing the results.\n",
      "\n",
      "2024/12/23 12:15:45 INFO dspy.teleprompt.mipro_optimizer_v2: 3: Create a SQLite query that accurately retrieves the requested information from the dataset, ensuring to differentiate between case-level and event-level inquiries. When the question pertains to cases, group the results by 'case_concept_name' to prevent duplicate counting of cases. Utilize appropriate SQL functions such as COUNT, AVG, or others as needed for aggregation. If the query involves calculating averages or totals, consider using subqueries or outer queries to refine the output and ensure it directly addresses the question. Always verify the context of the question to select the right columns and avoid misinterpretation of aggregated data.\n",
      "\n",
      "2024/12/23 12:15:45 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "\n",
      "2024/12/23 12:15:45 INFO dspy.teleprompt.mipro_optimizer_v2: Proposed Instructions for Predictor 1:\n",
      "\n",
      "2024/12/23 12:15:45 INFO dspy.teleprompt.mipro_optimizer_v2: 0: Objective: Develop a strategy and logic to create a single SQLite query that will answer a given question.\n",
      "Database Information: Use the details about the database and its columns to guide your approach. \n",
      "Be specific about whether the question pertains to \"cases\" or \"events,\" since every row is an event, and multiple events can be part of a single case.\n",
      "Column Details: Some columns contain the same information for each event (row) per case (referred to as \"case predicate\"). Other columns are independent of cases and refer to events directly.\n",
      "You can determine this, based on whether the column description mentions that all values are the same for a case or if the column is aggregated over a case.\n",
      "Grouping: When asked about questions independent of cases and you are using a column that is a case predicate, group by case to avoid counting an aggregated value multiple times.\n",
      "Do not forget about this for percentage calculations as well (using something like (DISTINCT case_concept_name) FILTER (WHERE col = 1) instead of not grouping by case first for case predicates).\n",
      "Query Construction: Do not write the actual query. Instead, provide a detailed explanation of how to construct the query.\n",
      "Aggregation: Aggregate data when necessary. Use subqueries and outer queries to limit the output size. Ensure the final result is a table that directly answers the question.\n",
      "Some questions might have multiple valid anwers(i.e finding case with highest value x, might have mutliple cases with the same highest value), be aware of this and consider LIMIT 10 instead of LIMIT 1 in such cases.\n",
      "\n",
      "2024/12/23 12:15:45 INFO dspy.teleprompt.mipro_optimizer_v2: 1: You are a data analyst tasked with optimizing the efficiency of case management systems by analyzing event logs related to fines and penalties. Your goal is to develop a strategy and logic to create a single SQLite query that will answer a given question about these events. Use the detailed information about the database columns to guide your approach. Be specific about whether the question pertains to \"cases\" or \"events,\" as each row represents an event, and multiple events can be part of a single case. Pay attention to columns that contain consistent information across all events of a case, and ensure you group by case when necessary to avoid counting aggregated values multiple times. Provide a detailed explanation of how to construct the query without writing the actual query, focusing on data aggregation and the use of subqueries and outer queries to limit the output size. Consider using LIMIT 10 in scenarios where multiple valid answers exist. Your analysis will help improve process optimization and automated reporting in administrative systems.\n",
      "\n",
      "2024/12/23 12:15:45 INFO dspy.teleprompt.mipro_optimizer_v2: 2: To create an SQLite query that addresses a specific question about the event log dataset, follow these steps: \n",
      "\n",
      "1. **Understand the Question Context**: Determine whether the question is about \"cases\" or \"events.\" This differentiation is crucial because each row represents an event, but multiple events can belong to a single case. \n",
      "\n",
      "2. **Identify Relevant Columns**: Based on the question, identify which columns are relevant. For example, if the question pertains to a specific event type, focus on columns like 'concept_name' and the corresponding event count columns.\n",
      "\n",
      "3. **Determine Case Predicate Columns**: Recognize which columns have consistent values across all events for a case (case predicate) and which are event-specific. This will guide how you group or aggregate data.\n",
      "\n",
      "4. **Decide on Grouping and Aggregation**: If the question is case-related, group by 'case_concept_name' to ensure you don't count aggregated values multiple times. For event-specific questions, consider whether you need to sum, count, or filter specific events.\n",
      "\n",
      "5. **Construct the Query Explanation**: Provide a detailed explanation of how to construct the query without writing the actual query. Explain the logic for selecting columns, grouping, and any necessary aggregation. Discuss the use of subqueries if needed to limit the output size or to achieve the desired result.\n",
      "\n",
      "6. **Consider Multiple Answers**: If the question can have multiple valid answers (e.g., finding cases with the highest value of a metric), mention the possibility of using LIMIT 10 instead of LIMIT 1 to accommodate multiple results.\n",
      "\n",
      "By following these steps, you can develop a logical strategy for constructing an SQLite query that effectively answers the question using the dataset's structure and content.\n",
      "\n",
      "2024/12/23 12:15:45 INFO dspy.teleprompt.mipro_optimizer_v2: 3: To address questions related to fines and penalties, develop a comprehensive strategy to construct a single SQLite query that accurately answers the query. Begin by identifying whether the question pertains to individual cases or specific events within those cases. Use the provided column descriptions to determine if the data is consistent across events for a case or specific to individual events. When the question focuses on case-level data, ensure to group by 'case_concept_name' to avoid duplicating aggregated values. For event-specific inquiries, focus on the relevant columns that capture event details. When constructing the query, explain the process step-by-step, including any necessary aggregations or filtering, and ensure the final result is a succinct table that directly answers the question. Consider using subqueries for complex aggregations and apply LIMIT wisely when multiple cases might meet the query criteria equally. Avoid writing the actual query; instead, provide a clear, logical roadmap for query construction.\n",
      "\n",
      "2024/12/23 12:15:45 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "\n",
      "2024/12/23 12:15:45 INFO dspy.teleprompt.mipro_optimizer_v2: Proposed Instructions for Predictor 2:\n",
      "\n",
      "2024/12/23 12:15:45 INFO dspy.teleprompt.mipro_optimizer_v2: 0: Carefully analyze the question and information in the table to form a helpful response. Use all the columns from the table (information) when writing your answer (don't leave away any additional information).\n",
      "\n",
      "2024/12/23 12:15:45 INFO dspy.teleprompt.mipro_optimizer_v2: 1: Imagine you are tasked with ensuring the smooth operation of a case management system for a governmental agency. Your role is crucial as it directly impacts the efficiency of handling fines and penalties. Analyze the given question and the table data thoroughly to generate a precise SQL query that retrieves the necessary information. Your response should include all relevant columns from the table, providing a comprehensive answer. The accuracy of your response could significantly affect the agency's ability to optimize their processes and improve administrative efficiency.\n",
      "\n",
      "2024/12/23 12:15:45 INFO dspy.teleprompt.mipro_optimizer_v2: 2: Imagine you are tasked with generating an urgent report for a high-level meeting in a government department responsible for case management systems. Your job is to analyze the event logs and provide precise statistical insights. Carefully examine the question and utilize all available data from the table to construct a comprehensive and accurate response. Consider the implications of each event type, such as \"Create Fine\" or \"Add Penalty,\" and ensure that your answer is not only correct but also provides valuable insights that can influence decision-making processes. Remember, the accuracy and depth of your response could significantly impact policy decisions and administrative efficiency improvements.\n",
      "\n",
      "2024/12/23 12:15:45 INFO dspy.teleprompt.mipro_optimizer_v2: 3: Given a question regarding case events related to fines and penalties, analyze the provided table information to construct an SQL query that accurately retrieves the requested data. Use all relevant columns from the table to ensure a comprehensive response that aligns with the question's requirements. Provide the SQL query and the resulting answer based on the dataset.\n",
      "\n",
      "2024/12/23 12:15:45 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "\n",
      "2024/12/23 12:15:45 INFO dspy.teleprompt.mipro_optimizer_v2: Evaluating the default program...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[34m[2024-12-23T12:15:45.357817]\u001b[0m\n",
      "\n",
      "\u001b[31mSystem message:\u001b[0m\n",
      "\n",
      "Your input fields are:\n",
      "1. `dataset_description` (str): A description of the dataset that we are using.\n",
      "2. `task_demos` (str): Example inputs/outputs of our module.\n",
      "3. `basic_instruction` (str): Basic instruction.\n",
      "\n",
      "Your output fields are:\n",
      "1. `proposed_instruction` (str): Propose an instruction that will be used to prompt a Language Model to perform this task.\n",
      "\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## dataset_description ## ]]\n",
      "{dataset_description}\n",
      "\n",
      "[[ ## task_demos ## ]]\n",
      "{task_demos}\n",
      "\n",
      "[[ ## basic_instruction ## ]]\n",
      "{basic_instruction}\n",
      "\n",
      "[[ ## proposed_instruction ## ]]\n",
      "{proposed_instruction}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "In adhering to this structure, your objective is: \n",
      "        Use the information below to learn about a task that we are trying to solve using calls to an LM, then generate a new instruction that will be used to prompt a Language Model to better solve the task.\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## dataset_description ## ]]\n",
      "The dataset captures detailed logs of events related to cases involving fines and penalties, emphasizing statistical analysis through counts, averages, and frequencies of events such as \"Create Fine,\" \"Send Appeal to Prefecture,\" and \"Payment.\" Its well-structured questions indicate a focus on precise event tracking, potentially supporting automated reporting to enhance administrative efficiency. The large volume of records and use of comparative metrics suggest its utility in improving process optimization for case management systems.\n",
      "\n",
      "[[ ## task_demos ## ]]\n",
      "Question: How many cases have been added two or more penalties?\n",
      "Table: number_of_cases_with_two_or_more_penalties \n",
      "0\n",
      "Sql: SELECT COUNT(DISTINCT case_concept_name) AS number_of_cases_with_two_or_more_penalties FROM event_log WHERE add_penalty_count >= 2;\n",
      "Answer: 0\n",
      "Question: What is the average number of payment events per case?\n",
      "Table: average_payment_events_per_case \n",
      "0.5160670346478686\n",
      "Sql: SELECT AVG(payment_count) AS average_payment_events_per_case FROM (SELECT DISTINCT case_concept_name, payment_count FROM event_log);\n",
      "Answer: 0.5160670346478686\n",
      "Question: How many cases have two or more payment events?\n",
      "Table: case_count \n",
      "7542\n",
      "Sql: SELECT COUNT(DISTINCT case_concept_name) AS case_count FROM event_log WHERE payment_count >= 2;\n",
      "Answer: 7542\n",
      "\n",
      "\n",
      "[[ ## basic_instruction ## ]]\n",
      "Carefully analyze the question and information in the table to form a helpful response. Use all the columns from the table (information) when writing your answer (don't leave away any additional information).\n",
      "\n",
      "Respond with the corresponding output fields, starting with the field `[[ ## proposed_instruction ## ]]`, and then ending with the marker for `[[ ## completed ## ]]`.\n",
      "\n",
      "\n",
      "\u001b[31mResponse:\u001b[0m\n",
      "\n",
      "\u001b[32m[[ ## proposed_instruction ## ]]\n",
      "Given a question regarding case events related to fines and penalties, analyze the provided table information to construct an SQL query that accurately retrieves the requested data. Use all relevant columns from the table to ensure a comprehensive response that aligns with the question's requirements. Provide the SQL query and the resulting answer based on the dataset.\n",
      "\n",
      "[[ ## completed ## ]]\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "PROPOSED INSTRUCTION: Given a question regarding case events related to fines and penalties, analyze the provided table information to construct an SQL query that accurately retrieves the requested data. Use all relevant columns from the table to ensure a comprehensive response that aligns with the question's requirements. Provide the SQL query and the resulting answer based on the dataset.\n",
      "Average Metric: 110.00 / 62 (177.4%): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 62/62 [07:42<00:00,  7.46s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/23 12:23:27 INFO dspy.evaluate.evaluate: Average Metric: 110 / 62 (177.4%)\n",
      "2024/12/23 12:23:27 INFO dspy.teleprompt.mipro_optimizer_v2: Default program score: 177.42\n",
      "\n",
      "2024/12/23 12:23:27 INFO dspy.teleprompt.mipro_optimizer_v2: ==> STEP 3: FINDING OPTIMAL PROMPT PARAMETERS <==\n",
      "2024/12/23 12:23:27 INFO dspy.teleprompt.mipro_optimizer_v2: We will evaluate the program over a series of trials with different combinations of instructions and few-shot examples to find the optimal combination using Bayesian Optimization.\n",
      "\n",
      "/Users/sulzair/Documents/Bachelor Thesis/dspy_v2/dspy_v2/lib/python3.12/site-packages/optuna/_experimental.py:31: ExperimentalWarning: Argument ``multivariate`` is an experimental feature. The interface can change in the future.\n",
      "  warnings.warn(\n",
      "2024/12/23 12:23:27 INFO dspy.teleprompt.mipro_optimizer_v2: == Minibatch Trial 1 / 7 ==\n",
      "2024/12/23 12:23:27 INFO dspy.teleprompt.mipro_optimizer_v2: Evaluating the following candidate program...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predictor 0\n",
      "i: You are a data analyst tasked with generating a single SQLite query to extract precise information from a detailed event log database concerning cases involving fines and penalties. Your goal is to construct a query that returns the specific information requested in the question, such as counts, averages, or frequencies of events like \"Create Fine\" or \"Payment.\" Ensure that when questions pertain to cases, you group by the case identifier to avoid counting the same case multiple times. Use aggregation functions and subqueries as needed to provide a concise and direct answer, and include additional relevant details like duration or amount. Be cautious to distinguish between questions about cases and those about events to avoid using aggregated columns incorrectly.\n",
      "p: Sqlite Query:\n",
      "Predictor 1\n",
      "i: To create an SQLite query that addresses a specific question about the event log dataset, follow these steps: \n",
      "\n",
      "1. **Understand the Question Context**: Determine whether the question is about \"cases\" or \"events.\" This differentiation is crucial because each row represents an event, but multiple events can belong to a single case. \n",
      "\n",
      "2. **Identify Relevant Columns**: Based on the question, identify which columns are relevant. For example, if the question pertains to a specific event type, focus on columns like 'concept_name' and the corresponding event count columns.\n",
      "\n",
      "3. **Determine Case Predicate Columns**: Recognize which columns have consistent values across all events for a case (case predicate) and which are event-specific. This will guide how you group or aggregate data.\n",
      "\n",
      "4. **Decide on Grouping and Aggregation**: If the question is case-related, group by 'case_concept_name' to ensure you don't count aggregated values multiple times. For event-specific questions, consider whether you need to sum, count, or filter specific events.\n",
      "\n",
      "5. **Construct the Query Explanation**: Provide a detailed explanation of how to construct the query without writing the actual query. Explain the logic for selecting columns, grouping, and any necessary aggregation. Discuss the use of subqueries if needed to limit the output size or to achieve the desired result.\n",
      "\n",
      "6. **Consider Multiple Answers**: If the question can have multiple valid answers (e.g., finding cases with the highest value of a metric), mention the possibility of using LIMIT 10 instead of LIMIT 1 to accommodate multiple results.\n",
      "\n",
      "By following these steps, you can develop a logical strategy for constructing an SQLite query that effectively answers the question using the dataset's structure and content.\n",
      "p: Reasoning:\n",
      "Predictor 2\n",
      "i: Given a question regarding case events related to fines and penalties, analyze the provided table information to construct an SQL query that accurately retrieves the requested data. Use all relevant columns from the table to ensure a comprehensive response that aligns with the question's requirements. Provide the SQL query and the resulting answer based on the dataset.\n",
      "p: Answer:\n",
      "\n",
      "\n",
      "Average Metric: 40.00 / 25 (160.0%): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [03:02<00:00,  7.28s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/23 12:26:30 INFO dspy.evaluate.evaluate: Average Metric: 40 / 25 (160.0%)\n",
      "2024/12/23 12:26:30 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 160.0 on minibatch of size 25 with parameters ['Predictor 0: Instruction 1', 'Predictor 1: Instruction 2', 'Predictor 2: Instruction 3'].\n",
      "2024/12/23 12:26:30 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [160.0]\n",
      "2024/12/23 12:26:30 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [177.42]\n",
      "2024/12/23 12:26:30 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 177.42\n",
      "2024/12/23 12:26:30 INFO dspy.teleprompt.mipro_optimizer_v2: ===========================\n",
      "\n",
      "\n",
      "2024/12/23 12:26:30 INFO dspy.teleprompt.mipro_optimizer_v2: == Minibatch Trial 2 / 7 ==\n",
      "2024/12/23 12:26:30 INFO dspy.teleprompt.mipro_optimizer_v2: Evaluating the following candidate program...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predictor 0\n",
      "i: Generate a single SQLite query that returns the specific information requested in the question \n",
      "and include relevant details such as duration or amount. When asked about information pertaining \n",
      "to cases (not events), group by case to avoid counting the same case multiple times. Aggregate when necessary,\n",
      "using subqueries and outer queries to limit the output size and results in a table that answers the question directly.\n",
      "Be aware to make a distinction between questions that ask about cases and question that ask about events, since some of the available columns are aggregated over cases and might lead to wrong results when used in the wrong context.\n",
      "p: Sqlite Query:\n",
      "Predictor 1\n",
      "i: Objective: Develop a strategy and logic to create a single SQLite query that will answer a given question.\n",
      "Database Information: Use the details about the database and its columns to guide your approach. \n",
      "Be specific about whether the question pertains to \"cases\" or \"events,\" since every row is an event, and multiple events can be part of a single case.\n",
      "Column Details: Some columns contain the same information for each event (row) per case (referred to as \"case predicate\"). Other columns are independent of cases and refer to events directly.\n",
      "You can determine this, based on whether the column description mentions that all values are the same for a case or if the column is aggregated over a case.\n",
      "Grouping: When asked about questions independent of cases and you are using a column that is a case predicate, group by case to avoid counting an aggregated value multiple times.\n",
      "Do not forget about this for percentage calculations as well (using something like (DISTINCT case_concept_name) FILTER (WHERE col = 1) instead of not grouping by case first for case predicates).\n",
      "Query Construction: Do not write the actual query. Instead, provide a detailed explanation of how to construct the query.\n",
      "Aggregation: Aggregate data when necessary. Use subqueries and outer queries to limit the output size. Ensure the final result is a table that directly answers the question.\n",
      "Some questions might have multiple valid anwers(i.e finding case with highest value x, might have mutliple cases with the same highest value), be aware of this and consider LIMIT 10 instead of LIMIT 1 in such cases.\n",
      "p: Reasoning:\n",
      "Predictor 2\n",
      "i: Imagine you are tasked with generating an urgent report for a high-level meeting in a government department responsible for case management systems. Your job is to analyze the event logs and provide precise statistical insights. Carefully examine the question and utilize all available data from the table to construct a comprehensive and accurate response. Consider the implications of each event type, such as \"Create Fine\" or \"Add Penalty,\" and ensure that your answer is not only correct but also provides valuable insights that can influence decision-making processes. Remember, the accuracy and depth of your response could significantly impact policy decisions and administrative efficiency improvements.\n",
      "p: Answer:\n",
      "\n",
      "\n",
      "Average Metric: 46.00 / 25 (184.0%): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [02:59<00:00,  7.20s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/23 12:29:30 INFO dspy.evaluate.evaluate: Average Metric: 46 / 25 (184.0%)\n",
      "2024/12/23 12:29:30 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 184.0 on minibatch of size 25 with parameters ['Predictor 0: Instruction 0', 'Predictor 1: Instruction 0', 'Predictor 2: Instruction 2'].\n",
      "2024/12/23 12:29:30 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [160.0, 184.0]\n",
      "2024/12/23 12:29:30 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [177.42]\n",
      "2024/12/23 12:29:30 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 177.42\n",
      "2024/12/23 12:29:30 INFO dspy.teleprompt.mipro_optimizer_v2: ===========================\n",
      "\n",
      "\n",
      "2024/12/23 12:29:30 INFO dspy.teleprompt.mipro_optimizer_v2: == Minibatch Trial 3 / 7 ==\n",
      "2024/12/23 12:29:30 INFO dspy.teleprompt.mipro_optimizer_v2: Evaluating the following candidate program...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predictor 0\n",
      "i: Imagine you are tasked with generating a critical report for the city's administrative body to assess the efficiency of their case management system. Your goal is to write a precise SQLite query that extracts specific information from the event log database. This query must accurately differentiate between case-related and event-related questions, ensuring that aggregated data is grouped appropriately to prevent misinterpretation. Your report will influence key decisions on process optimization, so it is essential to ensure the accuracy and reliability of the data you provide. Use subqueries and outer queries effectively to handle complex data retrieval, and always keep in mind the distinction between cases and events to avoid skewing the results.\n",
      "p: Sqlite Query:\n",
      "Predictor 1\n",
      "i: You are a data analyst tasked with optimizing the efficiency of case management systems by analyzing event logs related to fines and penalties. Your goal is to develop a strategy and logic to create a single SQLite query that will answer a given question about these events. Use the detailed information about the database columns to guide your approach. Be specific about whether the question pertains to \"cases\" or \"events,\" as each row represents an event, and multiple events can be part of a single case. Pay attention to columns that contain consistent information across all events of a case, and ensure you group by case when necessary to avoid counting aggregated values multiple times. Provide a detailed explanation of how to construct the query without writing the actual query, focusing on data aggregation and the use of subqueries and outer queries to limit the output size. Consider using LIMIT 10 in scenarios where multiple valid answers exist. Your analysis will help improve process optimization and automated reporting in administrative systems.\n",
      "p: Reasoning:\n",
      "Predictor 2\n",
      "i: Carefully analyze the question and information in the table to form a helpful response. Use all the columns from the table (information) when writing your answer (don't leave away any additional information).\n",
      "p: Answer:\n",
      "\n",
      "\n",
      "Average Metric: 45.00 / 25 (180.0%): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [02:59<00:00,  7.17s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/23 12:32:29 INFO dspy.evaluate.evaluate: Average Metric: 45 / 25 (180.0%)\n",
      "2024/12/23 12:32:29 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 180.0 on minibatch of size 25 with parameters ['Predictor 0: Instruction 2', 'Predictor 1: Instruction 1', 'Predictor 2: Instruction 0'].\n",
      "2024/12/23 12:32:29 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [160.0, 184.0, 180.0]\n",
      "2024/12/23 12:32:29 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [177.42]\n",
      "2024/12/23 12:32:29 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 177.42\n",
      "2024/12/23 12:32:29 INFO dspy.teleprompt.mipro_optimizer_v2: ===========================\n",
      "\n",
      "\n",
      "2024/12/23 12:32:29 INFO dspy.teleprompt.mipro_optimizer_v2: == Minibatch Trial 4 / 7 ==\n",
      "2024/12/23 12:32:29 INFO dspy.teleprompt.mipro_optimizer_v2: Evaluating the following candidate program...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predictor 0\n",
      "i: Generate a single SQLite query that returns the specific information requested in the question \n",
      "and include relevant details such as duration or amount. When asked about information pertaining \n",
      "to cases (not events), group by case to avoid counting the same case multiple times. Aggregate when necessary,\n",
      "using subqueries and outer queries to limit the output size and results in a table that answers the question directly.\n",
      "Be aware to make a distinction between questions that ask about cases and question that ask about events, since some of the available columns are aggregated over cases and might lead to wrong results when used in the wrong context.\n",
      "p: Sqlite Query:\n",
      "Predictor 1\n",
      "i: Objective: Develop a strategy and logic to create a single SQLite query that will answer a given question.\n",
      "Database Information: Use the details about the database and its columns to guide your approach. \n",
      "Be specific about whether the question pertains to \"cases\" or \"events,\" since every row is an event, and multiple events can be part of a single case.\n",
      "Column Details: Some columns contain the same information for each event (row) per case (referred to as \"case predicate\"). Other columns are independent of cases and refer to events directly.\n",
      "You can determine this, based on whether the column description mentions that all values are the same for a case or if the column is aggregated over a case.\n",
      "Grouping: When asked about questions independent of cases and you are using a column that is a case predicate, group by case to avoid counting an aggregated value multiple times.\n",
      "Do not forget about this for percentage calculations as well (using something like (DISTINCT case_concept_name) FILTER (WHERE col = 1) instead of not grouping by case first for case predicates).\n",
      "Query Construction: Do not write the actual query. Instead, provide a detailed explanation of how to construct the query.\n",
      "Aggregation: Aggregate data when necessary. Use subqueries and outer queries to limit the output size. Ensure the final result is a table that directly answers the question.\n",
      "Some questions might have multiple valid anwers(i.e finding case with highest value x, might have mutliple cases with the same highest value), be aware of this and consider LIMIT 10 instead of LIMIT 1 in such cases.\n",
      "p: Reasoning:\n",
      "Predictor 2\n",
      "i: Carefully analyze the question and information in the table to form a helpful response. Use all the columns from the table (information) when writing your answer (don't leave away any additional information).\n",
      "p: Answer:\n",
      "\n",
      "\n",
      "Average Metric: 48.00 / 25 (192.0%): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [03:01<00:00,  7.26s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/23 12:35:30 INFO dspy.evaluate.evaluate: Average Metric: 48 / 25 (192.0%)\n",
      "2024/12/23 12:35:30 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 192.0 on minibatch of size 25 with parameters ['Predictor 0: Instruction 0', 'Predictor 1: Instruction 0', 'Predictor 2: Instruction 0'].\n",
      "2024/12/23 12:35:30 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [160.0, 184.0, 180.0, 192.0]\n",
      "2024/12/23 12:35:30 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [177.42]\n",
      "2024/12/23 12:35:30 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 177.42\n",
      "2024/12/23 12:35:30 INFO dspy.teleprompt.mipro_optimizer_v2: ===========================\n",
      "\n",
      "\n",
      "2024/12/23 12:35:30 INFO dspy.teleprompt.mipro_optimizer_v2: == Minibatch Trial 5 / 7 ==\n",
      "2024/12/23 12:35:31 INFO dspy.teleprompt.mipro_optimizer_v2: Evaluating the following candidate program...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predictor 0\n",
      "i: Generate a single SQLite query that returns the specific information requested in the question \n",
      "and include relevant details such as duration or amount. When asked about information pertaining \n",
      "to cases (not events), group by case to avoid counting the same case multiple times. Aggregate when necessary,\n",
      "using subqueries and outer queries to limit the output size and results in a table that answers the question directly.\n",
      "Be aware to make a distinction between questions that ask about cases and question that ask about events, since some of the available columns are aggregated over cases and might lead to wrong results when used in the wrong context.\n",
      "p: Sqlite Query:\n",
      "Predictor 1\n",
      "i: Objective: Develop a strategy and logic to create a single SQLite query that will answer a given question.\n",
      "Database Information: Use the details about the database and its columns to guide your approach. \n",
      "Be specific about whether the question pertains to \"cases\" or \"events,\" since every row is an event, and multiple events can be part of a single case.\n",
      "Column Details: Some columns contain the same information for each event (row) per case (referred to as \"case predicate\"). Other columns are independent of cases and refer to events directly.\n",
      "You can determine this, based on whether the column description mentions that all values are the same for a case or if the column is aggregated over a case.\n",
      "Grouping: When asked about questions independent of cases and you are using a column that is a case predicate, group by case to avoid counting an aggregated value multiple times.\n",
      "Do not forget about this for percentage calculations as well (using something like (DISTINCT case_concept_name) FILTER (WHERE col = 1) instead of not grouping by case first for case predicates).\n",
      "Query Construction: Do not write the actual query. Instead, provide a detailed explanation of how to construct the query.\n",
      "Aggregation: Aggregate data when necessary. Use subqueries and outer queries to limit the output size. Ensure the final result is a table that directly answers the question.\n",
      "Some questions might have multiple valid anwers(i.e finding case with highest value x, might have mutliple cases with the same highest value), be aware of this and consider LIMIT 10 instead of LIMIT 1 in such cases.\n",
      "p: Reasoning:\n",
      "Predictor 2\n",
      "i: Carefully analyze the question and information in the table to form a helpful response. Use all the columns from the table (information) when writing your answer (don't leave away any additional information).\n",
      "p: Answer:\n",
      "\n",
      "\n",
      "Average Metric: 43.00 / 25 (172.0%): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [02:48<00:00,  6.76s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/23 12:38:19 INFO dspy.evaluate.evaluate: Average Metric: 43 / 25 (172.0%)\n",
      "2024/12/23 12:38:20 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 172.0 on minibatch of size 25 with parameters ['Predictor 0: Instruction 0', 'Predictor 1: Instruction 0', 'Predictor 2: Instruction 0'].\n",
      "2024/12/23 12:38:20 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [160.0, 184.0, 180.0, 192.0, 172.0]\n",
      "2024/12/23 12:38:20 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [177.42]\n",
      "2024/12/23 12:38:20 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 177.42\n",
      "2024/12/23 12:38:20 INFO dspy.teleprompt.mipro_optimizer_v2: ===========================\n",
      "\n",
      "\n",
      "2024/12/23 12:38:20 INFO dspy.teleprompt.mipro_optimizer_v2: == Minibatch Trial 6 / 7 ==\n",
      "2024/12/23 12:38:20 INFO dspy.teleprompt.mipro_optimizer_v2: Evaluating the following candidate program...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predictor 0\n",
      "i: Imagine you are tasked with generating a critical report for the city's administrative body to assess the efficiency of their case management system. Your goal is to write a precise SQLite query that extracts specific information from the event log database. This query must accurately differentiate between case-related and event-related questions, ensuring that aggregated data is grouped appropriately to prevent misinterpretation. Your report will influence key decisions on process optimization, so it is essential to ensure the accuracy and reliability of the data you provide. Use subqueries and outer queries effectively to handle complex data retrieval, and always keep in mind the distinction between cases and events to avoid skewing the results.\n",
      "p: Sqlite Query:\n",
      "Predictor 1\n",
      "i: Objective: Develop a strategy and logic to create a single SQLite query that will answer a given question.\n",
      "Database Information: Use the details about the database and its columns to guide your approach. \n",
      "Be specific about whether the question pertains to \"cases\" or \"events,\" since every row is an event, and multiple events can be part of a single case.\n",
      "Column Details: Some columns contain the same information for each event (row) per case (referred to as \"case predicate\"). Other columns are independent of cases and refer to events directly.\n",
      "You can determine this, based on whether the column description mentions that all values are the same for a case or if the column is aggregated over a case.\n",
      "Grouping: When asked about questions independent of cases and you are using a column that is a case predicate, group by case to avoid counting an aggregated value multiple times.\n",
      "Do not forget about this for percentage calculations as well (using something like (DISTINCT case_concept_name) FILTER (WHERE col = 1) instead of not grouping by case first for case predicates).\n",
      "Query Construction: Do not write the actual query. Instead, provide a detailed explanation of how to construct the query.\n",
      "Aggregation: Aggregate data when necessary. Use subqueries and outer queries to limit the output size. Ensure the final result is a table that directly answers the question.\n",
      "Some questions might have multiple valid anwers(i.e finding case with highest value x, might have mutliple cases with the same highest value), be aware of this and consider LIMIT 10 instead of LIMIT 1 in such cases.\n",
      "p: Reasoning:\n",
      "Predictor 2\n",
      "i: Imagine you are tasked with generating an urgent report for a high-level meeting in a government department responsible for case management systems. Your job is to analyze the event logs and provide precise statistical insights. Carefully examine the question and utilize all available data from the table to construct a comprehensive and accurate response. Consider the implications of each event type, such as \"Create Fine\" or \"Add Penalty,\" and ensure that your answer is not only correct but also provides valuable insights that can influence decision-making processes. Remember, the accuracy and depth of your response could significantly impact policy decisions and administrative efficiency improvements.\n",
      "p: Answer:\n",
      "\n",
      "\n",
      "Average Metric: 42.00 / 25 (168.0%): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [02:45<00:00,  6.62s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/23 12:41:05 INFO dspy.evaluate.evaluate: Average Metric: 42 / 25 (168.0%)\n",
      "2024/12/23 12:41:05 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 168.0 on minibatch of size 25 with parameters ['Predictor 0: Instruction 2', 'Predictor 1: Instruction 0', 'Predictor 2: Instruction 2'].\n",
      "2024/12/23 12:41:05 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [160.0, 184.0, 180.0, 192.0, 172.0, 168.0]\n",
      "2024/12/23 12:41:05 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [177.42]\n",
      "2024/12/23 12:41:05 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 177.42\n",
      "2024/12/23 12:41:05 INFO dspy.teleprompt.mipro_optimizer_v2: ===========================\n",
      "\n",
      "\n",
      "2024/12/23 12:41:05 INFO dspy.teleprompt.mipro_optimizer_v2: == Minibatch Trial 7 / 7 ==\n",
      "2024/12/23 12:41:05 INFO dspy.teleprompt.mipro_optimizer_v2: Evaluating the following candidate program...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predictor 0\n",
      "i: Create a SQLite query that accurately retrieves the requested information from the dataset, ensuring to differentiate between case-level and event-level inquiries. When the question pertains to cases, group the results by 'case_concept_name' to prevent duplicate counting of cases. Utilize appropriate SQL functions such as COUNT, AVG, or others as needed for aggregation. If the query involves calculating averages or totals, consider using subqueries or outer queries to refine the output and ensure it directly addresses the question. Always verify the context of the question to select the right columns and avoid misinterpretation of aggregated data.\n",
      "p: Sqlite Query:\n",
      "Predictor 1\n",
      "i: You are a data analyst tasked with optimizing the efficiency of case management systems by analyzing event logs related to fines and penalties. Your goal is to develop a strategy and logic to create a single SQLite query that will answer a given question about these events. Use the detailed information about the database columns to guide your approach. Be specific about whether the question pertains to \"cases\" or \"events,\" as each row represents an event, and multiple events can be part of a single case. Pay attention to columns that contain consistent information across all events of a case, and ensure you group by case when necessary to avoid counting aggregated values multiple times. Provide a detailed explanation of how to construct the query without writing the actual query, focusing on data aggregation and the use of subqueries and outer queries to limit the output size. Consider using LIMIT 10 in scenarios where multiple valid answers exist. Your analysis will help improve process optimization and automated reporting in administrative systems.\n",
      "p: Reasoning:\n",
      "Predictor 2\n",
      "i: Given a question regarding case events related to fines and penalties, analyze the provided table information to construct an SQL query that accurately retrieves the requested data. Use all relevant columns from the table to ensure a comprehensive response that aligns with the question's requirements. Provide the SQL query and the resulting answer based on the dataset.\n",
      "p: Answer:\n",
      "\n",
      "\n",
      "Average Metric: 43.00 / 25 (172.0%): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [04:31<00:00, 10.85s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/23 12:45:36 INFO dspy.evaluate.evaluate: Average Metric: 43 / 25 (172.0%)\n",
      "2024/12/23 12:45:36 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 172.0 on minibatch of size 25 with parameters ['Predictor 0: Instruction 3', 'Predictor 1: Instruction 1', 'Predictor 2: Instruction 3'].\n",
      "2024/12/23 12:45:36 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [160.0, 184.0, 180.0, 192.0, 172.0, 168.0, 172.0]\n",
      "2024/12/23 12:45:36 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [177.42]\n",
      "2024/12/23 12:45:36 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 177.42\n",
      "2024/12/23 12:45:36 INFO dspy.teleprompt.mipro_optimizer_v2: ===========================\n",
      "\n",
      "\n",
      "2024/12/23 12:45:36 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Full Eval 1 =====\n",
      "2024/12/23 12:45:36 INFO dspy.teleprompt.mipro_optimizer_v2: Doing full eval on next top averaging program (Avg Score: 184.0) from minibatch trials...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 30.00 / 16 (187.5%):  26%|‚ñà‚ñà‚ñå       | 16/62 [01:45<04:56,  6.45s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/23 12:47:29 INFO dspy.primitives.assertions: SuggestionFailed: Error executing SQLite query near \"15\": syntax error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 110.00 / 62 (177.4%): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 62/62 [07:07<00:00,  6.90s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/23 12:52:44 INFO dspy.evaluate.evaluate: Average Metric: 110 / 62 (177.4%)\n",
      "2024/12/23 12:52:44 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [177.42, 177.42]\n",
      "2024/12/23 12:52:44 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 177.42\n",
      "2024/12/23 12:52:44 INFO dspy.teleprompt.mipro_optimizer_v2: =======================\n",
      "2024/12/23 12:52:44 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "\n",
      "2024/12/23 12:52:44 INFO dspy.teleprompt.mipro_optimizer_v2: Returning best identified program with score 177.42!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "zeroshot_optimized_program = teleprompter.compile(\n",
    "    sql_random_search,\n",
    "    trainset=trainset,\n",
    "    max_bootstrapped_demos=0, # ZERO FEW-SHOT EXAMPLES\n",
    "    max_labeled_demos=0, # ZERO FEW-SHOT EXAMPLES\n",
    "    requires_permission_to_run=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeroshot_optimized_program.save(\"/Users/sulzair/Documents/Bachelor Thesis/dspy_v2/Optimized_prompts/sql_mipro_v2_1_optimized.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dspy_v2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
